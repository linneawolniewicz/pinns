{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Physics Informed Neural Networks\n",
    "\n",
    "This notebook implements PINNs from Raissi et al. 2017. Specifically, the notebook adapts the code implementation of Data-Driven Solutions of Nonlinear Partial Differential Equations from https://github.com/maziarraissi/PINNs, and the code by Michael Ito, to solve the force-field equation for solar modulation of cosmic rays. Michael Ito's code adaption use the TF2 API where the main mechanisms of the PINN arise in the train_step function efficiently computing higher order derivatives of custom loss functions through the use of the GradientTape data structure. \n",
    "\n",
    "In this application, our PINN is $h(r, p) = \\frac{\\partial f}{\\partial r} + \\frac{RV}{3k} \\frac{\\partial f}{\\partial p}$ where $k=\\beta(p)k_1(r)k_2(r)$ and $\\beta = \\frac{p}{\\sqrt{p^2 + M^2}}$. We will approximate $f(r, p)$ using a neural network.\n",
    "\n",
    "We have no initial data, but our boundary data will be given by $f(r_{HP}, p) = \\frac{J(r_{HP}, T)}{p^2} = \\frac{(T+M)^\\gamma}{p^2}$, where $r_{HP} = 120$ AU (i.e. the radius of Heliopause), $M=0.938$ GeV, $\\gamma$ is between $-2$ and $-3$, and $T = \\sqrt{p^2 + M^2} - M$. Or, vice versa, $p = \\sqrt{T^2 + 2TM}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 13:29:54.594232: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/system/CUDA/11.0.2/nvvm/lib64:/opt/apps/software/system/CUDA/11.0.2/extras/CUPTI/lib64:/opt/apps/software/system/CUDA/11.0.2/lib:/opt/apps/software/lib/slurm-drmaa/1.1.3/lib:/opt/apps/software/lib/libevent/2.1.8/lib:/opt/apps/software/devel/PCRE/8.41-GCCcore-7.3.0/lib:/opt/apps/software/lang/Perl/5.28.0-GCCcore-7.3.0/lib:/opt/apps/software/tools/expat/2.2.5-GCCcore-7.3.0/lib:/opt/apps/software/lang/Python/2.7.15-foss-2018b/lib/python2.7/site-packages/numpy-1.14.5-py2.7-linux-x86_64.egg/numpy/core/lib:/opt/apps/software/lang/Python/2.7.15-foss-2018b/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-7.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-7.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-7.3.0/lib:/opt/apps/software/devel/SQLite/3.24.0-GCCcore-7.3.0/lib:/opt/apps/software/lang/Tcl/8.6.8-GCCcore-7.3.0/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-7.3.0/lib:/opt/apps/software/devel/ncurses/6.1-GCCcore-7.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6-GCCcore-7.3.0/lib:/opt/apps/software/numlib/ScaLAPACK/2.0.2-gompi-2018b-OpenBLAS-0.3.1/lib:/opt/apps/software/numlib/FFTW/3.3.8-gompi-2018b/lib:/opt/apps/software/numlib/OpenBLAS/0.3.1-GCC-7.3.0-2.30/lib:/opt/apps/software/system/hwloc/1.11.10-GCCcore-7.3.0/lib:/opt/apps/software/system/libpciaccess/0.14-GCCcore-7.3.0/lib:/opt/apps/software/lib/libxml2/2.9.8-GCCcore-7.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-7.3.0/lib:/opt/apps/software/tools/numactl/2.0.11-GCCcore-7.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-7.3.0/lib:/opt/apps/software/tools/binutils/2.30-GCCcore-7.3.0/lib:/opt/apps/software/compiler/GCCcore/7.3.0/lib/gcc/x86_64-pc-linux-gnu/7.3.0:/opt/apps/software/compiler/GCCcore/7.3.0/lib64:/opt/apps/software/compiler/GCCcore/7.3.0/lib:/opt/apps/software/tools/zsh/5.7.1/lib\n",
      "2022-09-23 13:29:54.595693: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/system/CUDA/11.0.2/nvvm/lib64:/opt/apps/software/system/CUDA/11.0.2/extras/CUPTI/lib64:/opt/apps/software/system/CUDA/11.0.2/lib:/opt/apps/software/lib/slurm-drmaa/1.1.3/lib:/opt/apps/software/lib/libevent/2.1.8/lib:/opt/apps/software/devel/PCRE/8.41-GCCcore-7.3.0/lib:/opt/apps/software/lang/Perl/5.28.0-GCCcore-7.3.0/lib:/opt/apps/software/tools/expat/2.2.5-GCCcore-7.3.0/lib:/opt/apps/software/lang/Python/2.7.15-foss-2018b/lib/python2.7/site-packages/numpy-1.14.5-py2.7-linux-x86_64.egg/numpy/core/lib:/opt/apps/software/lang/Python/2.7.15-foss-2018b/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-7.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-7.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-7.3.0/lib:/opt/apps/software/devel/SQLite/3.24.0-GCCcore-7.3.0/lib:/opt/apps/software/lang/Tcl/8.6.8-GCCcore-7.3.0/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-7.3.0/lib:/opt/apps/software/devel/ncurses/6.1-GCCcore-7.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6-GCCcore-7.3.0/lib:/opt/apps/software/numlib/ScaLAPACK/2.0.2-gompi-2018b-OpenBLAS-0.3.1/lib:/opt/apps/software/numlib/FFTW/3.3.8-gompi-2018b/lib:/opt/apps/software/numlib/OpenBLAS/0.3.1-GCC-7.3.0-2.30/lib:/opt/apps/software/system/hwloc/1.11.10-GCCcore-7.3.0/lib:/opt/apps/software/system/libpciaccess/0.14-GCCcore-7.3.0/lib:/opt/apps/software/lib/libxml2/2.9.8-GCCcore-7.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-7.3.0/lib:/opt/apps/software/tools/numactl/2.0.11-GCCcore-7.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-7.3.0/lib:/opt/apps/software/tools/binutils/2.30-GCCcore-7.3.0/lib:/opt/apps/software/compiler/GCCcore/7.3.0/lib/gcc/x86_64-pc-linux-gnu/7.3.0:/opt/apps/software/compiler/GCCcore/7.3.0/lib64:/opt/apps/software/compiler/GCCcore/7.3.0/lib:/opt/apps/software/tools/zsh/5.7.1/lib\n",
      "2022-09-23 13:29:54.595724: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sherpa\n",
    "import pickle as pkl\n",
    "\n",
    "tf.config.list_physical_devices(device_type=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants  \n",
    "m = 0.938 # GeV/c^2\n",
    "gamma = -3 # Between -2 and -3\n",
    "size = 512 # size of r, T, p, and f_boundary\n",
    "\n",
    "# Create intial data\n",
    "T = np.logspace(np.log10(0.001), np.log10(1000), size).flatten()[:,None] # GeV\n",
    "p = (np.sqrt((T+m)**2-m**2)).flatten()[:,None] # GeV/c\n",
    "r = np.logspace(np.log10(119*150e6), np.log10(120*150e6), size).flatten()[:,None] # km\n",
    "f_boundary = ((T + m)**gamma)/(p**2) # particles/(m^3 (GeV/c)^3)\n",
    "\n",
    "# Take the log of all input data\n",
    "r = np.log(r)\n",
    "T = np.log(T)\n",
    "p = np.log(p)\n",
    "f_boundary = np.log(f_boundary)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array([p[0], r[0]]) # (p, r) in (GeV, AU)\n",
    "ub = np.array([p[-1], r[-1]]) # (p, r) in (GeV, AU)\n",
    "\n",
    "# Flatten and transpose data for ML\n",
    "P, R = np.meshgrid(p, r)\n",
    "P_star = np.hstack((P.flatten()[:,None], R.flatten()[:,None]))\n",
    "\n",
    "# Check inputs\n",
    "# print(f'r: {r.shape}, p: {p.shape}, T: {T.shape}, f_boundary: {f_boundary.shape}, P_star: {P_star.shape}, lb: {lb}, ub:{ub}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINN Class\n",
    "\n",
    "The PINN class subclasses the Keras Model so that we can implement our custom fit and train_step functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Description: Defines the class for a PINN model implementing train_step, fit, and predict functions. Note, it is necessary \n",
    "to design each PINN seperately for each system of PDEs since the train_step is customized for a specific system. \n",
    "This PINN in particular solves the force-field equation for solar modulation of cosmic rays. Once trained, the PINN can predict the solution space given \n",
    "domain bounds and the input space. \n",
    "'''\n",
    "class PINN(tf.keras.Model):\n",
    "    def __init__(self, inputs, outputs, lower_bound, upper_bound, p, r, f_boundary, size, n_samples=20000, n_boundary=50):\n",
    "        super(PINN, self).__init__(inputs=inputs, outputs=outputs)\n",
    "        self.lower_bound = lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "        self.p = p\n",
    "        self.r = r\n",
    "        self.f_boundary = f_boundary\n",
    "        self.n_samples = n_samples\n",
    "        self.n_boundary = n_boundary\n",
    "        self.size = size\n",
    "        \n",
    "    '''\n",
    "    Description: A system of PDEs are determined by 2 types of equations: the main partial differential equations \n",
    "    and the boundary value equations. These two equations will serve as loss functions which \n",
    "    we train the PINN to satisfy. If a PINN can satisfy BOTH equations, the system is solved. Since there are 2 types of \n",
    "    equations (PDE, Boundary Value), we will need 2 types of inputs. Each input is composed of a spatial \n",
    "    variable 'r' and a momentum variable 'p'. The different types of (p, r) pairs are described below.\n",
    "    \n",
    "    Inputs: \n",
    "        p, r: (batchsize, 1) shaped arrays : These inputs are used to derive the main partial differential equation loss.\n",
    "        Train step first feeds (p, r) through the PINN for the forward propagation. This expression is PINN(p, r) = f. \n",
    "        Next, the partials f_p and f_r are obtained. We utilize TF2s GradientTape data structure to obtain all partials. \n",
    "        Once we obtain these partials, we can compute the main PDE loss and optimize weights w.r.t. to the loss. \n",
    "        \n",
    "        p_boundary, r_boundary : (boundary_batchsize, 1) shaped arrays : These inputs are used to derive the boundary value\n",
    "        equations. The boundary value loss relies on target data (**not an equation**), so we can just measure the MAE of \n",
    "        PINN(p_boundary, r_boundary) = f_pred_boundary and boundary_f.\n",
    "        \n",
    "        f_boundary: (boundary_batchsize, 1) shaped arrays : This is the target data for the boundary value inputs\n",
    "        \n",
    "        alpha = weight on pinn_loss\n",
    "        \n",
    "    Outputs: sum_loss, pinn_loss, boundary_loss\n",
    "    '''\n",
    "    def train_step(self, p, r, p_boundary, r_boundary, f_boundary, alpha=1):\n",
    "        with tf.GradientTape(persistent=True) as t2: \n",
    "            with tf.GradientTape(persistent=True) as t1: \n",
    "                # Forward pass P (PINN data)\n",
    "                P = tf.concat((p, r), axis=1)\n",
    "                f = self.tf_call(P)\n",
    "\n",
    "                # Forward pass P_boundary (boundary condition data)\n",
    "                P_boundary = tf.concat((p_boundary, r_boundary), axis=1)\n",
    "                f_pred_boundary = self.tf_call(P_boundary)\n",
    "\n",
    "                # Calculate boundary loss\n",
    "                boundary_loss = tf.math.reduce_mean(tf.math.square(f_pred_boundary - f_boundary))\n",
    "\n",
    "            # Calculate first-order PINN gradients\n",
    "            f_p = t1.gradient(f, p)\n",
    "            f_r = t1.gradient(f, r)\n",
    "            \n",
    "            pinn_loss = self.pinn_loss(p, r, f_p, f_r)\n",
    "            total_loss = pinn_loss*boundary_loss\n",
    "        \n",
    "        # Backpropagation\n",
    "        gradients = t2.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Return losses\n",
    "        return pinn_loss.numpy(), boundary_loss.numpy()\n",
    "    \n",
    "    '''\n",
    "    Description: The fit function used to iterate through epoch * steps_per_epoch steps of train_step. \n",
    "    \n",
    "    Inputs: \n",
    "        P_predict: (N, 2) array: Input data for entire spatial and temporal domain. Used for vizualization for\n",
    "        predictions at the end of each epoch. Michael created a very pretty video file with it. \n",
    "        \n",
    "        alpha: weight on pinn_loss\n",
    "        \n",
    "        batchsize: batchsize for (p, r) in train step\n",
    "        \n",
    "        boundary_batchsize: batchsize for (x_lower, t_boundary) and (x_upper, t_boundary) in train step\n",
    "        \n",
    "        epochs: epochs\n",
    "        \n",
    "        lr: learning rate\n",
    "        \n",
    "        size: size of the prediction data (i.e. len(p) and len(r))\n",
    "        \n",
    "        save: Whether or not to save the model to a checkpoint every 10 epochs\n",
    "        \n",
    "        load_epoch: If -1, a saved model will not be loaded. Otherwise, the model will be \n",
    "        loaded from the provided epoch\n",
    "        \n",
    "        lr_decay: If -1, learning rate will not be decayed. Otherwise, lr = lr_decay*lr if loss doesn't\n",
    "        decrease for 3 epochs\n",
    "        \n",
    "        weight_change: If -1, alpha will not be changed. Otherwise, alpha = weight_change*alpha if loss \n",
    "        doesn't decrease for 3 epochs\n",
    "        \n",
    "        filename: Name for the checkpoint file\n",
    "    \n",
    "    Outputs: Losses for each equation (Total, PDE, Boundary Value), and predictions for each epoch.\n",
    "    '''\n",
    "    def fit(self, P_predict, alpha=1, batchsize=64, boundary_batchsize=16, epochs=20, lr=3e-3, size=256, \n",
    "            save=False, load_epoch=-1, lr_decay=-1, weight_change=-1, filename='pinn_epoch_'):\n",
    "        # If load == True, load the weights\n",
    "        if load_epoch != -1:\n",
    "            name = './ckpts/pinn_' + filename + '_epoch_' + str(load_epoch)\n",
    "            self.load_weights(name)\n",
    "        \n",
    "        # Initialize losses as zeros\n",
    "        steps_per_epoch = np.ceil(self.n_samples / batchsize).astype(int)\n",
    "        total_pinn_loss = np.zeros((epochs, ))\n",
    "        total_boundary_loss = np.zeros((epochs, ))\n",
    "        predictions = np.zeros((size**2, 1, epochs))\n",
    "        \n",
    "        # For each epoch, sample new values in the PINN and boundary areas and pass them to train_step\n",
    "        for epoch in range(epochs):\n",
    "            # Compile\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "            self.compile(optimizer=opt)\n",
    "\n",
    "            # Reset loss variables\n",
    "            sum_loss = np.zeros((steps_per_epoch,))\n",
    "            pinn_loss = np.zeros((steps_per_epoch,))\n",
    "            boundary_loss = np.zeros((steps_per_epoch,))\n",
    "            \n",
    "            # For each step, get PINN and boundary variables and pass them to train_step\n",
    "            for step in range(steps_per_epoch):\n",
    "                # Get PINN p and r variables via uniform distribution sampling between lower and upper bounds\n",
    "                p = tf.Variable(tf.random.uniform((batchsize, 1), minval=self.lower_bound[0], maxval=self.upper_bound[0]))\n",
    "                r = tf.Variable(tf.random.uniform((batchsize, 1), minval=self.lower_bound[1], maxval=self.upper_bound[1]))\n",
    "                \n",
    "                # Randomly sample boundary_batchsize from p_boundary and f_boundary\n",
    "                p_idx = np.expand_dims(np.random.choice(self.f_boundary.shape[0], boundary_batchsize, replace=False), axis=1)\n",
    "                p_boundary = self.p[p_idx]\n",
    "                f_boundary = self.f_boundary[p_idx]\n",
    "                \n",
    "                # Create r_boundary array = r_HP\n",
    "                upper_bound = np.zeros((boundary_batchsize, 1))\n",
    "                upper_bound[:] = self.upper_bound[1]\n",
    "                r_boundary = tf.Variable(upper_bound, dtype=tf.float32)\n",
    "                \n",
    "                # Pass variables through the model via train_step and get losses\n",
    "                losses = self.train_step(p, r, p_boundary, r_boundary, f_boundary, alpha)\n",
    "                pinn_loss[step] = losses[0]\n",
    "                boundary_loss[step] = losses[1]\n",
    "            \n",
    "            # Calculate and print total losses for the epoch\n",
    "            total_pinn_loss[epoch] = np.sum(pinn_loss)\n",
    "            total_boundary_loss[epoch] = np.sum(boundary_loss)\n",
    "            print(f'Training loss for epoch {epoch}: pinn: {total_pinn_loss[epoch]:.4f}, boundary: {total_boundary_loss[epoch]:.4f}, total: {(total_boundary_loss[epoch]*total_pinn_loss[epoch]):.4f}')\n",
    "            \n",
    "            # Predict\n",
    "            predictions[:, :, epoch] = self.predict(P_predict, size)\n",
    "            \n",
    "            # If the epoch is a multiple of 10, save to a checkpoint\n",
    "            if (epoch%10 == 0) & (save == True):\n",
    "                name = './ckpts/pinn_' + filename + '_epoch_' + str(epoch)\n",
    "                self.save_weights(name, overwrite=True, save_format=None, options=None)\n",
    "            \n",
    "            # Determine if loss has decreased for the past 2 or 5 epochs\n",
    "            if (epoch > 3):\n",
    "                isDecreasingFor2 = False\n",
    "                for i in range(2):\n",
    "                    if (total_pinn_loss[epoch-i] + total_boundary_loss[epoch-i]) < (total_pinn_loss[epoch-(i+1)] + total_boundary_loss[epoch-(i+1)]):\n",
    "                        isDecreasingFor2 = True\n",
    "                        \n",
    "                # If loss hasn't decreased for the past 2 epochs, decrease lr by lr_decay\n",
    "                if (lr_decay != -1) & (not isDecreasingFor2):\n",
    "                    lr = lr_decay*lr\n",
    "\n",
    "                # If pinn loss hasn't decreased for the past 2 epochs, increase alpha by weight_change\n",
    "                if (weight_change != -1) & (not isDecreasingFor2):\n",
    "                    alpha = np.tanh(weight_change*alpha)\n",
    "                    print(f'New learning rate {lr} and alpha {alpha}') \n",
    "        \n",
    "        # Return epoch losses\n",
    "        return total_pinn_loss, total_boundary_loss, predictions\n",
    "    \n",
    "    # Predict for some P's the value of the neural network f(r, p)\n",
    "    def predict(self, P, size, batchsize=2048):\n",
    "        steps_per_epoch = np.ceil(P.shape[0] / batchsize).astype(int)\n",
    "        preds = np.zeros((size**2, 1))\n",
    "        \n",
    "        # For each step calculate start and end index values for prediction data\n",
    "        for step in range(steps_per_epoch):\n",
    "            start_idx = step * 64\n",
    "            \n",
    "            # If last step of the epoch, end_idx is shape-1. Else, end_idx is start_idx + 64 \n",
    "            if step == steps_per_epoch - 1:\n",
    "                end_idx = P.shape[0] - 1\n",
    "            else:\n",
    "                end_idx = start_idx + 64\n",
    "                \n",
    "            # Pass prediction data through the model\n",
    "            preds[start_idx:end_idx, :] = self.tf_call(P[start_idx:end_idx, :]).numpy()\n",
    "        \n",
    "        # Return f\n",
    "        return preds\n",
    "    \n",
    "    def evaluate(self, ): \n",
    "        pass\n",
    "    \n",
    "    # pinn_loss calculates the PINN loss by calculating the MAE of the pinn function\n",
    "    @tf.function\n",
    "    def pinn_loss(self, p, r, f_p, f_r): \n",
    "        # Note: p and r are taken out of logspace for the PINN calculation\n",
    "        p = tf.math.exp(p) # GeV/c\n",
    "        r = tf.math.exp(r) # km\n",
    "        V = 400 # 400 km/s\n",
    "        m = 0.938 # GeV/c^2\n",
    "        k_0 = 1e11 # km^2/s\n",
    "        k_1 = k_0 * tf.math.divide(r, 150e6) # km^2/s\n",
    "        k_2 = p # unitless, k_2 = p/p0 and p0 = 1 GeV/c\n",
    "        R = p # GV\n",
    "        beta = tf.math.divide(p, tf.math.sqrt(tf.math.square(p) + tf.math.square(m))) \n",
    "        k = beta*k_1*k_2\n",
    "        \n",
    "        # Calculate physics loss\n",
    "        # l_f = tf.math.reduce_mean(tf.math.abs(f_r + (tf.math.divide(R*V, 3*k) * f_p)))\n",
    "        l_f = tf.math.reduce_mean(tf.math.square(f_r + (tf.math.divide(R*V, 3*k) * f_p)))\n",
    "        \n",
    "        return l_f\n",
    "    \n",
    "    # tf_call passes inputs through the neural network\n",
    "    @tf.function\n",
    "    def tf_call(self, inputs): \n",
    "        return self.call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train neural network regularly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for epoch 0: pinn: 0.0459, boundary: 3821.9180, total: 175.5514\n",
      "Training loss for epoch 1: pinn: 0.0081, boundary: 3859.3451, total: 31.3832\n",
      "Training loss for epoch 2: pinn: 0.0024, boundary: 3877.8429, total: 9.3938\n",
      "Training loss for epoch 3: pinn: 0.0009, boundary: 3830.5006, total: 3.2884\n",
      "Training loss for epoch 4: pinn: 0.0003, boundary: 4160.3913, total: 1.3727\n",
      "Training loss for epoch 5: pinn: 0.0003, boundary: 3860.3238, total: 1.1227\n",
      "Training loss for epoch 6: pinn: 0.0002, boundary: 3914.5591, total: 0.7666\n",
      "Training loss for epoch 7: pinn: 0.0001, boundary: 3994.3073, total: 0.4195\n",
      "Training loss for epoch 8: pinn: 0.0001, boundary: 3792.7270, total: 0.3707\n",
      "Training loss for epoch 9: pinn: 0.0001, boundary: 3844.3299, total: 0.3022\n",
      "Training loss for epoch 10: pinn: 0.0000, boundary: 3892.6607, total: 0.1064\n",
      "Training loss for epoch 11: pinn: 0.0000, boundary: 3988.8987, total: 0.0290\n",
      "Training loss for epoch 12: pinn: 0.0000, boundary: 3843.8019, total: 0.0222\n",
      "Training loss for epoch 13: pinn: 0.0000, boundary: 3992.7278, total: 0.0528\n",
      "Training loss for epoch 14: pinn: 0.0000, boundary: 3836.1379, total: 0.0194\n",
      "Training loss for epoch 15: pinn: 0.0000, boundary: 3821.6335, total: 0.0361\n",
      "Training loss for epoch 16: pinn: 0.0000, boundary: 3931.7711, total: 0.0225\n",
      "Training loss for epoch 17: pinn: 0.0000, boundary: 3686.6295, total: 0.0047\n",
      "Training loss for epoch 18: pinn: 0.0000, boundary: 3747.7771, total: 0.0030\n",
      "Training loss for epoch 19: pinn: 0.0000, boundary: 3592.8097, total: 0.0094\n",
      "Training loss for epoch 20: pinn: 0.0000, boundary: 3945.2829, total: 0.0385\n",
      "Training loss for epoch 21: pinn: 0.0000, boundary: 3715.0535, total: 0.0281\n",
      "Training loss for epoch 22: pinn: 0.0000, boundary: 3715.3173, total: 0.0119\n",
      "Training loss for epoch 23: pinn: 0.0000, boundary: 3738.4174, total: 0.0057\n",
      "Training loss for epoch 24: pinn: 0.0000, boundary: 3943.8182, total: 0.0157\n",
      "Training loss for epoch 25: pinn: 0.0000, boundary: 3885.9039, total: 0.0138\n",
      "Training loss for epoch 26: pinn: 0.0000, boundary: 3821.2528, total: 0.0333\n",
      "Training loss for epoch 27: pinn: 0.0000, boundary: 3645.2346, total: 0.0038\n",
      "Training loss for epoch 28: pinn: 0.0000, boundary: 3859.3423, total: 0.0033\n",
      "Training loss for epoch 29: pinn: 0.0000, boundary: 3809.8970, total: 0.0032\n",
      "Training loss for epoch 30: pinn: 0.0000, boundary: 3772.1927, total: 0.0018\n",
      "Training loss for epoch 31: pinn: 0.0000, boundary: 3695.2305, total: 0.0051\n",
      "Training loss for epoch 32: pinn: 0.0000, boundary: 3912.0116, total: 0.0029\n",
      "Training loss for epoch 33: pinn: 0.0000, boundary: 3785.4865, total: 0.0009\n",
      "Training loss for epoch 34: pinn: 0.0000, boundary: 3834.3219, total: 0.0006\n",
      "Training loss for epoch 35: pinn: 0.0000, boundary: 3836.2719, total: 0.0016\n",
      "Training loss for epoch 36: pinn: 0.0000, boundary: 3824.3925, total: 0.0018\n",
      "Training loss for epoch 37: pinn: 0.0000, boundary: 3714.9712, total: 0.0006\n",
      "Training loss for epoch 38: pinn: 0.0000, boundary: 3754.4943, total: 0.0004\n",
      "Training loss for epoch 39: pinn: 0.0000, boundary: 3930.0859, total: 0.0004\n",
      "Training loss for epoch 40: pinn: 0.0000, boundary: 3860.9584, total: 0.0005\n",
      "Training loss for epoch 41: pinn: 0.0000, boundary: 3811.3824, total: 0.0006\n",
      "Training loss for epoch 42: pinn: 0.0000, boundary: 3855.6546, total: 0.0003\n",
      "Training loss for epoch 43: pinn: 0.0000, boundary: 3822.7781, total: 0.0000\n",
      "Training loss for epoch 44: pinn: 0.0000, boundary: 3972.0199, total: 0.0000\n",
      "Training loss for epoch 45: pinn: 0.0000, boundary: 3865.2502, total: 0.0000\n",
      "Training loss for epoch 46: pinn: 0.0000, boundary: 3869.5499, total: 0.0000\n",
      "Training loss for epoch 47: pinn: 0.0000, boundary: 3837.9624, total: 0.0000\n",
      "Training loss for epoch 48: pinn: 0.0000, boundary: 3774.1786, total: 0.0000\n",
      "Training loss for epoch 49: pinn: 0.0000, boundary: 3834.1257, total: 0.0000\n",
      "Training loss for epoch 50: pinn: 0.0000, boundary: 3924.3731, total: 0.0000\n",
      "Training loss for epoch 51: pinn: 0.0000, boundary: 3791.7865, total: 0.0000\n",
      "Training loss for epoch 52: pinn: 0.0000, boundary: 3815.5115, total: 0.0000\n",
      "Training loss for epoch 53: pinn: 0.0000, boundary: 3986.9136, total: 0.0000\n",
      "Training loss for epoch 54: pinn: 0.0000, boundary: 3945.8812, total: 0.0000\n",
      "Training loss for epoch 55: pinn: 0.0000, boundary: 3715.5857, total: 0.0000\n",
      "Training loss for epoch 56: pinn: 0.0000, boundary: 3880.3608, total: 0.0000\n",
      "Training loss for epoch 57: pinn: 0.0000, boundary: 4070.5587, total: 0.0000\n",
      "Training loss for epoch 58: pinn: 0.0000, boundary: 3952.5630, total: 0.0000\n",
      "Training loss for epoch 59: pinn: 0.0000, boundary: 3658.5840, total: 0.0000\n",
      "Training loss for epoch 60: pinn: 0.0000, boundary: 3953.8601, total: 0.0000\n",
      "Training loss for epoch 61: pinn: 0.0000, boundary: 3642.5722, total: 0.0000\n",
      "Training loss for epoch 62: pinn: 0.0000, boundary: 3843.0122, total: 0.0000\n",
      "Training loss for epoch 63: pinn: 0.0000, boundary: 3736.6911, total: 0.0000\n",
      "Training loss for epoch 64: pinn: 0.0000, boundary: 3916.2577, total: 0.0000\n",
      "Training loss for epoch 65: pinn: 0.0000, boundary: 3772.6312, total: 0.0000\n",
      "Training loss for epoch 66: pinn: 0.0000, boundary: 4017.3565, total: 0.0000\n",
      "Training loss for epoch 67: pinn: 0.0000, boundary: 3979.4017, total: 0.0000\n",
      "Training loss for epoch 68: pinn: 0.0000, boundary: 3775.4234, total: 0.0000\n",
      "Training loss for epoch 69: pinn: 0.0000, boundary: 3875.4929, total: 0.0000\n",
      "Training loss for epoch 70: pinn: 0.0000, boundary: 3760.8123, total: 0.0000\n",
      "Training loss for epoch 71: pinn: 0.0000, boundary: 3720.0614, total: 0.0000\n",
      "Training loss for epoch 72: pinn: 0.0000, boundary: 3834.5516, total: 0.0000\n",
      "Training loss for epoch 73: pinn: 0.0000, boundary: 3798.2845, total: 0.0000\n",
      "Training loss for epoch 74: pinn: 0.0000, boundary: 3959.8479, total: 0.0000\n",
      "Training loss for epoch 75: pinn: 0.0000, boundary: 3924.2779, total: 0.0000\n",
      "Training loss for epoch 76: pinn: 0.0000, boundary: 3902.8072, total: 0.0000\n",
      "Training loss for epoch 77: pinn: 0.0000, boundary: 3772.4695, total: 0.0000\n",
      "Training loss for epoch 78: pinn: 0.0000, boundary: 3833.3688, total: 0.0000\n",
      "Training loss for epoch 79: pinn: 0.0000, boundary: 3876.4143, total: 0.0000\n",
      "Training loss for epoch 80: pinn: 0.0000, boundary: 3899.8447, total: 0.0000\n",
      "Training loss for epoch 81: pinn: 0.0000, boundary: 3792.7155, total: 0.0000\n",
      "Training loss for epoch 82: pinn: 0.0000, boundary: 3731.5721, total: 0.0000\n",
      "Training loss for epoch 83: pinn: 0.0000, boundary: 3852.0630, total: 0.0000\n",
      "Training loss for epoch 84: pinn: 0.0000, boundary: 4079.9842, total: 0.0000\n",
      "Training loss for epoch 85: pinn: 0.0000, boundary: 3983.8273, total: 0.0000\n",
      "Training loss for epoch 86: pinn: 0.0000, boundary: 3832.3341, total: 0.0000\n",
      "Training loss for epoch 87: pinn: 0.0000, boundary: 4061.9020, total: 0.0000\n",
      "Training loss for epoch 88: pinn: 0.0000, boundary: 3966.8481, total: 0.0000\n",
      "Training loss for epoch 89: pinn: 0.0000, boundary: 3917.9742, total: 0.0000\n",
      "Training loss for epoch 90: pinn: 0.0000, boundary: 3764.0180, total: 0.0000\n",
      "Training loss for epoch 91: pinn: 0.0000, boundary: 3871.1265, total: 0.0000\n",
      "Training loss for epoch 92: pinn: 0.0000, boundary: 3884.4691, total: 0.0000\n",
      "Training loss for epoch 93: pinn: 0.0000, boundary: 3887.2131, total: 0.0000\n",
      "Training loss for epoch 94: pinn: 0.0000, boundary: 3864.9147, total: 0.0000\n",
      "Training loss for epoch 95: pinn: 0.0000, boundary: 3960.2581, total: 0.0000\n",
      "Training loss for epoch 96: pinn: 0.0000, boundary: 3786.0281, total: 0.0000\n",
      "Training loss for epoch 97: pinn: 0.0000, boundary: 3704.3929, total: 0.0000\n",
      "Training loss for epoch 98: pinn: 0.0000, boundary: 3684.5634, total: 0.0000\n",
      "Training loss for epoch 99: pinn: 0.0000, boundary: 3906.6503, total: 0.0000\n",
      "Training loss for epoch 100: pinn: 0.0000, boundary: 3971.8592, total: 0.0000\n",
      "Training loss for epoch 101: pinn: 0.0000, boundary: 3775.1638, total: 0.0000\n",
      "Training loss for epoch 102: pinn: 0.0000, boundary: 3965.0605, total: 0.0000\n",
      "Training loss for epoch 103: pinn: 0.0000, boundary: 3856.6208, total: 0.0000\n",
      "Training loss for epoch 104: pinn: 0.0000, boundary: 3733.4692, total: 0.0000\n",
      "Training loss for epoch 105: pinn: 0.0000, boundary: 4051.5969, total: 0.0000\n",
      "Training loss for epoch 106: pinn: 0.0000, boundary: 3858.7253, total: 0.0000\n",
      "Training loss for epoch 107: pinn: 0.0000, boundary: 4025.2379, total: 0.0000\n",
      "Training loss for epoch 108: pinn: 0.0000, boundary: 4002.5505, total: 0.0000\n",
      "Training loss for epoch 109: pinn: 0.0000, boundary: 3944.2092, total: 0.0000\n",
      "Training loss for epoch 110: pinn: 0.0000, boundary: 3819.6809, total: 0.0000\n",
      "Training loss for epoch 111: pinn: 0.0000, boundary: 3997.0497, total: 0.0000\n",
      "Training loss for epoch 112: pinn: 0.0000, boundary: 4015.7418, total: 0.0000\n",
      "Training loss for epoch 113: pinn: 0.0000, boundary: 3831.2262, total: 0.0000\n",
      "Training loss for epoch 114: pinn: 0.0000, boundary: 4063.7901, total: 0.0000\n",
      "Training loss for epoch 115: pinn: 0.0000, boundary: 3908.1353, total: 0.0000\n",
      "Training loss for epoch 116: pinn: 0.0000, boundary: 3778.4748, total: 0.0000\n",
      "Training loss for epoch 117: pinn: 0.0000, boundary: 3859.8599, total: 0.0000\n",
      "Training loss for epoch 118: pinn: 0.0000, boundary: 4009.2217, total: 0.0000\n",
      "Training loss for epoch 119: pinn: 0.0000, boundary: 3937.2847, total: 0.0000\n",
      "Training loss for epoch 120: pinn: 0.0000, boundary: 3772.1082, total: 0.0000\n",
      "Training loss for epoch 121: pinn: 0.0000, boundary: 4007.0457, total: 0.0000\n",
      "Training loss for epoch 122: pinn: 0.0000, boundary: 3712.7320, total: 0.0000\n",
      "Training loss for epoch 123: pinn: 0.0000, boundary: 3886.5076, total: 0.0000\n",
      "Training loss for epoch 124: pinn: 0.0000, boundary: 3712.8500, total: 0.0000\n",
      "Training loss for epoch 125: pinn: 0.0000, boundary: 3889.8808, total: 0.0000\n",
      "Training loss for epoch 126: pinn: 0.0000, boundary: 3936.4969, total: 0.0000\n",
      "Training loss for epoch 127: pinn: 0.0000, boundary: 3763.1231, total: 0.0000\n",
      "Training loss for epoch 128: pinn: 0.0000, boundary: 3847.8121, total: 0.0000\n",
      "Training loss for epoch 129: pinn: 0.0000, boundary: 3734.7437, total: 0.0000\n",
      "Training loss for epoch 130: pinn: 0.0000, boundary: 3965.0949, total: 0.0000\n",
      "Training loss for epoch 131: pinn: 0.0000, boundary: 3891.1916, total: 0.0000\n",
      "Training loss for epoch 132: pinn: 0.0000, boundary: 3844.3714, total: 0.0000\n",
      "Training loss for epoch 133: pinn: 0.0000, boundary: 3810.0197, total: 0.0000\n",
      "Training loss for epoch 134: pinn: 0.0000, boundary: 3929.3418, total: 0.0000\n",
      "Training loss for epoch 135: pinn: 0.0000, boundary: 3925.2158, total: 0.0000\n",
      "Training loss for epoch 136: pinn: 0.0000, boundary: 3967.2045, total: 0.0000\n",
      "Training loss for epoch 137: pinn: 0.0000, boundary: 3781.4634, total: 0.0000\n",
      "Training loss for epoch 138: pinn: 0.0000, boundary: 4040.9866, total: 0.0000\n",
      "Training loss for epoch 139: pinn: 0.0000, boundary: 3937.9527, total: 0.0000\n",
      "Training loss for epoch 140: pinn: 0.0000, boundary: 3878.6894, total: 0.0000\n",
      "Training loss for epoch 141: pinn: 0.0000, boundary: 3885.3297, total: 0.0000\n",
      "Training loss for epoch 142: pinn: 0.0000, boundary: 3929.1024, total: 0.0000\n",
      "Training loss for epoch 143: pinn: 0.0000, boundary: 4058.4980, total: 0.0000\n",
      "Training loss for epoch 144: pinn: 0.0000, boundary: 4014.6085, total: 0.0000\n",
      "Training loss for epoch 145: pinn: 0.0000, boundary: 3864.8012, total: 0.0000\n",
      "Training loss for epoch 146: pinn: 0.0000, boundary: 3837.7616, total: 0.0000\n",
      "Training loss for epoch 147: pinn: 0.0000, boundary: 3934.4386, total: 0.0000\n",
      "Training loss for epoch 148: pinn: 0.0000, boundary: 4089.2699, total: 0.0000\n",
      "Training loss for epoch 149: pinn: 0.0000, boundary: 3907.8713, total: 0.0000\n",
      "Training loss for epoch 150: pinn: 0.0000, boundary: 3835.7501, total: 0.0000\n",
      "Training loss for epoch 151: pinn: 0.0000, boundary: 3926.4990, total: 0.0000\n",
      "Training loss for epoch 152: pinn: 0.0000, boundary: 3841.6952, total: 0.0000\n",
      "Training loss for epoch 153: pinn: 0.0000, boundary: 3611.4998, total: 0.0000\n",
      "Training loss for epoch 154: pinn: 0.0000, boundary: 3867.8413, total: 0.0000\n",
      "Training loss for epoch 155: pinn: 0.0000, boundary: 3900.6561, total: 0.0000\n",
      "Training loss for epoch 156: pinn: 0.0000, boundary: 3968.9649, total: 0.0000\n",
      "Training loss for epoch 157: pinn: 0.0000, boundary: 4006.0625, total: 0.0000\n",
      "Training loss for epoch 158: pinn: 0.0000, boundary: 3934.3338, total: 0.0000\n",
      "Training loss for epoch 159: pinn: 0.0000, boundary: 3949.3051, total: 0.0000\n",
      "Training loss for epoch 160: pinn: 0.0000, boundary: 3867.9136, total: 0.0000\n",
      "Training loss for epoch 161: pinn: 0.0000, boundary: 3802.7558, total: 0.0000\n",
      "Training loss for epoch 162: pinn: 0.0000, boundary: 3928.0044, total: 0.0000\n",
      "Training loss for epoch 163: pinn: 0.0000, boundary: 3846.5721, total: 0.0000\n",
      "Training loss for epoch 164: pinn: 0.0000, boundary: 3941.6233, total: 0.0000\n",
      "Training loss for epoch 165: pinn: 0.0000, boundary: 3906.9675, total: 0.0000\n",
      "Training loss for epoch 166: pinn: 0.0000, boundary: 3805.8726, total: 0.0000\n",
      "Training loss for epoch 167: pinn: 0.0000, boundary: 3926.9511, total: 0.0000\n",
      "Training loss for epoch 168: pinn: 0.0000, boundary: 4012.8548, total: 0.0000\n",
      "Training loss for epoch 169: pinn: 0.0000, boundary: 3926.3470, total: 0.0000\n",
      "Training loss for epoch 170: pinn: 0.0000, boundary: 3829.0610, total: 0.0000\n",
      "Training loss for epoch 171: pinn: 0.0000, boundary: 3650.1445, total: 0.0000\n",
      "Training loss for epoch 172: pinn: 0.0000, boundary: 3778.1929, total: 0.0000\n",
      "Training loss for epoch 173: pinn: 0.0000, boundary: 3873.8026, total: 0.0000\n",
      "Training loss for epoch 174: pinn: 0.0000, boundary: 3839.1730, total: 0.0000\n",
      "Training loss for epoch 175: pinn: 0.0000, boundary: 3890.1894, total: 0.0000\n",
      "Training loss for epoch 176: pinn: 0.0000, boundary: 3953.4659, total: 0.0000\n",
      "Training loss for epoch 177: pinn: 0.0000, boundary: 3808.4745, total: 0.0000\n",
      "Training loss for epoch 178: pinn: 0.0000, boundary: 3983.2268, total: 0.0000\n",
      "Training loss for epoch 179: pinn: 0.0000, boundary: 3768.6646, total: 0.0000\n",
      "Training loss for epoch 180: pinn: 0.0000, boundary: 3816.7439, total: 0.0000\n",
      "Training loss for epoch 181: pinn: 0.0000, boundary: 3910.3912, total: 0.0000\n",
      "Training loss for epoch 182: pinn: 0.0000, boundary: 3970.1211, total: 0.0000\n",
      "Training loss for epoch 183: pinn: 0.0000, boundary: 3892.1194, total: 0.0000\n",
      "Training loss for epoch 184: pinn: 0.0000, boundary: 3751.2505, total: 0.0000\n",
      "Training loss for epoch 185: pinn: 0.0000, boundary: 3857.4333, total: 0.0000\n",
      "Training loss for epoch 186: pinn: 0.0000, boundary: 3816.5343, total: 0.0000\n",
      "Training loss for epoch 187: pinn: 0.0000, boundary: 3772.5457, total: 0.0000\n",
      "Training loss for epoch 188: pinn: 0.0000, boundary: 3851.6649, total: 0.0000\n",
      "Training loss for epoch 189: pinn: 0.0000, boundary: 3830.7295, total: 0.0000\n",
      "Training loss for epoch 190: pinn: 0.0000, boundary: 3619.9561, total: 0.0000\n",
      "Training loss for epoch 191: pinn: 0.0000, boundary: 3845.4320, total: 0.0000\n",
      "Training loss for epoch 192: pinn: 0.0000, boundary: 3877.1806, total: 0.0000\n",
      "Training loss for epoch 193: pinn: 0.0000, boundary: 3761.9039, total: 0.0000\n",
      "Training loss for epoch 194: pinn: 0.0000, boundary: 3838.1010, total: 0.0000\n",
      "Training loss for epoch 195: pinn: 0.0000, boundary: 3905.0206, total: 0.0000\n",
      "Training loss for epoch 196: pinn: 0.0000, boundary: 3840.5359, total: 0.0000\n",
      "Training loss for epoch 197: pinn: 0.0000, boundary: 3848.7097, total: 0.0000\n",
      "Training loss for epoch 198: pinn: 0.0000, boundary: 3843.3770, total: 0.0000\n",
      "Training loss for epoch 199: pinn: 0.0000, boundary: 4076.1558, total: 0.0000\n",
      "Training loss for epoch 200: pinn: 0.0000, boundary: 3905.3773, total: 0.0000\n",
      "Training loss for epoch 201: pinn: 0.0000, boundary: 3962.7432, total: 0.0000\n",
      "Training loss for epoch 202: pinn: 0.0000, boundary: 3805.6865, total: 0.0000\n",
      "Training loss for epoch 203: pinn: 0.0000, boundary: 3985.4062, total: 0.0000\n",
      "Training loss for epoch 204: pinn: 0.0000, boundary: 3715.3134, total: 0.0000\n",
      "Training loss for epoch 205: pinn: 0.0000, boundary: 3829.4839, total: 0.0000\n",
      "Training loss for epoch 206: pinn: 0.0000, boundary: 3811.0202, total: 0.0000\n",
      "Training loss for epoch 207: pinn: 0.0000, boundary: 3820.3698, total: 0.0000\n",
      "Training loss for epoch 208: pinn: 0.0000, boundary: 3900.8411, total: 0.0000\n",
      "Training loss for epoch 209: pinn: 0.0000, boundary: 3815.6219, total: 0.0000\n",
      "Training loss for epoch 210: pinn: 0.0000, boundary: 3848.6441, total: 0.0000\n",
      "Training loss for epoch 211: pinn: 0.0000, boundary: 3887.7856, total: 0.0000\n",
      "Training loss for epoch 212: pinn: 0.0000, boundary: 3883.6462, total: 0.0000\n",
      "Training loss for epoch 213: pinn: 0.0000, boundary: 3941.4878, total: 0.0000\n",
      "Training loss for epoch 214: pinn: 0.0000, boundary: 3858.1164, total: 0.0000\n",
      "Training loss for epoch 215: pinn: 0.0000, boundary: 3814.8057, total: 0.0000\n",
      "Training loss for epoch 216: pinn: 0.0000, boundary: 4010.9436, total: 0.0000\n",
      "Training loss for epoch 217: pinn: 0.0000, boundary: 3820.1846, total: 0.0000\n",
      "Training loss for epoch 218: pinn: 0.0000, boundary: 3901.3316, total: 0.0000\n",
      "Training loss for epoch 219: pinn: 0.0000, boundary: 3890.2158, total: 0.0000\n",
      "Training loss for epoch 220: pinn: 0.0000, boundary: 3842.2818, total: 0.0000\n",
      "Training loss for epoch 221: pinn: 0.0000, boundary: 3919.1597, total: 0.0000\n",
      "Training loss for epoch 222: pinn: 0.0000, boundary: 3869.0084, total: 0.0000\n",
      "Training loss for epoch 223: pinn: 0.0000, boundary: 3873.8659, total: 0.0000\n",
      "Training loss for epoch 224: pinn: 0.0000, boundary: 4021.9223, total: 0.0000\n",
      "Training loss for epoch 225: pinn: 0.0000, boundary: 3877.9877, total: 0.0000\n",
      "Training loss for epoch 226: pinn: 0.0000, boundary: 3701.2708, total: 0.0000\n",
      "Training loss for epoch 227: pinn: 0.0000, boundary: 3974.8757, total: 0.0000\n",
      "Training loss for epoch 228: pinn: 0.0000, boundary: 3678.0914, total: 0.0000\n",
      "Training loss for epoch 229: pinn: 0.0000, boundary: 3724.0072, total: 0.0000\n",
      "Training loss for epoch 230: pinn: 0.0000, boundary: 3833.7632, total: 0.0000\n",
      "Training loss for epoch 231: pinn: 0.0000, boundary: 3942.2890, total: 0.0000\n",
      "Training loss for epoch 232: pinn: 0.0000, boundary: 3789.0284, total: 0.0000\n",
      "Training loss for epoch 233: pinn: 0.0000, boundary: 3703.5076, total: 0.0000\n",
      "Training loss for epoch 234: pinn: 0.0000, boundary: 3936.2483, total: 0.0000\n",
      "Training loss for epoch 235: pinn: 0.0000, boundary: 3823.4254, total: 0.0000\n",
      "Training loss for epoch 236: pinn: 0.0000, boundary: 3862.4957, total: 0.0000\n",
      "Training loss for epoch 237: pinn: 0.0000, boundary: 3987.4090, total: 0.0000\n",
      "Training loss for epoch 238: pinn: 0.0000, boundary: 3927.2345, total: 0.0000\n",
      "Training loss for epoch 239: pinn: 0.0000, boundary: 3790.5165, total: 0.0000\n",
      "Training loss for epoch 240: pinn: 0.0000, boundary: 3891.7175, total: 0.0000\n",
      "Training loss for epoch 241: pinn: 0.0000, boundary: 4030.2895, total: 0.0000\n",
      "Training loss for epoch 242: pinn: 0.0000, boundary: 3827.9853, total: 0.0000\n",
      "Training loss for epoch 243: pinn: 0.0000, boundary: 3823.1808, total: 0.0000\n",
      "Training loss for epoch 244: pinn: 0.0000, boundary: 3906.5704, total: 0.0000\n",
      "Training loss for epoch 245: pinn: 0.0000, boundary: 4077.3091, total: 0.0000\n",
      "Training loss for epoch 246: pinn: 0.0000, boundary: 3786.2478, total: 0.0000\n",
      "Training loss for epoch 247: pinn: 0.0000, boundary: 3739.1825, total: 0.0000\n",
      "Training loss for epoch 248: pinn: 0.0000, boundary: 3897.0600, total: 0.0000\n",
      "Training loss for epoch 249: pinn: 0.0000, boundary: 3762.9144, total: 0.0000\n",
      "Training loss for epoch 250: pinn: 0.0000, boundary: 3787.6760, total: 0.0000\n",
      "Training loss for epoch 251: pinn: 0.0000, boundary: 3836.3992, total: 0.0000\n",
      "Training loss for epoch 252: pinn: 0.0000, boundary: 3760.1378, total: 0.0000\n",
      "Training loss for epoch 253: pinn: 0.0000, boundary: 4056.7080, total: 0.0000\n",
      "Training loss for epoch 254: pinn: 0.0000, boundary: 3898.9627, total: 0.0000\n",
      "Training loss for epoch 255: pinn: 0.0000, boundary: 3968.8398, total: 0.0000\n",
      "Training loss for epoch 256: pinn: 0.0000, boundary: 4099.7452, total: 0.0000\n",
      "Training loss for epoch 257: pinn: 0.0000, boundary: 3899.3842, total: 0.0000\n",
      "Training loss for epoch 258: pinn: 0.0000, boundary: 3996.6758, total: 0.0000\n",
      "Training loss for epoch 259: pinn: 0.0000, boundary: 3978.0717, total: 0.0000\n",
      "Training loss for epoch 260: pinn: 0.0000, boundary: 3906.6849, total: 0.0000\n",
      "Training loss for epoch 261: pinn: 0.0000, boundary: 3880.6252, total: 0.0000\n",
      "Training loss for epoch 262: pinn: 0.0000, boundary: 3832.6238, total: 0.0000\n",
      "Training loss for epoch 263: pinn: 0.0000, boundary: 4036.4233, total: 0.0000\n",
      "Training loss for epoch 264: pinn: 0.0000, boundary: 3820.2055, total: 0.0000\n",
      "Training loss for epoch 265: pinn: 0.0000, boundary: 3902.7582, total: 0.0000\n",
      "Training loss for epoch 266: pinn: 0.0000, boundary: 3976.6888, total: 0.0000\n",
      "Training loss for epoch 267: pinn: 0.0000, boundary: 3777.8138, total: 0.0000\n",
      "Training loss for epoch 268: pinn: 0.0000, boundary: 3883.7389, total: 0.0000\n",
      "Training loss for epoch 269: pinn: 0.0000, boundary: 3921.1739, total: 0.0000\n",
      "Training loss for epoch 270: pinn: 0.0000, boundary: 3859.2156, total: 0.0000\n",
      "Training loss for epoch 271: pinn: 0.0000, boundary: 4027.4403, total: 0.0000\n",
      "Training loss for epoch 272: pinn: 0.0000, boundary: 4001.2194, total: 0.0000\n",
      "Training loss for epoch 273: pinn: 0.0000, boundary: 3996.7675, total: 0.0000\n",
      "Training loss for epoch 274: pinn: 0.0000, boundary: 3862.9987, total: 0.0000\n",
      "Training loss for epoch 275: pinn: 0.0000, boundary: 3914.1977, total: 0.0000\n",
      "Training loss for epoch 276: pinn: 0.0000, boundary: 3871.5146, total: 0.0000\n",
      "Training loss for epoch 277: pinn: 0.0000, boundary: 3900.1709, total: 0.0000\n",
      "Training loss for epoch 278: pinn: 0.0000, boundary: 3658.5383, total: 0.0000\n",
      "Training loss for epoch 279: pinn: 0.0000, boundary: 3914.5912, total: 0.0000\n",
      "Training loss for epoch 280: pinn: 0.0000, boundary: 3768.1162, total: 0.0000\n",
      "Training loss for epoch 281: pinn: 0.0000, boundary: 3901.6732, total: 0.0000\n",
      "Training loss for epoch 282: pinn: 0.0000, boundary: 3889.2967, total: 0.0000\n",
      "Training loss for epoch 283: pinn: 0.0000, boundary: 3979.9605, total: 0.0000\n",
      "Training loss for epoch 284: pinn: 0.0000, boundary: 3848.3944, total: 0.0000\n",
      "Training loss for epoch 285: pinn: 0.0000, boundary: 3829.1063, total: 0.0000\n",
      "Training loss for epoch 286: pinn: 0.0000, boundary: 3908.0975, total: 0.0000\n",
      "Training loss for epoch 287: pinn: 0.0000, boundary: 3875.4948, total: 0.0000\n",
      "Training loss for epoch 288: pinn: 0.0000, boundary: 3744.8534, total: 0.0000\n",
      "Training loss for epoch 289: pinn: 0.0000, boundary: 3987.9740, total: 0.0000\n",
      "Training loss for epoch 290: pinn: 0.0000, boundary: 4048.4592, total: 0.0000\n",
      "Training loss for epoch 291: pinn: 0.0000, boundary: 3853.2104, total: 0.0000\n",
      "Training loss for epoch 292: pinn: 0.0000, boundary: 3823.3839, total: 0.0000\n",
      "Training loss for epoch 293: pinn: 0.0000, boundary: 3920.4379, total: 0.0000\n",
      "Training loss for epoch 294: pinn: 0.0000, boundary: 3912.1286, total: 0.0000\n",
      "Training loss for epoch 295: pinn: 0.0000, boundary: 3911.0469, total: 0.0000\n",
      "Training loss for epoch 296: pinn: 0.0000, boundary: 3806.3404, total: 0.0000\n",
      "Training loss for epoch 297: pinn: 0.0000, boundary: 3750.2801, total: 0.0000\n",
      "Training loss for epoch 298: pinn: 0.0000, boundary: 3951.7433, total: 0.0000\n",
      "Training loss for epoch 299: pinn: 0.0000, boundary: 3935.2401, total: 0.0000\n",
      "Training loss for epoch 300: pinn: 0.0000, boundary: 3853.6581, total: 0.0000\n",
      "Training loss for epoch 301: pinn: 0.0000, boundary: 3859.1311, total: 0.0000\n",
      "Training loss for epoch 302: pinn: 0.0000, boundary: 3685.4531, total: 0.0000\n",
      "Training loss for epoch 303: pinn: 0.0000, boundary: 3930.2954, total: 0.0000\n",
      "Training loss for epoch 304: pinn: 0.0000, boundary: 3962.0358, total: 0.0000\n",
      "Training loss for epoch 305: pinn: 0.0000, boundary: 3886.9082, total: 0.0000\n",
      "Training loss for epoch 306: pinn: 0.0000, boundary: 3843.9703, total: 0.0000\n",
      "Training loss for epoch 307: pinn: 0.0000, boundary: 3848.6343, total: 0.0000\n",
      "Training loss for epoch 308: pinn: 0.0000, boundary: 3838.2647, total: 0.0000\n",
      "Training loss for epoch 309: pinn: 0.0000, boundary: 3915.8276, total: 0.0000\n",
      "Training loss for epoch 310: pinn: 0.0000, boundary: 3887.0730, total: 0.0000\n",
      "Training loss for epoch 311: pinn: 0.0000, boundary: 3932.0707, total: 0.0000\n",
      "Training loss for epoch 312: pinn: 0.0000, boundary: 3860.1412, total: 0.0000\n",
      "Training loss for epoch 313: pinn: 0.0000, boundary: 3959.0222, total: 0.0000\n",
      "Training loss for epoch 314: pinn: 0.0000, boundary: 3791.5276, total: 0.0000\n",
      "Training loss for epoch 315: pinn: 0.0000, boundary: 3890.6290, total: 0.0000\n",
      "Training loss for epoch 316: pinn: 0.0000, boundary: 3903.4407, total: 0.0000\n",
      "Training loss for epoch 317: pinn: 0.0000, boundary: 4110.5536, total: 0.0000\n",
      "Training loss for epoch 318: pinn: 0.0000, boundary: 3929.0152, total: 0.0000\n",
      "Training loss for epoch 319: pinn: 0.0000, boundary: 3955.0844, total: 0.0000\n",
      "Training loss for epoch 320: pinn: 0.0000, boundary: 4046.5519, total: 0.0000\n",
      "Training loss for epoch 321: pinn: 0.0000, boundary: 3674.1481, total: 0.0000\n",
      "Training loss for epoch 322: pinn: 0.0000, boundary: 4005.2785, total: 0.0000\n",
      "Training loss for epoch 323: pinn: 0.0000, boundary: 3752.1569, total: 0.0000\n",
      "Training loss for epoch 324: pinn: 0.0000, boundary: 3903.3828, total: 0.0000\n",
      "Training loss for epoch 325: pinn: 0.0000, boundary: 3962.6559, total: 0.0000\n",
      "Training loss for epoch 326: pinn: 0.0000, boundary: 3970.2005, total: 0.0000\n",
      "Training loss for epoch 327: pinn: 0.0000, boundary: 3884.2597, total: 0.0000\n",
      "Training loss for epoch 328: pinn: 0.0000, boundary: 4151.2878, total: 0.0000\n",
      "Training loss for epoch 329: pinn: 0.0000, boundary: 3983.4739, total: 0.0000\n",
      "Training loss for epoch 330: pinn: 0.0000, boundary: 3871.1764, total: 0.0000\n",
      "Training loss for epoch 331: pinn: 0.0000, boundary: 4063.9217, total: 0.0000\n",
      "Training loss for epoch 332: pinn: 0.0000, boundary: 3871.6650, total: 0.0000\n",
      "Training loss for epoch 333: pinn: 0.0000, boundary: 3826.4168, total: 0.0000\n",
      "Training loss for epoch 334: pinn: 0.0000, boundary: 3790.4720, total: 0.0000\n",
      "Training loss for epoch 335: pinn: 0.0000, boundary: 3876.2031, total: 0.0000\n",
      "Training loss for epoch 336: pinn: 0.0000, boundary: 3962.2475, total: 0.0000\n",
      "Training loss for epoch 337: pinn: 0.0000, boundary: 3766.2146, total: 0.0000\n",
      "Training loss for epoch 338: pinn: 0.0000, boundary: 3936.3764, total: 0.0000\n",
      "Training loss for epoch 339: pinn: 0.0000, boundary: 3752.4600, total: 0.0000\n",
      "Training loss for epoch 340: pinn: 0.0000, boundary: 3897.2918, total: 0.0000\n",
      "Training loss for epoch 341: pinn: 0.0000, boundary: 3940.6039, total: 0.0000\n",
      "Training loss for epoch 342: pinn: 0.0000, boundary: 3852.8067, total: 0.0000\n",
      "Training loss for epoch 343: pinn: 0.0000, boundary: 3922.6852, total: 0.0000\n",
      "Training loss for epoch 344: pinn: 0.0000, boundary: 3841.5494, total: 0.0000\n",
      "Training loss for epoch 345: pinn: 0.0000, boundary: 3835.4002, total: 0.0000\n",
      "Training loss for epoch 346: pinn: 0.0000, boundary: 3807.3218, total: 0.0000\n",
      "Training loss for epoch 347: pinn: 0.0000, boundary: 3747.1136, total: 0.0000\n",
      "Training loss for epoch 348: pinn: 0.0000, boundary: 3871.3019, total: 0.0000\n",
      "Training loss for epoch 349: pinn: 0.0000, boundary: 3961.8947, total: 0.0000\n",
      "Training loss for epoch 350: pinn: 0.0000, boundary: 3970.4175, total: 0.0000\n",
      "Training loss for epoch 351: pinn: 0.0000, boundary: 3919.3248, total: 0.0000\n",
      "Training loss for epoch 352: pinn: 0.0000, boundary: 3870.7367, total: 0.0000\n",
      "Training loss for epoch 353: pinn: 0.0000, boundary: 3767.2393, total: 0.0000\n",
      "Training loss for epoch 354: pinn: 0.0000, boundary: 3808.6131, total: 0.0000\n",
      "Training loss for epoch 355: pinn: 0.0000, boundary: 3989.8476, total: 0.0000\n",
      "Training loss for epoch 356: pinn: 0.0000, boundary: 3809.5492, total: 0.0000\n",
      "Training loss for epoch 357: pinn: 0.0000, boundary: 3970.1512, total: 0.0000\n",
      "Training loss for epoch 358: pinn: 0.0000, boundary: 3908.7358, total: 0.0000\n",
      "Training loss for epoch 359: pinn: 0.0000, boundary: 3998.6620, total: 0.0000\n",
      "Training loss for epoch 360: pinn: 0.0000, boundary: 3943.5788, total: 0.0000\n",
      "Training loss for epoch 361: pinn: 0.0000, boundary: 3952.8958, total: 0.0000\n",
      "Training loss for epoch 362: pinn: 0.0000, boundary: 4043.6898, total: 0.0000\n",
      "Training loss for epoch 363: pinn: 0.0000, boundary: 3904.8652, total: 0.0000\n",
      "Training loss for epoch 364: pinn: 0.0000, boundary: 3829.2512, total: 0.0000\n",
      "Training loss for epoch 365: pinn: 0.0000, boundary: 3866.7823, total: 0.0000\n",
      "Training loss for epoch 366: pinn: 0.0000, boundary: 3913.3905, total: 0.0000\n",
      "Training loss for epoch 367: pinn: 0.0000, boundary: 3972.8509, total: 0.0000\n",
      "Training loss for epoch 368: pinn: 0.0000, boundary: 4066.9498, total: 0.0000\n",
      "Training loss for epoch 369: pinn: 0.0000, boundary: 3884.6922, total: 0.0000\n",
      "Training loss for epoch 370: pinn: 0.0000, boundary: 3671.2721, total: 0.0000\n",
      "Training loss for epoch 371: pinn: 0.0000, boundary: 3846.2918, total: 0.0000\n",
      "Training loss for epoch 372: pinn: 0.0000, boundary: 3626.2968, total: 0.0000\n",
      "Training loss for epoch 373: pinn: 0.0000, boundary: 3783.1059, total: 0.0000\n",
      "Training loss for epoch 374: pinn: 0.0000, boundary: 3896.0094, total: 0.0000\n",
      "Training loss for epoch 375: pinn: 0.0000, boundary: 3947.5257, total: 0.0000\n",
      "Training loss for epoch 376: pinn: 0.0000, boundary: 3876.3588, total: 0.0000\n",
      "Training loss for epoch 377: pinn: 0.0000, boundary: 3916.5772, total: 0.0000\n",
      "Training loss for epoch 378: pinn: 0.0000, boundary: 3856.6117, total: 0.0000\n",
      "Training loss for epoch 379: pinn: 0.0000, boundary: 3837.0612, total: 0.0000\n",
      "Training loss for epoch 380: pinn: 0.0000, boundary: 4000.0940, total: 0.0000\n",
      "Training loss for epoch 381: pinn: 0.0000, boundary: 3883.4322, total: 0.0000\n",
      "Training loss for epoch 382: pinn: 0.0000, boundary: 4053.5019, total: 0.0000\n",
      "Training loss for epoch 383: pinn: 0.0000, boundary: 4084.5204, total: 0.0000\n",
      "Training loss for epoch 384: pinn: 0.0000, boundary: 3763.5778, total: 0.0000\n",
      "Training loss for epoch 385: pinn: 0.0000, boundary: 3968.1113, total: 0.0000\n",
      "Training loss for epoch 386: pinn: 0.0000, boundary: 4101.2580, total: 0.0000\n",
      "Training loss for epoch 387: pinn: 0.0000, boundary: 4002.7280, total: 0.0000\n",
      "Training loss for epoch 388: pinn: 0.0000, boundary: 3639.0643, total: 0.0000\n",
      "Training loss for epoch 389: pinn: 0.0000, boundary: 3892.3946, total: 0.0000\n",
      "Training loss for epoch 390: pinn: 0.0000, boundary: 4026.7151, total: 0.0000\n",
      "Training loss for epoch 391: pinn: 0.0000, boundary: 3846.7073, total: 0.0000\n",
      "Training loss for epoch 392: pinn: 0.0000, boundary: 3730.1089, total: 0.0000\n",
      "Training loss for epoch 393: pinn: 0.0000, boundary: 3758.1233, total: 0.0000\n",
      "Training loss for epoch 394: pinn: 0.0000, boundary: 3864.0266, total: 0.0000\n",
      "Training loss for epoch 395: pinn: 0.0000, boundary: 3683.6248, total: 0.0000\n",
      "Training loss for epoch 396: pinn: 0.0000, boundary: 3777.6317, total: 0.0000\n",
      "Training loss for epoch 397: pinn: 0.0000, boundary: 3661.7372, total: 0.0000\n",
      "Training loss for epoch 398: pinn: 0.0000, boundary: 3874.3063, total: 0.0000\n",
      "Training loss for epoch 399: pinn: 0.0000, boundary: 3898.1153, total: 0.0000\n",
      "Training loss for epoch 400: pinn: 0.0000, boundary: 3913.6095, total: 0.0000\n",
      "Training loss for epoch 401: pinn: 0.0000, boundary: 4016.9899, total: 0.0000\n",
      "Training loss for epoch 402: pinn: 0.0000, boundary: 3888.9016, total: 0.0000\n",
      "Training loss for epoch 403: pinn: 0.0000, boundary: 4014.6886, total: 0.0000\n",
      "Training loss for epoch 404: pinn: 0.0000, boundary: 3746.1744, total: 0.0000\n",
      "Training loss for epoch 405: pinn: 0.0000, boundary: 3758.1113, total: 0.0000\n",
      "Training loss for epoch 406: pinn: 0.0000, boundary: 3891.7279, total: 0.0000\n",
      "Training loss for epoch 407: pinn: 0.0000, boundary: 3950.2383, total: 0.0000\n",
      "Training loss for epoch 408: pinn: 0.0000, boundary: 3869.1925, total: 0.0000\n",
      "Training loss for epoch 409: pinn: 0.0000, boundary: 3963.0953, total: 0.0000\n",
      "Training loss for epoch 410: pinn: 0.0000, boundary: 3756.0678, total: 0.0000\n",
      "Training loss for epoch 411: pinn: 0.0000, boundary: 3868.6396, total: 0.0000\n",
      "Training loss for epoch 412: pinn: 0.0000, boundary: 3762.2200, total: 0.0000\n",
      "Training loss for epoch 413: pinn: 0.0000, boundary: 3911.8532, total: 0.0000\n",
      "Training loss for epoch 414: pinn: 0.0000, boundary: 3879.7970, total: 0.0000\n",
      "Training loss for epoch 415: pinn: 0.0000, boundary: 4054.1759, total: 0.0000\n",
      "Training loss for epoch 416: pinn: 0.0000, boundary: 3958.5664, total: 0.0000\n",
      "Training loss for epoch 417: pinn: 0.0000, boundary: 3990.1108, total: 0.0000\n",
      "Training loss for epoch 418: pinn: 0.0000, boundary: 3744.5160, total: 0.0000\n",
      "Training loss for epoch 419: pinn: 0.0000, boundary: 3994.9839, total: 0.0000\n",
      "Training loss for epoch 420: pinn: 0.0000, boundary: 4107.5046, total: 0.0000\n",
      "Training loss for epoch 421: pinn: 0.0000, boundary: 4029.6005, total: 0.0000\n",
      "Training loss for epoch 422: pinn: 0.0000, boundary: 3851.4978, total: 0.0000\n",
      "Training loss for epoch 423: pinn: 0.0000, boundary: 3936.9779, total: 0.0000\n",
      "Training loss for epoch 424: pinn: 0.0000, boundary: 3802.7165, total: 0.0000\n",
      "Training loss for epoch 425: pinn: 0.0000, boundary: 3950.5258, total: 0.0000\n",
      "Training loss for epoch 426: pinn: 0.0000, boundary: 3894.8988, total: 0.0000\n",
      "Training loss for epoch 427: pinn: 0.0000, boundary: 3844.2604, total: 0.0000\n",
      "Training loss for epoch 428: pinn: 0.0000, boundary: 3981.5222, total: 0.0000\n",
      "Training loss for epoch 429: pinn: 0.0000, boundary: 3840.6453, total: 0.0000\n",
      "Training loss for epoch 430: pinn: 0.0000, boundary: 4021.6187, total: 0.0000\n",
      "Training loss for epoch 431: pinn: 0.0000, boundary: 3871.9154, total: 0.0000\n",
      "Training loss for epoch 432: pinn: 0.0000, boundary: 3928.0928, total: 0.0000\n",
      "Training loss for epoch 433: pinn: 0.0000, boundary: 3840.0327, total: 0.0000\n",
      "Training loss for epoch 434: pinn: 0.0000, boundary: 3857.2648, total: 0.0000\n",
      "Training loss for epoch 435: pinn: 0.0000, boundary: 3818.8164, total: 0.0000\n",
      "Training loss for epoch 436: pinn: 0.0000, boundary: 3815.5013, total: 0.0000\n",
      "Training loss for epoch 437: pinn: 0.0000, boundary: 3785.6878, total: 0.0000\n",
      "Training loss for epoch 438: pinn: 0.0000, boundary: 3872.5243, total: 0.0000\n",
      "Training loss for epoch 439: pinn: 0.0000, boundary: 3877.1119, total: 0.0000\n",
      "Training loss for epoch 440: pinn: 0.0000, boundary: 3892.9682, total: 0.0000\n",
      "Training loss for epoch 441: pinn: 0.0000, boundary: 3888.7119, total: 0.0000\n",
      "Training loss for epoch 442: pinn: 0.0000, boundary: 3615.1651, total: 0.0000\n",
      "Training loss for epoch 443: pinn: 0.0000, boundary: 3716.7070, total: 0.0000\n",
      "Training loss for epoch 444: pinn: 0.0000, boundary: 3979.0918, total: 0.0000\n",
      "Training loss for epoch 445: pinn: 0.0000, boundary: 3682.6203, total: 0.0000\n",
      "Training loss for epoch 446: pinn: 0.0000, boundary: 3877.3591, total: 0.0000\n",
      "Training loss for epoch 447: pinn: 0.0000, boundary: 4014.9646, total: 0.0000\n",
      "Training loss for epoch 448: pinn: 0.0000, boundary: 3817.9978, total: 0.0000\n",
      "Training loss for epoch 449: pinn: 0.0000, boundary: 3980.3787, total: 0.0000\n",
      "Training loss for epoch 450: pinn: 0.0000, boundary: 3831.3304, total: 0.0000\n",
      "Training loss for epoch 451: pinn: 0.0000, boundary: 3842.1790, total: 0.0000\n",
      "Training loss for epoch 452: pinn: 0.0000, boundary: 3977.8773, total: 0.0000\n",
      "Training loss for epoch 453: pinn: 0.0000, boundary: 3885.8401, total: 0.0000\n",
      "Training loss for epoch 454: pinn: 0.0000, boundary: 3753.7768, total: 0.0000\n",
      "Training loss for epoch 455: pinn: 0.0000, boundary: 3919.5095, total: 0.0000\n",
      "Training loss for epoch 456: pinn: 0.0000, boundary: 3748.7054, total: 0.0000\n",
      "Training loss for epoch 457: pinn: 0.0000, boundary: 3892.4275, total: 0.0000\n",
      "Training loss for epoch 458: pinn: 0.0000, boundary: 3904.3190, total: 0.0000\n",
      "Training loss for epoch 459: pinn: 0.0000, boundary: 3874.6758, total: 0.0000\n",
      "Training loss for epoch 460: pinn: 0.0000, boundary: 3997.0155, total: 0.0000\n",
      "Training loss for epoch 461: pinn: 0.0000, boundary: 3842.9219, total: 0.0000\n",
      "Training loss for epoch 462: pinn: 0.0000, boundary: 3730.0506, total: 0.0000\n",
      "Training loss for epoch 463: pinn: 0.0000, boundary: 3956.2101, total: 0.0000\n",
      "Training loss for epoch 464: pinn: 0.0000, boundary: 3835.9823, total: 0.0000\n",
      "Training loss for epoch 465: pinn: 0.0000, boundary: 4056.2306, total: 0.0000\n",
      "Training loss for epoch 466: pinn: 0.0000, boundary: 3827.8870, total: 0.0000\n",
      "Training loss for epoch 467: pinn: 0.0000, boundary: 3873.0000, total: 0.0000\n",
      "Training loss for epoch 468: pinn: 0.0000, boundary: 3802.8932, total: 0.0000\n",
      "Training loss for epoch 469: pinn: 0.0000, boundary: 3888.9776, total: 0.0000\n",
      "Training loss for epoch 470: pinn: 0.0000, boundary: 3815.0774, total: 0.0000\n",
      "Training loss for epoch 471: pinn: 0.0000, boundary: 3724.8476, total: 0.0000\n",
      "Training loss for epoch 472: pinn: 0.0000, boundary: 3825.4734, total: 0.0000\n",
      "Training loss for epoch 473: pinn: 0.0000, boundary: 3848.3236, total: 0.0000\n",
      "Training loss for epoch 474: pinn: 0.0000, boundary: 3767.3773, total: 0.0000\n",
      "Training loss for epoch 475: pinn: 0.0000, boundary: 3990.5222, total: 0.0000\n",
      "Training loss for epoch 476: pinn: 0.0000, boundary: 3900.2457, total: 0.0000\n",
      "Training loss for epoch 477: pinn: 0.0000, boundary: 3733.6841, total: 0.0000\n",
      "Training loss for epoch 478: pinn: 0.0000, boundary: 3822.3970, total: 0.0000\n",
      "Training loss for epoch 479: pinn: 0.0000, boundary: 3728.8217, total: 0.0000\n",
      "Training loss for epoch 480: pinn: 0.0000, boundary: 3773.0175, total: 0.0000\n",
      "Training loss for epoch 481: pinn: 0.0000, boundary: 3790.0936, total: 0.0000\n",
      "Training loss for epoch 482: pinn: 0.0000, boundary: 3883.4851, total: 0.0000\n",
      "Training loss for epoch 483: pinn: 0.0000, boundary: 3924.3929, total: 0.0000\n",
      "Training loss for epoch 484: pinn: 0.0000, boundary: 3723.7398, total: 0.0000\n",
      "Training loss for epoch 485: pinn: 0.0000, boundary: 3828.3270, total: 0.0000\n",
      "Training loss for epoch 486: pinn: 0.0000, boundary: 3898.3816, total: 0.0000\n",
      "Training loss for epoch 487: pinn: 0.0000, boundary: 3922.5248, total: 0.0000\n",
      "Training loss for epoch 488: pinn: 0.0000, boundary: 3884.6905, total: 0.0000\n",
      "Training loss for epoch 489: pinn: 0.0000, boundary: 3842.4460, total: 0.0000\n",
      "Training loss for epoch 490: pinn: 0.0000, boundary: 4033.8752, total: 0.0000\n",
      "Training loss for epoch 491: pinn: 0.0000, boundary: 3912.7710, total: 0.0000\n",
      "Training loss for epoch 492: pinn: 0.0000, boundary: 3824.9957, total: 0.0000\n",
      "Training loss for epoch 493: pinn: 0.0000, boundary: 3924.0347, total: 0.0000\n",
      "Training loss for epoch 494: pinn: 0.0000, boundary: 3879.1539, total: 0.0000\n",
      "Training loss for epoch 495: pinn: 0.0000, boundary: 3799.9810, total: 0.0000\n",
      "Training loss for epoch 496: pinn: 0.0000, boundary: 3847.8331, total: 0.0000\n",
      "Training loss for epoch 497: pinn: 0.0000, boundary: 3873.3926, total: 0.0000\n",
      "Training loss for epoch 498: pinn: 0.0000, boundary: 3691.7870, total: 0.0000\n",
      "Training loss for epoch 499: pinn: 0.0000, boundary: 3861.2005, total: 0.0000\n",
      "Training loss for epoch 500: pinn: 0.0000, boundary: 3771.4264, total: 0.0000\n",
      "Training loss for epoch 501: pinn: 0.0000, boundary: 3981.9478, total: 0.0000\n",
      "Training loss for epoch 502: pinn: 0.0000, boundary: 3782.4398, total: 0.0000\n",
      "Training loss for epoch 503: pinn: 0.0000, boundary: 3833.7972, total: 0.0000\n",
      "Training loss for epoch 504: pinn: 0.0000, boundary: 3935.8715, total: 0.0000\n",
      "Training loss for epoch 505: pinn: 0.0000, boundary: 3712.0012, total: 0.0000\n",
      "Training loss for epoch 506: pinn: 0.0000, boundary: 3882.8418, total: 0.0000\n",
      "Training loss for epoch 507: pinn: 0.0000, boundary: 3775.3344, total: 0.0000\n",
      "Training loss for epoch 508: pinn: 0.0000, boundary: 3958.9147, total: 0.0000\n",
      "Training loss for epoch 509: pinn: 0.0000, boundary: 3988.8061, total: 0.0000\n",
      "Training loss for epoch 510: pinn: 0.0000, boundary: 3871.1111, total: 0.0000\n",
      "Training loss for epoch 511: pinn: 0.0000, boundary: 3881.5934, total: 0.0000\n",
      "Training loss for epoch 512: pinn: 0.0000, boundary: 3945.1355, total: 0.0000\n",
      "Training loss for epoch 513: pinn: 0.0000, boundary: 3877.8434, total: 0.0000\n",
      "Training loss for epoch 514: pinn: 0.0000, boundary: 3814.6001, total: 0.0000\n",
      "Training loss for epoch 515: pinn: 0.0000, boundary: 3778.4885, total: 0.0000\n",
      "Training loss for epoch 516: pinn: 0.0000, boundary: 3891.6654, total: 0.0000\n",
      "Training loss for epoch 517: pinn: 0.0000, boundary: 3962.7414, total: 0.0000\n",
      "Training loss for epoch 518: pinn: 0.0000, boundary: 3860.9169, total: 0.0000\n",
      "Training loss for epoch 519: pinn: 0.0000, boundary: 3935.3080, total: 0.0000\n",
      "Training loss for epoch 520: pinn: 0.0000, boundary: 3797.4654, total: 0.0000\n",
      "Training loss for epoch 521: pinn: 0.0000, boundary: 3877.2278, total: 0.0000\n",
      "Training loss for epoch 522: pinn: 0.0000, boundary: 3879.7648, total: 0.0000\n",
      "Training loss for epoch 523: pinn: 0.0000, boundary: 3829.4449, total: 0.0000\n",
      "Training loss for epoch 524: pinn: 0.0000, boundary: 3883.6967, total: 0.0000\n",
      "Training loss for epoch 525: pinn: 0.0000, boundary: 4087.7636, total: 0.0000\n",
      "Training loss for epoch 526: pinn: 0.0000, boundary: 3988.8274, total: 0.0000\n",
      "Training loss for epoch 527: pinn: 0.0000, boundary: 3993.5106, total: 0.0000\n",
      "Training loss for epoch 528: pinn: 0.0000, boundary: 3986.4724, total: 0.0000\n",
      "Training loss for epoch 529: pinn: 0.0000, boundary: 3818.0895, total: 0.0000\n",
      "Training loss for epoch 530: pinn: 0.0000, boundary: 3749.1962, total: 0.0000\n",
      "Training loss for epoch 531: pinn: 0.0000, boundary: 3712.7494, total: 0.0000\n",
      "Training loss for epoch 532: pinn: 0.0000, boundary: 3843.0922, total: 0.0000\n",
      "Training loss for epoch 533: pinn: 0.0000, boundary: 3877.6433, total: 0.0000\n",
      "Training loss for epoch 534: pinn: 0.0000, boundary: 3865.7139, total: 0.0000\n",
      "Training loss for epoch 535: pinn: 0.0000, boundary: 3982.3607, total: 0.0000\n",
      "Training loss for epoch 536: pinn: 0.0000, boundary: 3889.1923, total: 0.0000\n",
      "Training loss for epoch 537: pinn: 0.0000, boundary: 3896.3320, total: 0.0000\n",
      "Training loss for epoch 538: pinn: 0.0000, boundary: 3634.3287, total: 0.0000\n",
      "Training loss for epoch 539: pinn: 0.0000, boundary: 3866.7620, total: 0.0000\n",
      "Training loss for epoch 540: pinn: 0.0000, boundary: 3713.0625, total: 0.0000\n",
      "Training loss for epoch 541: pinn: 0.0000, boundary: 4089.4669, total: 0.0000\n",
      "Training loss for epoch 542: pinn: 0.0000, boundary: 3820.3485, total: 0.0000\n",
      "Training loss for epoch 543: pinn: 0.0000, boundary: 3641.6886, total: 0.0000\n",
      "Training loss for epoch 544: pinn: 0.0000, boundary: 3840.1011, total: 0.0000\n",
      "Training loss for epoch 545: pinn: 0.0000, boundary: 3961.8268, total: 0.0000\n",
      "Training loss for epoch 546: pinn: 0.0000, boundary: 3751.0148, total: 0.0000\n",
      "Training loss for epoch 547: pinn: 0.0000, boundary: 4135.7759, total: 0.0000\n",
      "Training loss for epoch 548: pinn: 0.0000, boundary: 3798.5924, total: 0.0000\n",
      "Training loss for epoch 549: pinn: 0.0000, boundary: 3953.6945, total: 0.0000\n",
      "Training loss for epoch 550: pinn: 0.0000, boundary: 3897.4836, total: 0.0000\n",
      "Training loss for epoch 551: pinn: 0.0000, boundary: 3926.3215, total: 0.0000\n",
      "Training loss for epoch 552: pinn: 0.0000, boundary: 3911.2040, total: 0.0000\n",
      "Training loss for epoch 553: pinn: 0.0000, boundary: 3917.0249, total: 0.0000\n",
      "Training loss for epoch 554: pinn: 0.0000, boundary: 3834.0002, total: 0.0000\n",
      "Training loss for epoch 555: pinn: 0.0000, boundary: 3806.1067, total: 0.0000\n",
      "Training loss for epoch 556: pinn: 0.0000, boundary: 3912.8517, total: 0.0000\n",
      "Training loss for epoch 557: pinn: 0.0000, boundary: 3925.5155, total: 0.0000\n",
      "Training loss for epoch 558: pinn: 0.0000, boundary: 3896.1673, total: 0.0000\n",
      "Training loss for epoch 559: pinn: 0.0000, boundary: 3806.1576, total: 0.0000\n",
      "Training loss for epoch 560: pinn: 0.0000, boundary: 4159.6132, total: 0.0000\n",
      "Training loss for epoch 561: pinn: 0.0000, boundary: 3826.7684, total: 0.0000\n",
      "Training loss for epoch 562: pinn: 0.0000, boundary: 3842.8817, total: 0.0000\n",
      "Training loss for epoch 563: pinn: 0.0000, boundary: 4037.5788, total: 0.0000\n",
      "Training loss for epoch 564: pinn: 0.0000, boundary: 3662.1257, total: 0.0000\n",
      "Training loss for epoch 565: pinn: 0.0000, boundary: 3738.5747, total: 0.0000\n",
      "Training loss for epoch 566: pinn: 0.0000, boundary: 3801.9583, total: 0.0000\n",
      "Training loss for epoch 567: pinn: 0.0000, boundary: 3851.4144, total: 0.0000\n",
      "Training loss for epoch 568: pinn: 0.0000, boundary: 3777.7377, total: 0.0000\n",
      "Training loss for epoch 569: pinn: 0.0000, boundary: 3696.3878, total: 0.0000\n",
      "Training loss for epoch 570: pinn: 0.0000, boundary: 3871.8068, total: 0.0000\n",
      "Training loss for epoch 571: pinn: 0.0000, boundary: 3751.1994, total: 0.0000\n",
      "Training loss for epoch 572: pinn: 0.0000, boundary: 3877.3018, total: 0.0000\n",
      "Training loss for epoch 573: pinn: 0.0000, boundary: 3806.2621, total: 0.0000\n",
      "Training loss for epoch 574: pinn: 0.0000, boundary: 3660.2998, total: 0.0000\n",
      "Training loss for epoch 575: pinn: 0.0000, boundary: 3749.9781, total: 0.0000\n",
      "Training loss for epoch 576: pinn: 0.0000, boundary: 4006.6867, total: 0.0000\n",
      "Training loss for epoch 577: pinn: 0.0000, boundary: 3681.7072, total: 0.0000\n",
      "Training loss for epoch 578: pinn: 0.0000, boundary: 3777.2347, total: 0.0000\n",
      "Training loss for epoch 579: pinn: 0.0000, boundary: 3897.9751, total: 0.0000\n",
      "Training loss for epoch 580: pinn: 0.0000, boundary: 4127.7047, total: 0.0000\n",
      "Training loss for epoch 581: pinn: 0.0000, boundary: 3759.1815, total: 0.0000\n",
      "Training loss for epoch 582: pinn: 0.0000, boundary: 3992.9411, total: 0.0000\n",
      "Training loss for epoch 583: pinn: 0.0000, boundary: 3790.6814, total: 0.0000\n",
      "Training loss for epoch 584: pinn: 0.0000, boundary: 4013.3874, total: 0.0000\n",
      "Training loss for epoch 585: pinn: 0.0000, boundary: 3663.5896, total: 0.0000\n",
      "Training loss for epoch 586: pinn: 0.0000, boundary: 3569.4056, total: 0.0000\n",
      "Training loss for epoch 587: pinn: 0.0000, boundary: 4028.9304, total: 0.0000\n",
      "Training loss for epoch 588: pinn: 0.0000, boundary: 3984.0082, total: 0.0000\n",
      "Training loss for epoch 589: pinn: 0.0000, boundary: 4020.4503, total: 0.0000\n",
      "Training loss for epoch 590: pinn: 0.0000, boundary: 3903.1742, total: 0.0000\n",
      "Training loss for epoch 591: pinn: 0.0000, boundary: 3867.2130, total: 0.0000\n",
      "Training loss for epoch 592: pinn: 0.0000, boundary: 3836.2513, total: 0.0000\n",
      "Training loss for epoch 593: pinn: 0.0000, boundary: 3835.5213, total: 0.0000\n",
      "Training loss for epoch 594: pinn: 0.0000, boundary: 4024.3204, total: 0.0000\n",
      "Training loss for epoch 595: pinn: 0.0000, boundary: 3826.3340, total: 0.0000\n",
      "Training loss for epoch 596: pinn: 0.0000, boundary: 3771.2574, total: 0.0000\n",
      "Training loss for epoch 597: pinn: 0.0000, boundary: 3662.2954, total: 0.0000\n",
      "Training loss for epoch 598: pinn: 0.0000, boundary: 3882.1832, total: 0.0000\n",
      "Training loss for epoch 599: pinn: 0.0000, boundary: 3914.4727, total: 0.0000\n",
      "Training loss for epoch 600: pinn: 0.0000, boundary: 3886.8456, total: 0.0000\n",
      "Training loss for epoch 601: pinn: 0.0000, boundary: 4007.0965, total: 0.0000\n",
      "Training loss for epoch 602: pinn: 0.0000, boundary: 3866.3801, total: 0.0000\n",
      "Training loss for epoch 603: pinn: 0.0000, boundary: 3866.3202, total: 0.0000\n",
      "Training loss for epoch 604: pinn: 0.0000, boundary: 3843.1584, total: 0.0000\n",
      "Training loss for epoch 605: pinn: 0.0000, boundary: 3811.5323, total: 0.0000\n",
      "Training loss for epoch 606: pinn: 0.0000, boundary: 3766.2871, total: 0.0000\n",
      "Training loss for epoch 607: pinn: 0.0000, boundary: 3846.3039, total: 0.0000\n",
      "Training loss for epoch 608: pinn: 0.0000, boundary: 3890.6957, total: 0.0000\n",
      "Training loss for epoch 609: pinn: 0.0000, boundary: 3966.5861, total: 0.0000\n",
      "Training loss for epoch 610: pinn: 0.0000, boundary: 3812.2845, total: 0.0000\n",
      "Training loss for epoch 611: pinn: 0.0000, boundary: 3907.1325, total: 0.0000\n",
      "Training loss for epoch 612: pinn: 0.0000, boundary: 3940.7712, total: 0.0000\n",
      "Training loss for epoch 613: pinn: 0.0000, boundary: 3833.6019, total: 0.0000\n",
      "Training loss for epoch 614: pinn: 0.0000, boundary: 3853.5182, total: 0.0000\n",
      "Training loss for epoch 615: pinn: 0.0000, boundary: 4054.6888, total: 0.0000\n",
      "Training loss for epoch 616: pinn: 0.0000, boundary: 3850.4485, total: 0.0000\n",
      "Training loss for epoch 617: pinn: 0.0000, boundary: 3810.4079, total: 0.0000\n",
      "Training loss for epoch 618: pinn: 0.0000, boundary: 4022.8961, total: 0.0000\n",
      "Training loss for epoch 619: pinn: 0.0000, boundary: 3853.8673, total: 0.0000\n",
      "Training loss for epoch 620: pinn: 0.0000, boundary: 4025.3773, total: 0.0000\n",
      "Training loss for epoch 621: pinn: 0.0000, boundary: 3977.0515, total: 0.0000\n",
      "Training loss for epoch 622: pinn: 0.0000, boundary: 4054.9178, total: 0.0000\n",
      "Training loss for epoch 623: pinn: 0.0000, boundary: 3813.9533, total: 0.0000\n",
      "Training loss for epoch 624: pinn: 0.0000, boundary: 4076.7827, total: 0.0000\n",
      "Training loss for epoch 625: pinn: 0.0000, boundary: 3757.6704, total: 0.0000\n",
      "Training loss for epoch 626: pinn: 0.0000, boundary: 3996.5423, total: 0.0000\n",
      "Training loss for epoch 627: pinn: 0.0000, boundary: 3890.8451, total: 0.0000\n",
      "Training loss for epoch 628: pinn: 0.0000, boundary: 3877.0260, total: 0.0000\n",
      "Training loss for epoch 629: pinn: 0.0000, boundary: 3928.3356, total: 0.0000\n",
      "Training loss for epoch 630: pinn: 0.0000, boundary: 3909.6976, total: 0.0000\n",
      "Training loss for epoch 631: pinn: 0.0000, boundary: 3960.9224, total: 0.0000\n",
      "Training loss for epoch 632: pinn: 0.0000, boundary: 3826.9621, total: 0.0000\n",
      "Training loss for epoch 633: pinn: 0.0000, boundary: 3953.8024, total: 0.0000\n",
      "Training loss for epoch 634: pinn: 0.0000, boundary: 3804.8327, total: 0.0000\n",
      "Training loss for epoch 635: pinn: 0.0000, boundary: 3959.8140, total: 0.0000\n",
      "Training loss for epoch 636: pinn: 0.0000, boundary: 4008.3599, total: 0.0000\n",
      "Training loss for epoch 637: pinn: 0.0000, boundary: 3967.2248, total: 0.0000\n",
      "Training loss for epoch 638: pinn: 0.0000, boundary: 3836.2105, total: 0.0000\n",
      "Training loss for epoch 639: pinn: 0.0000, boundary: 3934.1801, total: 0.0000\n",
      "Training loss for epoch 640: pinn: 0.0000, boundary: 3926.3988, total: 0.0000\n",
      "Training loss for epoch 641: pinn: 0.0000, boundary: 3860.6053, total: 0.0000\n",
      "Training loss for epoch 642: pinn: 0.0000, boundary: 3936.1028, total: 0.0000\n",
      "Training loss for epoch 643: pinn: 0.0000, boundary: 3732.5441, total: 0.0000\n",
      "Training loss for epoch 644: pinn: 0.0000, boundary: 3811.6724, total: 0.0000\n",
      "Training loss for epoch 645: pinn: 0.0000, boundary: 4016.7918, total: 0.0000\n",
      "Training loss for epoch 646: pinn: 0.0000, boundary: 3767.7228, total: 0.0000\n",
      "Training loss for epoch 647: pinn: 0.0000, boundary: 3920.2138, total: 0.0000\n",
      "Training loss for epoch 648: pinn: 0.0000, boundary: 3857.6346, total: 0.0000\n",
      "Training loss for epoch 649: pinn: 0.0000, boundary: 3754.9461, total: 0.0000\n",
      "Training loss for epoch 650: pinn: 0.0000, boundary: 3995.4977, total: 0.0000\n",
      "Training loss for epoch 651: pinn: 0.0000, boundary: 3977.8914, total: 0.0000\n",
      "Training loss for epoch 652: pinn: 0.0000, boundary: 3903.1440, total: 0.0000\n",
      "Training loss for epoch 653: pinn: 0.0000, boundary: 3921.6786, total: 0.0000\n",
      "Training loss for epoch 654: pinn: 0.0000, boundary: 3878.4394, total: 0.0000\n",
      "Training loss for epoch 655: pinn: 0.0000, boundary: 3970.1064, total: 0.0000\n",
      "Training loss for epoch 656: pinn: 0.0000, boundary: 3810.8658, total: 0.0000\n",
      "Training loss for epoch 657: pinn: 0.0000, boundary: 3949.5806, total: 0.0000\n",
      "Training loss for epoch 658: pinn: 0.0000, boundary: 3915.9477, total: 0.0000\n",
      "Training loss for epoch 659: pinn: 0.0000, boundary: 3819.8576, total: 0.0000\n",
      "Training loss for epoch 660: pinn: 0.0000, boundary: 3890.9456, total: 0.0000\n",
      "Training loss for epoch 661: pinn: 0.0000, boundary: 3911.7334, total: 0.0000\n",
      "Training loss for epoch 662: pinn: 0.0000, boundary: 3848.5607, total: 0.0000\n",
      "Training loss for epoch 663: pinn: 0.0000, boundary: 3755.6044, total: 0.0000\n",
      "Training loss for epoch 664: pinn: 0.0000, boundary: 3768.4904, total: 0.0000\n",
      "Training loss for epoch 665: pinn: 0.0000, boundary: 3786.2263, total: 0.0000\n",
      "Training loss for epoch 666: pinn: 0.0000, boundary: 3805.1109, total: 0.0000\n",
      "Training loss for epoch 667: pinn: 0.0000, boundary: 3779.2069, total: 0.0000\n",
      "Training loss for epoch 668: pinn: 0.0000, boundary: 3867.2229, total: 0.0000\n",
      "Training loss for epoch 669: pinn: 0.0000, boundary: 3783.8290, total: 0.0000\n",
      "Training loss for epoch 670: pinn: 0.0000, boundary: 3871.8356, total: 0.0000\n",
      "Training loss for epoch 671: pinn: 0.0000, boundary: 4000.9376, total: 0.0000\n",
      "Training loss for epoch 672: pinn: 0.0000, boundary: 3992.6387, total: 0.0000\n",
      "Training loss for epoch 673: pinn: 0.0000, boundary: 3830.1942, total: 0.0000\n",
      "Training loss for epoch 674: pinn: 0.0000, boundary: 3717.3184, total: 0.0000\n",
      "Training loss for epoch 675: pinn: 0.0000, boundary: 4026.0935, total: 0.0000\n",
      "Training loss for epoch 676: pinn: 0.0000, boundary: 3888.2850, total: 0.0000\n",
      "Training loss for epoch 677: pinn: 0.0000, boundary: 3933.8501, total: 0.0000\n",
      "Training loss for epoch 678: pinn: 0.0000, boundary: 3950.7577, total: 0.0000\n",
      "Training loss for epoch 679: pinn: 0.0000, boundary: 3949.6380, total: 0.0000\n",
      "Training loss for epoch 680: pinn: 0.0000, boundary: 3861.8593, total: 0.0000\n",
      "Training loss for epoch 681: pinn: 0.0000, boundary: 3873.8581, total: 0.0000\n",
      "Training loss for epoch 682: pinn: 0.0000, boundary: 3813.0460, total: 0.0000\n",
      "Training loss for epoch 683: pinn: 0.0000, boundary: 4010.7291, total: 0.0000\n",
      "Training loss for epoch 684: pinn: 0.0000, boundary: 3938.8731, total: 0.0000\n",
      "Training loss for epoch 685: pinn: 0.0000, boundary: 3991.3540, total: 0.0000\n",
      "Training loss for epoch 686: pinn: 0.0000, boundary: 3881.0484, total: 0.0000\n",
      "Training loss for epoch 687: pinn: 0.0000, boundary: 4047.2278, total: 0.0000\n",
      "Training loss for epoch 688: pinn: 0.0000, boundary: 4060.0401, total: 0.0000\n",
      "Training loss for epoch 689: pinn: 0.0000, boundary: 3923.3224, total: 0.0000\n",
      "Training loss for epoch 690: pinn: 0.0000, boundary: 3743.0068, total: 0.0000\n",
      "Training loss for epoch 691: pinn: 0.0000, boundary: 3834.3915, total: 0.0000\n",
      "Training loss for epoch 692: pinn: 0.0000, boundary: 4084.1497, total: 0.0000\n",
      "Training loss for epoch 693: pinn: 0.0000, boundary: 4049.3120, total: 0.0000\n",
      "Training loss for epoch 694: pinn: 0.0000, boundary: 3993.3354, total: 0.0000\n",
      "Training loss for epoch 695: pinn: 0.0000, boundary: 3836.1455, total: 0.0000\n",
      "Training loss for epoch 696: pinn: 0.0000, boundary: 3764.1336, total: 0.0000\n",
      "Training loss for epoch 697: pinn: 0.0000, boundary: 3917.6732, total: 0.0000\n",
      "Training loss for epoch 698: pinn: 0.0000, boundary: 4017.8376, total: 0.0000\n",
      "Training loss for epoch 699: pinn: 0.0000, boundary: 4010.4764, total: 0.0000\n",
      "Training loss for epoch 700: pinn: 0.0000, boundary: 3841.6412, total: 0.0000\n",
      "Training loss for epoch 701: pinn: 0.0000, boundary: 3943.4140, total: 0.0000\n",
      "Training loss for epoch 702: pinn: 0.0000, boundary: 3966.9878, total: 0.0000\n",
      "Training loss for epoch 703: pinn: 0.0000, boundary: 3983.2742, total: 0.0000\n",
      "Training loss for epoch 704: pinn: 0.0000, boundary: 3857.2748, total: 0.0000\n",
      "Training loss for epoch 705: pinn: 0.0000, boundary: 3918.5047, total: 0.0000\n",
      "Training loss for epoch 706: pinn: 0.0000, boundary: 3837.4081, total: 0.0000\n",
      "Training loss for epoch 707: pinn: 0.0000, boundary: 4024.3362, total: 0.0000\n",
      "Training loss for epoch 708: pinn: 0.0000, boundary: 3901.6058, total: 0.0000\n",
      "Training loss for epoch 709: pinn: 0.0000, boundary: 3684.7734, total: 0.0000\n",
      "Training loss for epoch 710: pinn: 0.0000, boundary: 3744.2673, total: 0.0000\n",
      "Training loss for epoch 711: pinn: 0.0000, boundary: 3786.4874, total: 0.0000\n",
      "Training loss for epoch 712: pinn: 0.0000, boundary: 3590.7586, total: 0.0000\n",
      "Training loss for epoch 713: pinn: 0.0000, boundary: 3776.9363, total: 0.0000\n",
      "Training loss for epoch 714: pinn: 0.0000, boundary: 4038.7801, total: 0.0000\n",
      "Training loss for epoch 715: pinn: 0.0000, boundary: 3777.2164, total: 0.0000\n",
      "Training loss for epoch 716: pinn: 0.0000, boundary: 3922.1318, total: 0.0000\n",
      "Training loss for epoch 717: pinn: 0.0000, boundary: 3743.5724, total: 0.0000\n",
      "Training loss for epoch 718: pinn: 0.0000, boundary: 3825.4937, total: 0.0000\n",
      "Training loss for epoch 719: pinn: 0.0000, boundary: 3813.3559, total: 0.0000\n",
      "Training loss for epoch 720: pinn: 0.0000, boundary: 3917.7359, total: 0.0000\n",
      "Training loss for epoch 721: pinn: 0.0000, boundary: 3788.9483, total: 0.0000\n",
      "Training loss for epoch 722: pinn: 0.0000, boundary: 3852.9720, total: 0.0000\n",
      "Training loss for epoch 723: pinn: 0.0000, boundary: 3915.2885, total: 0.0000\n",
      "Training loss for epoch 724: pinn: 0.0000, boundary: 3782.6242, total: 0.0000\n",
      "Training loss for epoch 725: pinn: 0.0000, boundary: 3885.6272, total: 0.0000\n",
      "Training loss for epoch 726: pinn: 0.0000, boundary: 3976.1999, total: 0.0000\n",
      "Training loss for epoch 727: pinn: 0.0000, boundary: 4010.6887, total: 0.0000\n",
      "Training loss for epoch 728: pinn: 0.0000, boundary: 3884.2774, total: 0.0000\n",
      "Training loss for epoch 729: pinn: 0.0000, boundary: 3868.2173, total: 0.0000\n",
      "Training loss for epoch 730: pinn: 0.0000, boundary: 3960.2068, total: 0.0000\n",
      "Training loss for epoch 731: pinn: 0.0000, boundary: 4011.0501, total: 0.0000\n",
      "Training loss for epoch 732: pinn: 0.0000, boundary: 3837.1285, total: 0.0000\n",
      "Training loss for epoch 733: pinn: 0.0000, boundary: 3864.9581, total: 0.0000\n",
      "Training loss for epoch 734: pinn: 0.0000, boundary: 3709.9360, total: 0.0000\n",
      "Training loss for epoch 735: pinn: 0.0000, boundary: 3841.0751, total: 0.0000\n",
      "Training loss for epoch 736: pinn: 0.0000, boundary: 3634.5852, total: 0.0000\n",
      "Training loss for epoch 737: pinn: 0.0000, boundary: 3946.1188, total: 0.0000\n",
      "Training loss for epoch 738: pinn: 0.0000, boundary: 3939.5861, total: 0.0000\n",
      "Training loss for epoch 739: pinn: 0.0000, boundary: 3711.6067, total: 0.0000\n",
      "Training loss for epoch 740: pinn: 0.0000, boundary: 3854.5307, total: 0.0000\n",
      "Training loss for epoch 741: pinn: 0.0000, boundary: 3923.6567, total: 0.0000\n",
      "Training loss for epoch 742: pinn: 0.0000, boundary: 3949.5301, total: 0.0000\n",
      "Training loss for epoch 743: pinn: 0.0000, boundary: 3897.6956, total: 0.0000\n",
      "Training loss for epoch 744: pinn: 0.0000, boundary: 3742.7234, total: 0.0000\n",
      "Training loss for epoch 745: pinn: 0.0000, boundary: 3852.7939, total: 0.0000\n",
      "Training loss for epoch 746: pinn: 0.0000, boundary: 3685.3223, total: 0.0000\n",
      "Training loss for epoch 747: pinn: 0.0000, boundary: 3831.0309, total: 0.0000\n",
      "Training loss for epoch 748: pinn: 0.0000, boundary: 3865.9781, total: 0.0000\n",
      "Training loss for epoch 749: pinn: 0.0000, boundary: 3872.5420, total: 0.0000\n",
      "Training loss for epoch 750: pinn: 0.0000, boundary: 3951.8994, total: 0.0000\n",
      "Training loss for epoch 751: pinn: 0.0000, boundary: 3827.0355, total: 0.0000\n",
      "Training loss for epoch 752: pinn: 0.0000, boundary: 3787.9293, total: 0.0000\n",
      "Training loss for epoch 753: pinn: 0.0000, boundary: 3860.4063, total: 0.0000\n",
      "Training loss for epoch 754: pinn: 0.0000, boundary: 3782.3118, total: 0.0000\n",
      "Training loss for epoch 755: pinn: 0.0000, boundary: 3870.3951, total: 0.0000\n",
      "Training loss for epoch 756: pinn: 0.0000, boundary: 3855.4090, total: 0.0000\n",
      "Training loss for epoch 757: pinn: 0.0000, boundary: 3722.8768, total: 0.0000\n",
      "Training loss for epoch 758: pinn: 0.0000, boundary: 3993.4482, total: 0.0000\n",
      "Training loss for epoch 759: pinn: 0.0000, boundary: 4011.6083, total: 0.0000\n",
      "Training loss for epoch 760: pinn: 0.0000, boundary: 3982.4434, total: 0.0000\n",
      "Training loss for epoch 761: pinn: 0.0000, boundary: 3749.7145, total: 0.0000\n",
      "Training loss for epoch 762: pinn: 0.0000, boundary: 3912.0300, total: 0.0000\n",
      "Training loss for epoch 763: pinn: 0.0000, boundary: 3981.3635, total: 0.0000\n",
      "Training loss for epoch 764: pinn: 0.0000, boundary: 3829.9636, total: 0.0000\n",
      "Training loss for epoch 765: pinn: 0.0000, boundary: 3854.8682, total: 0.0000\n",
      "Training loss for epoch 766: pinn: 0.0000, boundary: 3934.3032, total: 0.0000\n",
      "Training loss for epoch 767: pinn: 0.0000, boundary: 3807.3191, total: 0.0000\n",
      "Training loss for epoch 768: pinn: 0.0000, boundary: 4099.5480, total: 0.0000\n",
      "Training loss for epoch 769: pinn: 0.0000, boundary: 3854.2605, total: 0.0000\n",
      "Training loss for epoch 770: pinn: 0.0000, boundary: 3846.4882, total: 0.0000\n",
      "Training loss for epoch 771: pinn: 0.0000, boundary: 3883.6665, total: 0.0000\n",
      "Training loss for epoch 772: pinn: 0.0000, boundary: 3924.5237, total: 0.0000\n",
      "Training loss for epoch 773: pinn: 0.0000, boundary: 3888.9944, total: 0.0000\n",
      "Training loss for epoch 774: pinn: 0.0000, boundary: 3864.8424, total: 0.0000\n",
      "Training loss for epoch 775: pinn: 0.0000, boundary: 3934.2190, total: 0.0000\n",
      "Training loss for epoch 776: pinn: 0.0000, boundary: 3908.8327, total: 0.0000\n",
      "Training loss for epoch 777: pinn: 0.0000, boundary: 3803.2417, total: 0.0000\n",
      "Training loss for epoch 778: pinn: 0.0000, boundary: 3755.8697, total: 0.0000\n",
      "Training loss for epoch 779: pinn: 0.0000, boundary: 3910.1287, total: 0.0000\n",
      "Training loss for epoch 780: pinn: 0.0000, boundary: 3914.6637, total: 0.0000\n",
      "Training loss for epoch 781: pinn: 0.0000, boundary: 3892.0122, total: 0.0000\n",
      "Training loss for epoch 782: pinn: 0.0000, boundary: 4038.7423, total: 0.0000\n",
      "Training loss for epoch 783: pinn: 0.0000, boundary: 3834.3235, total: 0.0000\n",
      "Training loss for epoch 784: pinn: 0.0000, boundary: 3952.3991, total: 0.0000\n",
      "Training loss for epoch 785: pinn: 0.0000, boundary: 3936.4584, total: 0.0000\n",
      "Training loss for epoch 786: pinn: 0.0000, boundary: 3792.7560, total: 0.0000\n",
      "Training loss for epoch 787: pinn: 0.0000, boundary: 3899.3264, total: 0.0000\n",
      "Training loss for epoch 788: pinn: 0.0000, boundary: 3896.4070, total: 0.0000\n",
      "Training loss for epoch 789: pinn: 0.0000, boundary: 3898.4269, total: 0.0000\n",
      "Training loss for epoch 790: pinn: 0.0000, boundary: 4006.2431, total: 0.0000\n",
      "Training loss for epoch 791: pinn: 0.0000, boundary: 3832.8788, total: 0.0000\n",
      "Training loss for epoch 792: pinn: 0.0000, boundary: 3924.0997, total: 0.0000\n",
      "Training loss for epoch 793: pinn: 0.0000, boundary: 3908.5710, total: 0.0000\n",
      "Training loss for epoch 794: pinn: 0.0000, boundary: 4147.9371, total: 0.0000\n",
      "Training loss for epoch 795: pinn: 0.0000, boundary: 3901.9876, total: 0.0000\n",
      "Training loss for epoch 796: pinn: 0.0000, boundary: 3633.8518, total: 0.0000\n",
      "Training loss for epoch 797: pinn: 0.0000, boundary: 3854.8704, total: 0.0000\n",
      "Training loss for epoch 798: pinn: 0.0000, boundary: 3748.1063, total: 0.0000\n",
      "Training loss for epoch 799: pinn: 0.0000, boundary: 4055.6270, total: 0.0000\n",
      "Training loss for epoch 800: pinn: 0.0000, boundary: 3824.1883, total: 0.0000\n",
      "Training loss for epoch 801: pinn: 0.0000, boundary: 3640.8501, total: 0.0000\n",
      "Training loss for epoch 802: pinn: 0.0000, boundary: 3969.2965, total: 0.0000\n",
      "Training loss for epoch 803: pinn: 0.0000, boundary: 4034.9146, total: 0.0000\n",
      "Training loss for epoch 804: pinn: 0.0000, boundary: 3825.8448, total: 0.0000\n",
      "Training loss for epoch 805: pinn: 0.0000, boundary: 3860.9850, total: 0.0000\n",
      "Training loss for epoch 806: pinn: 0.0000, boundary: 4191.6884, total: 0.0000\n",
      "Training loss for epoch 807: pinn: 0.0000, boundary: 3837.4251, total: 0.0000\n",
      "Training loss for epoch 808: pinn: 0.0000, boundary: 3657.9017, total: 0.0000\n",
      "Training loss for epoch 809: pinn: 0.0000, boundary: 3924.6500, total: 0.0000\n",
      "Training loss for epoch 810: pinn: 0.0000, boundary: 3914.0807, total: 0.0000\n",
      "Training loss for epoch 811: pinn: 0.0000, boundary: 3941.6265, total: 0.0000\n",
      "Training loss for epoch 812: pinn: 0.0000, boundary: 3896.3926, total: 0.0000\n",
      "Training loss for epoch 813: pinn: 0.0000, boundary: 3920.5157, total: 0.0000\n",
      "Training loss for epoch 814: pinn: 0.0000, boundary: 3812.4357, total: 0.0000\n",
      "Training loss for epoch 815: pinn: 0.0000, boundary: 3828.8162, total: 0.0000\n",
      "Training loss for epoch 816: pinn: 0.0000, boundary: 3816.0116, total: 0.0000\n",
      "Training loss for epoch 817: pinn: 0.0000, boundary: 3961.9275, total: 0.0000\n",
      "Training loss for epoch 818: pinn: 0.0000, boundary: 4013.8984, total: 0.0000\n",
      "Training loss for epoch 819: pinn: 0.0000, boundary: 3945.6824, total: 0.0000\n",
      "Training loss for epoch 820: pinn: 0.0000, boundary: 3916.7908, total: 0.0000\n",
      "Training loss for epoch 821: pinn: 0.0000, boundary: 3842.9871, total: 0.0000\n",
      "Training loss for epoch 822: pinn: 0.0000, boundary: 4063.8774, total: 0.0000\n",
      "Training loss for epoch 823: pinn: 0.0000, boundary: 3960.2441, total: 0.0000\n",
      "Training loss for epoch 824: pinn: 0.0000, boundary: 3964.5542, total: 0.0000\n",
      "Training loss for epoch 825: pinn: 0.0000, boundary: 3890.9650, total: 0.0000\n",
      "Training loss for epoch 826: pinn: 0.0000, boundary: 3881.5880, total: 0.0000\n",
      "Training loss for epoch 827: pinn: 0.0000, boundary: 3860.0963, total: 0.0000\n",
      "Training loss for epoch 828: pinn: 0.0000, boundary: 3725.0678, total: 0.0000\n",
      "Training loss for epoch 829: pinn: 0.0000, boundary: 3728.0870, total: 0.0000\n",
      "Training loss for epoch 830: pinn: 0.0000, boundary: 4076.3746, total: 0.0000\n",
      "Training loss for epoch 831: pinn: 0.0000, boundary: 3719.6015, total: 0.0000\n",
      "Training loss for epoch 832: pinn: 0.0000, boundary: 3633.5627, total: 0.0000\n",
      "Training loss for epoch 833: pinn: 0.0000, boundary: 3951.7595, total: 0.0000\n",
      "Training loss for epoch 834: pinn: 0.0000, boundary: 3815.8309, total: 0.0000\n",
      "Training loss for epoch 835: pinn: 0.0000, boundary: 3725.9014, total: 0.0000\n",
      "Training loss for epoch 836: pinn: 0.0000, boundary: 4024.5426, total: 0.0000\n",
      "Training loss for epoch 837: pinn: 0.0000, boundary: 3811.5236, total: 0.0000\n",
      "Training loss for epoch 838: pinn: 0.0000, boundary: 3936.8712, total: 0.0000\n",
      "Training loss for epoch 839: pinn: 0.0000, boundary: 3880.4195, total: 0.0000\n",
      "Training loss for epoch 840: pinn: 0.0000, boundary: 3723.2091, total: 0.0000\n",
      "Training loss for epoch 841: pinn: 0.0000, boundary: 3758.8182, total: 0.0000\n",
      "Training loss for epoch 842: pinn: 0.0000, boundary: 3736.0871, total: 0.0000\n",
      "Training loss for epoch 843: pinn: 0.0000, boundary: 3797.2240, total: 0.0000\n",
      "Training loss for epoch 844: pinn: 0.0000, boundary: 3937.4871, total: 0.0000\n",
      "Training loss for epoch 845: pinn: 0.0000, boundary: 3820.8303, total: 0.0000\n",
      "Training loss for epoch 846: pinn: 0.0000, boundary: 3896.3043, total: 0.0000\n",
      "Training loss for epoch 847: pinn: 0.0000, boundary: 3746.0374, total: 0.0000\n",
      "Training loss for epoch 848: pinn: 0.0000, boundary: 3992.7714, total: 0.0000\n",
      "Training loss for epoch 849: pinn: 0.0000, boundary: 3928.0842, total: 0.0000\n",
      "Training loss for epoch 850: pinn: 0.0000, boundary: 3828.7657, total: 0.0000\n",
      "Training loss for epoch 851: pinn: 0.0000, boundary: 3875.7196, total: 0.0000\n",
      "Training loss for epoch 852: pinn: 0.0000, boundary: 3875.4591, total: 0.0000\n",
      "Training loss for epoch 853: pinn: 0.0000, boundary: 3779.5971, total: 0.0000\n",
      "Training loss for epoch 854: pinn: 0.0000, boundary: 3735.6782, total: 0.0000\n",
      "Training loss for epoch 855: pinn: 0.0000, boundary: 3788.9105, total: 0.0000\n",
      "Training loss for epoch 856: pinn: 0.0000, boundary: 3909.2591, total: 0.0000\n",
      "Training loss for epoch 857: pinn: 0.0000, boundary: 3895.9894, total: 0.0000\n",
      "Training loss for epoch 858: pinn: 0.0000, boundary: 3735.6870, total: 0.0000\n",
      "Training loss for epoch 859: pinn: 0.0000, boundary: 3804.4898, total: 0.0000\n",
      "Training loss for epoch 860: pinn: 0.0000, boundary: 3824.8737, total: 0.0000\n",
      "Training loss for epoch 861: pinn: 0.0000, boundary: 4023.3658, total: 0.0000\n",
      "Training loss for epoch 862: pinn: 0.0000, boundary: 3942.4195, total: 0.0000\n",
      "Training loss for epoch 863: pinn: 0.0000, boundary: 3913.2543, total: 0.0000\n",
      "Training loss for epoch 864: pinn: 0.0000, boundary: 3880.3820, total: 0.0000\n",
      "Training loss for epoch 865: pinn: 0.0000, boundary: 3855.1440, total: 0.0000\n",
      "Training loss for epoch 866: pinn: 0.0000, boundary: 3730.9891, total: 0.0000\n",
      "Training loss for epoch 867: pinn: 0.0000, boundary: 3866.9387, total: 0.0000\n",
      "Training loss for epoch 868: pinn: 0.0000, boundary: 3729.2438, total: 0.0000\n",
      "Training loss for epoch 869: pinn: 0.0000, boundary: 4152.4326, total: 0.0000\n",
      "Training loss for epoch 870: pinn: 0.0000, boundary: 3795.1353, total: 0.0000\n",
      "Training loss for epoch 871: pinn: 0.0000, boundary: 3907.9926, total: 0.0000\n",
      "Training loss for epoch 872: pinn: 0.0000, boundary: 4129.5472, total: 0.0000\n",
      "Training loss for epoch 873: pinn: 0.0000, boundary: 3886.4595, total: 0.0000\n",
      "Training loss for epoch 874: pinn: 0.0000, boundary: 3857.3804, total: 0.0000\n",
      "Training loss for epoch 875: pinn: 0.0000, boundary: 3967.4420, total: 0.0000\n",
      "Training loss for epoch 876: pinn: 0.0000, boundary: 3920.1682, total: 0.0000\n",
      "Training loss for epoch 877: pinn: 0.0000, boundary: 3844.7178, total: 0.0000\n",
      "Training loss for epoch 878: pinn: 0.0000, boundary: 3895.5022, total: 0.0000\n",
      "Training loss for epoch 879: pinn: 0.0000, boundary: 3685.7910, total: 0.0000\n",
      "Training loss for epoch 880: pinn: 0.0000, boundary: 3931.1964, total: 0.0000\n",
      "Training loss for epoch 881: pinn: 0.0000, boundary: 3877.6772, total: 0.0000\n",
      "Training loss for epoch 882: pinn: 0.0000, boundary: 3855.6448, total: 0.0000\n",
      "Training loss for epoch 883: pinn: 0.0000, boundary: 3890.9063, total: 0.0000\n",
      "Training loss for epoch 884: pinn: 0.0000, boundary: 4083.6181, total: 0.0000\n",
      "Training loss for epoch 885: pinn: 0.0000, boundary: 3715.7871, total: 0.0000\n",
      "Training loss for epoch 886: pinn: 0.0000, boundary: 3917.4500, total: 0.0000\n",
      "Training loss for epoch 887: pinn: 0.0000, boundary: 4155.5212, total: 0.0000\n",
      "Training loss for epoch 888: pinn: 0.0000, boundary: 3851.8335, total: 0.0000\n",
      "Training loss for epoch 889: pinn: 0.0000, boundary: 3809.7564, total: 0.0000\n",
      "Training loss for epoch 890: pinn: 0.0000, boundary: 3984.7218, total: 0.0000\n",
      "Training loss for epoch 891: pinn: 0.0000, boundary: 3948.7058, total: 0.0000\n",
      "Training loss for epoch 892: pinn: 0.0000, boundary: 3805.8589, total: 0.0000\n",
      "Training loss for epoch 893: pinn: 0.0000, boundary: 4008.7824, total: 0.0000\n",
      "Training loss for epoch 894: pinn: 0.0000, boundary: 3692.1788, total: 0.0000\n",
      "Training loss for epoch 895: pinn: 0.0000, boundary: 4170.5134, total: 0.0000\n",
      "Training loss for epoch 896: pinn: 0.0000, boundary: 3800.9370, total: 0.0000\n",
      "Training loss for epoch 897: pinn: 0.0000, boundary: 4103.9608, total: 0.0000\n",
      "Training loss for epoch 898: pinn: 0.0000, boundary: 3687.2659, total: 0.0000\n",
      "Training loss for epoch 899: pinn: 0.0000, boundary: 4000.6285, total: 0.0000\n",
      "Training loss for epoch 900: pinn: 0.0000, boundary: 3793.8035, total: 0.0000\n",
      "Training loss for epoch 901: pinn: 0.0000, boundary: 3930.7086, total: 0.0000\n",
      "Training loss for epoch 902: pinn: 0.0000, boundary: 3971.5061, total: 0.0000\n",
      "Training loss for epoch 903: pinn: 0.0000, boundary: 3855.9455, total: 0.0000\n",
      "Training loss for epoch 904: pinn: 0.0000, boundary: 3755.4312, total: 0.0000\n",
      "Training loss for epoch 905: pinn: 0.0000, boundary: 4026.1639, total: 0.0000\n",
      "Training loss for epoch 906: pinn: 0.0000, boundary: 3885.0496, total: 0.0000\n",
      "Training loss for epoch 907: pinn: 0.0000, boundary: 3928.9844, total: 0.0000\n",
      "Training loss for epoch 908: pinn: 0.0000, boundary: 3864.4671, total: 0.0000\n",
      "Training loss for epoch 909: pinn: 0.0000, boundary: 3992.8444, total: 0.0000\n",
      "Training loss for epoch 910: pinn: 0.0000, boundary: 3920.2298, total: 0.0000\n",
      "Training loss for epoch 911: pinn: 0.0000, boundary: 4028.7486, total: 0.0000\n",
      "Training loss for epoch 912: pinn: 0.0000, boundary: 3815.5236, total: 0.0000\n",
      "Training loss for epoch 913: pinn: 0.0000, boundary: 3862.6558, total: 0.0000\n",
      "Training loss for epoch 914: pinn: 0.0000, boundary: 3712.3236, total: 0.0000\n",
      "Training loss for epoch 915: pinn: 0.0000, boundary: 3878.8952, total: 0.0000\n",
      "Training loss for epoch 916: pinn: 0.0000, boundary: 3786.2579, total: 0.0000\n",
      "Training loss for epoch 917: pinn: 0.0000, boundary: 3935.4495, total: 0.0000\n",
      "Training loss for epoch 918: pinn: 0.0000, boundary: 3960.9311, total: 0.0000\n",
      "Training loss for epoch 919: pinn: 0.0000, boundary: 3851.6061, total: 0.0000\n",
      "Training loss for epoch 920: pinn: 0.0000, boundary: 4006.8214, total: 0.0000\n",
      "Training loss for epoch 921: pinn: 0.0000, boundary: 3737.7993, total: 0.0000\n",
      "Training loss for epoch 922: pinn: 0.0000, boundary: 3756.7768, total: 0.0000\n",
      "Training loss for epoch 923: pinn: 0.0000, boundary: 4102.4318, total: 0.0000\n",
      "Training loss for epoch 924: pinn: 0.0000, boundary: 3972.0984, total: 0.0000\n",
      "Training loss for epoch 925: pinn: 0.0000, boundary: 4000.9631, total: 0.0000\n",
      "Training loss for epoch 926: pinn: 0.0000, boundary: 3898.9891, total: 0.0000\n",
      "Training loss for epoch 927: pinn: 0.0000, boundary: 3863.5663, total: 0.0000\n",
      "Training loss for epoch 928: pinn: 0.0000, boundary: 3835.7579, total: 0.0000\n",
      "Training loss for epoch 929: pinn: 0.0000, boundary: 4011.7966, total: 0.0000\n",
      "Training loss for epoch 930: pinn: 0.0000, boundary: 3858.1830, total: 0.0000\n",
      "Training loss for epoch 931: pinn: 0.0000, boundary: 3905.0749, total: 0.0000\n",
      "Training loss for epoch 932: pinn: 0.0000, boundary: 3754.1200, total: 0.0000\n",
      "Training loss for epoch 933: pinn: 0.0000, boundary: 4063.6521, total: 0.0000\n",
      "Training loss for epoch 934: pinn: 0.0000, boundary: 3741.1211, total: 0.0000\n",
      "Training loss for epoch 935: pinn: 0.0000, boundary: 3728.8931, total: 0.0000\n",
      "Training loss for epoch 936: pinn: 0.0000, boundary: 3976.6736, total: 0.0000\n",
      "Training loss for epoch 937: pinn: 0.0000, boundary: 3756.8414, total: 0.0000\n",
      "Training loss for epoch 938: pinn: 0.0000, boundary: 3946.5240, total: 0.0000\n",
      "Training loss for epoch 939: pinn: 0.0000, boundary: 3565.3787, total: 0.0000\n",
      "Training loss for epoch 940: pinn: 0.0000, boundary: 3929.3911, total: 0.0000\n",
      "Training loss for epoch 941: pinn: 0.0000, boundary: 4008.3376, total: 0.0000\n",
      "Training loss for epoch 942: pinn: 0.0000, boundary: 4054.7622, total: 0.0000\n",
      "Training loss for epoch 943: pinn: 0.0000, boundary: 3743.4376, total: 0.0000\n",
      "Training loss for epoch 944: pinn: 0.0000, boundary: 3815.7615, total: 0.0000\n",
      "Training loss for epoch 945: pinn: 0.0000, boundary: 3736.6394, total: 0.0000\n",
      "Training loss for epoch 946: pinn: 0.0000, boundary: 3936.0994, total: 0.0000\n",
      "Training loss for epoch 947: pinn: 0.0000, boundary: 3993.6587, total: 0.0000\n",
      "Training loss for epoch 948: pinn: 0.0000, boundary: 3882.9418, total: 0.0000\n",
      "Training loss for epoch 949: pinn: 0.0000, boundary: 3931.6575, total: 0.0000\n",
      "Training loss for epoch 950: pinn: 0.0000, boundary: 3945.4965, total: 0.0000\n",
      "Training loss for epoch 951: pinn: 0.0000, boundary: 3831.1271, total: 0.0000\n",
      "Training loss for epoch 952: pinn: 0.0000, boundary: 3786.9361, total: 0.0000\n",
      "Training loss for epoch 953: pinn: 0.0000, boundary: 3934.7585, total: 0.0000\n",
      "Training loss for epoch 954: pinn: 0.0000, boundary: 3845.6433, total: 0.0000\n",
      "Training loss for epoch 955: pinn: 0.0000, boundary: 3720.0503, total: 0.0000\n",
      "Training loss for epoch 956: pinn: 0.0000, boundary: 3777.3917, total: 0.0000\n",
      "Training loss for epoch 957: pinn: 0.0000, boundary: 4009.8387, total: 0.0000\n",
      "Training loss for epoch 958: pinn: 0.0000, boundary: 3946.2503, total: 0.0000\n",
      "Training loss for epoch 959: pinn: 0.0000, boundary: 4074.7801, total: 0.0000\n",
      "Training loss for epoch 960: pinn: 0.0000, boundary: 3659.2027, total: 0.0000\n",
      "Training loss for epoch 961: pinn: 0.0000, boundary: 3681.7835, total: 0.0000\n",
      "Training loss for epoch 962: pinn: 0.0000, boundary: 3890.4764, total: 0.0000\n",
      "Training loss for epoch 963: pinn: 0.0000, boundary: 3938.4799, total: 0.0000\n",
      "Training loss for epoch 964: pinn: 0.0000, boundary: 4117.6133, total: 0.0000\n",
      "Training loss for epoch 965: pinn: 0.0000, boundary: 3687.4051, total: 0.0000\n",
      "Training loss for epoch 966: pinn: 0.0000, boundary: 3789.7757, total: 0.0000\n",
      "Training loss for epoch 967: pinn: 0.0000, boundary: 3780.5288, total: 0.0000\n",
      "Training loss for epoch 968: pinn: 0.0000, boundary: 3878.2143, total: 0.0000\n",
      "Training loss for epoch 969: pinn: 0.0000, boundary: 4025.7888, total: 0.0000\n",
      "Training loss for epoch 970: pinn: 0.0000, boundary: 3850.5522, total: 0.0000\n",
      "Training loss for epoch 971: pinn: 0.0000, boundary: 3643.5109, total: 0.0000\n",
      "Training loss for epoch 972: pinn: 0.0000, boundary: 3913.6822, total: 0.0000\n",
      "Training loss for epoch 973: pinn: 0.0000, boundary: 3869.8757, total: 0.0000\n",
      "Training loss for epoch 974: pinn: 0.0000, boundary: 3882.8338, total: 0.0000\n",
      "Training loss for epoch 975: pinn: 0.0000, boundary: 3863.6179, total: 0.0000\n",
      "Training loss for epoch 976: pinn: 0.0000, boundary: 3833.9369, total: 0.0000\n",
      "Training loss for epoch 977: pinn: 0.0000, boundary: 3988.8467, total: 0.0000\n",
      "Training loss for epoch 978: pinn: 0.0000, boundary: 3771.8968, total: 0.0000\n",
      "Training loss for epoch 979: pinn: 0.0000, boundary: 3984.4207, total: 0.0000\n",
      "Training loss for epoch 980: pinn: 0.0000, boundary: 3753.0211, total: 0.0000\n",
      "Training loss for epoch 981: pinn: 0.0000, boundary: 3889.9196, total: 0.0000\n",
      "Training loss for epoch 982: pinn: 0.0000, boundary: 3819.1183, total: 0.0000\n",
      "Training loss for epoch 983: pinn: 0.0000, boundary: 3845.0370, total: 0.0000\n",
      "Training loss for epoch 984: pinn: 0.0000, boundary: 4099.8780, total: 0.0000\n",
      "Training loss for epoch 985: pinn: 0.0000, boundary: 3782.8767, total: 0.0000\n",
      "Training loss for epoch 986: pinn: 0.0000, boundary: 3965.9147, total: 0.0000\n",
      "Training loss for epoch 987: pinn: 0.0000, boundary: 3813.8887, total: 0.0000\n",
      "Training loss for epoch 988: pinn: 0.0000, boundary: 3803.7722, total: 0.0000\n",
      "Training loss for epoch 989: pinn: 0.0000, boundary: 4099.6181, total: 0.0000\n",
      "Training loss for epoch 990: pinn: 0.0000, boundary: 4028.9938, total: 0.0000\n",
      "Training loss for epoch 991: pinn: 0.0000, boundary: 3979.3142, total: 0.0000\n",
      "Training loss for epoch 992: pinn: 0.0000, boundary: 3999.0940, total: 0.0000\n",
      "Training loss for epoch 993: pinn: 0.0000, boundary: 3725.7796, total: 0.0000\n",
      "Training loss for epoch 994: pinn: 0.0000, boundary: 3804.4242, total: 0.0000\n",
      "Training loss for epoch 995: pinn: 0.0000, boundary: 3819.5236, total: 0.0000\n",
      "Training loss for epoch 996: pinn: 0.0000, boundary: 3967.6363, total: 0.0000\n",
      "Training loss for epoch 997: pinn: 0.0000, boundary: 3900.3586, total: 0.0000\n",
      "Training loss for epoch 998: pinn: 0.0000, boundary: 3852.8321, total: 0.0000\n",
      "Training loss for epoch 999: pinn: 0.0000, boundary: 3964.8364, total: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Neural network. Note: 2 inputs- (p, r), 1 output- f(r, p)\n",
    "inputs = tf.keras.Input((2))\n",
    "x_ = tf.keras.layers.Dense(100, activation='relu')(inputs)\n",
    "x_ = tf.keras.layers.Dense(100, activation='relu')(x_)\n",
    "x_ = tf.keras.layers.Dense(100, activation='relu')(x_)\n",
    "outputs = tf.keras.layers.Dense(1, activation='linear')(x_) \n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 1\n",
    "lr = 3e-3\n",
    "lr_decay = 0.95\n",
    "batchsize = 1032\n",
    "boundary_batchsize = 128\n",
    "epochs = 1000\n",
    "save = True\n",
    "load_epoch = -1\n",
    "weight_change = -1\n",
    "filename = 'multipliedGrad'\n",
    "\n",
    "# Initialize and fit the PINN\n",
    "pinn = PINN(inputs=inputs, outputs=outputs, lower_bound=lb, upper_bound=ub, p=p[:, 0], r=r[:, 0], \n",
    "            f_boundary=f_boundary[:, 0], size=size)\n",
    "pinn_loss, boundary_loss, predictions = pinn.fit(P_predict=P_star, alpha=alpha, batchsize=batchsize, boundary_batchsize=boundary_batchsize,\n",
    "                                                 epochs=epochs, lr=lr, size=size, save=save, load_epoch=load_epoch, lr_decay=lr_decay,\n",
    "                                                 weight_change=weight_change, filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a for loop\n",
    "Train NN to match radii 115-120 AU, then pass result at 115 AU as boundary condition to the next PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Constants  \n",
    "# m = 0.938 # GeV/c^2\n",
    "# gamma = -3 # Between -2 and -3\n",
    "# size = 512 # size of r, T, p, and f_boundary\n",
    "# T_lims = [0.001, 1000]\n",
    "# r_lims = [0.4, 120]\n",
    "# num_r = 120\n",
    "\n",
    "# # Create intial data\n",
    "# T = np.logspace(np.log10(T_lims[0]), np.log10(T_lims[1]), size).flatten()[:,None] # GeV\n",
    "# p = (np.sqrt((T+m)**2-m**2)).flatten()[:,None] # GeV/c\n",
    "# r_mins = np.linspace(r_lims[0], r_lims[1], num_r)\n",
    "# f_boundary = ((T + m)**gamma)/(p**2) # particles/(m^3 (GeV/c)^3)\n",
    "\n",
    "# T = np.log(T)\n",
    "# p = np.log(p)\n",
    "# f_boundary = np.log(f_boundary)\n",
    "\n",
    "# # Neural network. Note: 2 inputs- (p, r), 1 output- f(r, p)\n",
    "# inputs = tf.keras.Input((2))\n",
    "# x_ = tf.keras.layers.Dense(100, activation='relu')(inputs)\n",
    "# outputs = tf.keras.layers.Dense(1, activation='linear')(x_) \n",
    "\n",
    "# # Hyperparameters\n",
    "# alpha = 0.2\n",
    "# lr = 3e-3\n",
    "# lr_decay = 0.9\n",
    "# batchsize = 512\n",
    "# boundary_batchsize = 256\n",
    "# epochs = 1000\n",
    "# save = True\n",
    "# load_epoch = -1\n",
    "# weight_change = 1.05\n",
    "# filename = '5hundred'\n",
    "\n",
    "# boundaries = np.zeros((size, num_r+1)) \n",
    "# boundaries[:, 0] = f_boundary[:, 0]\n",
    "\n",
    "# for i in range(num_r):\n",
    "#     print(f'Index {i} with r ranging from {r_mins[-(i+1)]} to {r_mins[-(i+2)]}')\n",
    "#     print(f'Boundary condition for pinn: {boundaries[:, i]}')\n",
    "#     r = (np.logspace(np.log10(r_mins[-(i+1)]*150e6), np.log10(r_mins[-i]*150e6), size)).flatten()[:,None] # km\n",
    "#     r = np.log(r)\n",
    "\n",
    "#     # Domain bounds\n",
    "#     lb = np.array([p[0], r[0]]) # (p, r) in (GeV, AU)\n",
    "#     ub = np.array([p[-1], r[-1]]) # (p, r) in (GeV, AU)\n",
    "\n",
    "#     # Flatten and transpose data for ML\n",
    "#     P, R = np.meshgrid(p, r)\n",
    "#     P_star = np.hstack((P.flatten()[:,None], R.flatten()[:,None]))\n",
    "    \n",
    "#     pinn = PINN(inputs=inputs, outputs=outputs, lower_bound=lb, upper_bound=ub, p=p[:, 0], r=r[:, 0], \n",
    "#                     f_boundary=boundaries[:, i], size=size)        \n",
    "    \n",
    "#     pinn_loss, boundary_loss, predictions = pinn.fit(P_predict=P_star, alpha=alpha, batchsize=batchsize, \n",
    "#                                                      boundary_batchsize=boundary_batchsize, epochs=epochs, lr=lr, size=size, \n",
    "#                                                      save=save, load_epoch=load_epoch, lr_decay=lr_decay, weight_change=weight_change)\n",
    "    \n",
    "#     boundaries[:, i+1] = predictions[:, :, -1].reshape((size, size))[-1, :]\n",
    "    \n",
    "#     # Break if reached inner boundary of r\n",
    "#     if(num_r - (i+2))==0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the outputs to a pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PINN outputs\n",
    "with open('./figures/pickles/pinn_loss_' + filename + '.pkl', 'wb') as file:\n",
    "    pkl.dump(pinn_loss, file)\n",
    "    \n",
    "with open('./figures/pickles/boundary_loss_' + filename + '.pkl', 'wb') as file:\n",
    "    pkl.dump(boundary_loss, file)\n",
    "    \n",
    "with open('./figures/pickles/predictions_' + filename + '.pkl', 'wb') as file:\n",
    "    pkl.dump(predictions, file)\n",
    "    \n",
    "# with open('./figures/pickles/f_boundary.pkl', 'wb') as file:\n",
    "#     pkl.dump(f_boundary, file)\n",
    "    \n",
    "# with open('./figures/pickles/p.pkl', 'wb') as file:\n",
    "#     pkl.dump(p, file)\n",
    "    \n",
    "# with open('./figures/pickles/T.pkl', 'wb') as file:\n",
    "#     pkl.dump(T, file)\n",
    "    \n",
    "# with open('./figures/pickles/r.pkl', 'wb') as file:\n",
    "#     pkl.dump(r, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train neural network with Sherpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set-up sherpa parameters, algorithm, and study\n",
    "# parameters = [sherpa.Ordinal(name='beta', range=[5, 10, 15, 20, 30]),\n",
    "#               sherpa.Continuous(name='lr', range=[3e-5, 3e-1], scale='log'),\n",
    "#               sherpa.Ordinal(name='batchsize', range=[256, 512, 1032, 2048]),\n",
    "#               sherpa.Ordinal(name='boundary_batchsize', range=[64, 128, 256]),\n",
    "#               sherpa.Ordinal(name='num_hidden_units', range=[100, 500, 1000]),\n",
    "#               sherpa.Choice(name='activation', range=['relu', 'tanh'])]\n",
    "\n",
    "# algorithm = sherpa.algorithms.RandomSearch(max_num_trials=2)\n",
    "\n",
    "# study = sherpa.Study(parameters=parameters,\n",
    "#                  algorithm=algorithm,\n",
    "#                  lower_is_better=True)\n",
    "\n",
    "# num_iterations = 1\n",
    "\n",
    "# # For each trial in the study, fit the model on the parameters and add the observation to the study\n",
    "# for trial in study:\n",
    "#     # Define neural network\n",
    "#     inputs = tf.keras.Input((2))\n",
    "#     x_ = tf.keras.layers.Dense(trial.parameters, activation=trial.parameters[5])(inputs)\n",
    "#     x_ = tf.keras.layers.Dense(trial.parameters[4], activation=trial.parameters[5])(x_)\n",
    "#     outputs = tf.keras.layers.Dense(1, activation='linear')(x_) \n",
    "\n",
    "#     # Initialize PINN and compile\n",
    "#     pinn = PINN(inputs=inputs, outputs=outputs, lower_bound=lb, upper_bound=ub, p=p[:, 0], r=r[:, 0], \n",
    "#             f_boundary=f_boundary[:, 0], size=size)\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=trial.parameters[1])\n",
    "#     pinn.compile(optimizer=optimizer)\n",
    "    \n",
    "#     # For each iteration, fit the PINN and add the observation to the study\n",
    "#     for iteration in range(num_iterations):\n",
    "#         total_loss, pinn_loss, boundary_loss, predictions = pinn.fit(P_predict=P_star, alpha=alpha, beta=trial.parameters[0], batchsize=trial.parameters[2], \n",
    "#                                                              boundary_batchsize=trial.parameters[3], epochs=100, size=size)\n",
    "#         study.add_observation(trial=trial,\n",
    "#                               iteration=iteration,\n",
    "#                               objective=boundary_loss,\n",
    "#                               context={'boundary_loss': boundary_loss})\n",
    "#     study.finalize(trial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinns",
   "language": "python",
   "name": "pinns"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
