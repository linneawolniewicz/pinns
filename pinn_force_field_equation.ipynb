{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Physics Informed Neural Networks\n",
    "\n",
    "This notebook implements PINNs from Raissi et al. 2017. Specifically, the notebook adapts the code implementation of Data-Driven Solutions of Nonlinear Partial Differential Equations from https://github.com/maziarraissi/PINNs, and the code by Michael Ito, to solve the force-field equation for solar modulation of cosmic rays. Michael Ito's code adaption use the TF2 API where the main mechanisms of the PINN arise in the train_step function efficiently computing higher order derivatives of custom loss functions through the use of the GradientTape data structure. \n",
    "\n",
    "In this application, our PINN is $h(r, p) = \\frac{\\partial f}{\\partial r} + \\frac{RV}{3k} \\frac{\\partial f}{\\partial p}$ where $k=\\beta(p)k_1(r)k_2(r)$ and $\\beta = \\frac{p}{\\sqrt{p^2 + M^2}}$. We will approximate $f(r, p)$ using a neural network.\n",
    "\n",
    "We have no initial data, but our boundary data will be given by $f(r_{HP}, p) = \\frac{J(r_{HP}, T)}{p^2} = \\frac{(T+M)^\\gamma}{p^2}$, where $r_{HP} = 120$ AU (i.e. the radius of Heliopause), $M=0.938$ GeV, $\\gamma$ is between $-2$ and $-3$, and $T = \\sqrt{p^2 + M^2} - M$. Or, vice versa, $p = \\sqrt{T^2 + 2TM}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 16:30:32.144165: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/system/CUDA/11.0.2/nvvm/lib64:/opt/apps/software/system/CUDA/11.0.2/extras/CUPTI/lib64:/opt/apps/software/system/CUDA/11.0.2/lib:/opt/apps/software/lib/slurm-drmaa/1.1.3/lib:/opt/apps/software/lib/libevent/2.1.8/lib:/opt/apps/software/devel/PCRE/8.41-GCCcore-7.3.0/lib:/opt/apps/software/lang/Perl/5.28.0-GCCcore-7.3.0/lib:/opt/apps/software/tools/expat/2.2.5-GCCcore-7.3.0/lib:/opt/apps/software/lang/Python/2.7.15-foss-2018b/lib/python2.7/site-packages/numpy-1.14.5-py2.7-linux-x86_64.egg/numpy/core/lib:/opt/apps/software/lang/Python/2.7.15-foss-2018b/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-7.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-7.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-7.3.0/lib:/opt/apps/software/devel/SQLite/3.24.0-GCCcore-7.3.0/lib:/opt/apps/software/lang/Tcl/8.6.8-GCCcore-7.3.0/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-7.3.0/lib:/opt/apps/software/devel/ncurses/6.1-GCCcore-7.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6-GCCcore-7.3.0/lib:/opt/apps/software/numlib/ScaLAPACK/2.0.2-gompi-2018b-OpenBLAS-0.3.1/lib:/opt/apps/software/numlib/FFTW/3.3.8-gompi-2018b/lib:/opt/apps/software/numlib/OpenBLAS/0.3.1-GCC-7.3.0-2.30/lib:/opt/apps/software/system/hwloc/1.11.10-GCCcore-7.3.0/lib:/opt/apps/software/system/libpciaccess/0.14-GCCcore-7.3.0/lib:/opt/apps/software/lib/libxml2/2.9.8-GCCcore-7.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-7.3.0/lib:/opt/apps/software/tools/numactl/2.0.11-GCCcore-7.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-7.3.0/lib:/opt/apps/software/tools/binutils/2.30-GCCcore-7.3.0/lib:/opt/apps/software/compiler/GCCcore/7.3.0/lib/gcc/x86_64-pc-linux-gnu/7.3.0:/opt/apps/software/compiler/GCCcore/7.3.0/lib64:/opt/apps/software/compiler/GCCcore/7.3.0/lib:/opt/apps/software/tools/zsh/5.7.1/lib\n",
      "2022-09-30 16:30:32.147752: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/system/CUDA/11.0.2/nvvm/lib64:/opt/apps/software/system/CUDA/11.0.2/extras/CUPTI/lib64:/opt/apps/software/system/CUDA/11.0.2/lib:/opt/apps/software/lib/slurm-drmaa/1.1.3/lib:/opt/apps/software/lib/libevent/2.1.8/lib:/opt/apps/software/devel/PCRE/8.41-GCCcore-7.3.0/lib:/opt/apps/software/lang/Perl/5.28.0-GCCcore-7.3.0/lib:/opt/apps/software/tools/expat/2.2.5-GCCcore-7.3.0/lib:/opt/apps/software/lang/Python/2.7.15-foss-2018b/lib/python2.7/site-packages/numpy-1.14.5-py2.7-linux-x86_64.egg/numpy/core/lib:/opt/apps/software/lang/Python/2.7.15-foss-2018b/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-7.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-7.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-7.3.0/lib:/opt/apps/software/devel/SQLite/3.24.0-GCCcore-7.3.0/lib:/opt/apps/software/lang/Tcl/8.6.8-GCCcore-7.3.0/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-7.3.0/lib:/opt/apps/software/devel/ncurses/6.1-GCCcore-7.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6-GCCcore-7.3.0/lib:/opt/apps/software/numlib/ScaLAPACK/2.0.2-gompi-2018b-OpenBLAS-0.3.1/lib:/opt/apps/software/numlib/FFTW/3.3.8-gompi-2018b/lib:/opt/apps/software/numlib/OpenBLAS/0.3.1-GCC-7.3.0-2.30/lib:/opt/apps/software/system/hwloc/1.11.10-GCCcore-7.3.0/lib:/opt/apps/software/system/libpciaccess/0.14-GCCcore-7.3.0/lib:/opt/apps/software/lib/libxml2/2.9.8-GCCcore-7.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-7.3.0/lib:/opt/apps/software/tools/numactl/2.0.11-GCCcore-7.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-7.3.0/lib:/opt/apps/software/tools/binutils/2.30-GCCcore-7.3.0/lib:/opt/apps/software/compiler/GCCcore/7.3.0/lib/gcc/x86_64-pc-linux-gnu/7.3.0:/opt/apps/software/compiler/GCCcore/7.3.0/lib64:/opt/apps/software/compiler/GCCcore/7.3.0/lib:/opt/apps/software/tools/zsh/5.7.1/lib\n",
      "2022-09-30 16:30:32.147779: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sherpa\n",
    "import pickle as pkl\n",
    "\n",
    "tf.config.list_physical_devices(device_type=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants  \n",
    "m = 0.938 # GeV/c^2\n",
    "gamma = -3 # Between -2 and -3\n",
    "size = 512 # size of r, T, p, and f_boundary\n",
    "\n",
    "# Create intial data\n",
    "T = np.logspace(np.log10(0.001), np.log10(1000), size).flatten()[:,None] # GeV\n",
    "p = (np.sqrt((T+m)**2-m**2)).flatten()[:,None] # GeV/c\n",
    "r = np.logspace(np.log10(119*150e6), np.log10(120*150e6), size).flatten()[:,None] # km\n",
    "f_boundary = ((T + m)**gamma)/(p**2) # particles/(m^3 (GeV/c)^3)\n",
    "\n",
    "# Take the log of all input data\n",
    "r = np.log(r)\n",
    "T = np.log(T)\n",
    "p = np.log(p)\n",
    "f_boundary = np.log(f_boundary)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array([p[0], r[0]]) # (p, r) in (GeV, AU)\n",
    "ub = np.array([p[-1], r[-1]]) # (p, r) in (GeV, AU)\n",
    "\n",
    "# Flatten and transpose data for ML\n",
    "P, R = np.meshgrid(p, r)\n",
    "P_star = np.hstack((P.flatten()[:,None], R.flatten()[:,None]))\n",
    "\n",
    "# Check inputs\n",
    "# print(f'r: {r.shape}, p: {p.shape}, T: {T.shape}, f_boundary: {f_boundary.shape}, P_star: {P_star.shape}, lb: {lb}, ub:{ub}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINN Class\n",
    "\n",
    "The PINN class subclasses the Keras Model so that we can implement our custom fit and train_step functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Description: Defines the class for a PINN model implementing train_step, fit, and predict functions. Note, it is necessary \n",
    "to design each PINN seperately for each system of PDEs since the train_step is customized for a specific system. \n",
    "This PINN in particular solves the force-field equation for solar modulation of cosmic rays. Once trained, the PINN can predict the solution space given \n",
    "domain bounds and the input space. \n",
    "'''\n",
    "class PINN(tf.keras.Model):\n",
    "    def __init__(self, inputs, outputs, lower_bound, upper_bound, p, r, f_boundary, size, n_samples=20000, n_boundary=50):\n",
    "        super(PINN, self).__init__(inputs=inputs, outputs=outputs)\n",
    "        self.lower_bound = lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "        self.p = p\n",
    "        self.r = r\n",
    "        self.f_boundary = f_boundary\n",
    "        self.n_samples = n_samples\n",
    "        self.n_boundary = n_boundary\n",
    "        self.size = size\n",
    "        \n",
    "    '''\n",
    "    Description: A system of PDEs are determined by 2 types of equations: the main partial differential equations \n",
    "    and the boundary value equations. These two equations will serve as loss functions which \n",
    "    we train the PINN to satisfy. If a PINN can satisfy BOTH equations, the system is solved. Since there are 2 types of \n",
    "    equations (PDE, Boundary Value), we will need 2 types of inputs. Each input is composed of a spatial \n",
    "    variable 'r' and a momentum variable 'p'. The different types of (p, r) pairs are described below.\n",
    "    \n",
    "    Inputs: \n",
    "        p, r: (batchsize, 1) shaped arrays : These inputs are used to derive the main partial differential equation loss.\n",
    "        Train step first feeds (p, r) through the PINN for the forward propagation. This expression is PINN(p, r) = f. \n",
    "        Next, the partials f_p and f_r are obtained. We utilize TF2s GradientTape data structure to obtain all partials. \n",
    "        Once we obtain these partials, we can compute the main PDE loss and optimize weights w.r.t. to the loss. \n",
    "        \n",
    "        p_boundary, r_boundary : (boundary_batchsize, 1) shaped arrays : These inputs are used to derive the boundary value\n",
    "        equations. The boundary value loss relies on target data (**not an equation**), so we can just measure the MAE of \n",
    "        PINN(p_boundary, r_boundary) = f_pred_boundary and boundary_f.\n",
    "        \n",
    "        f_boundary: (boundary_batchsize, 1) shaped arrays : This is the target data for the boundary value inputs\n",
    "        \n",
    "        alpha = weight on pinn_loss\n",
    "        \n",
    "    Outputs: sum_loss, pinn_loss, boundary_loss\n",
    "    '''\n",
    "    def train_step(self, p, r, p_boundary, r_boundary, f_boundary, alpha):\n",
    "        with tf.GradientTape(persistent=True) as t2: \n",
    "            with tf.GradientTape(persistent=True) as t1: \n",
    "                # Forward pass P (PINN data)\n",
    "                P = tf.concat((p, r), axis=1)\n",
    "                f = self.tf_call(P)\n",
    "\n",
    "                # Forward pass P_boundary (boundary condition data)\n",
    "                P_boundary = tf.concat((p_boundary, r_boundary), axis=1)\n",
    "                f_pred_boundary = self.tf_call(P_boundary)\n",
    "\n",
    "                # Calculate boundary loss\n",
    "                boundary_loss = tf.math.reduce_mean(tf.math.abs(f_pred_boundary - f_boundary))\n",
    "\n",
    "            # Calculate first-order PINN gradients\n",
    "            f_p = t1.gradient(f, p)\n",
    "            f_r = t1.gradient(f, r)\n",
    "            print(f'f_r: {f_r[-1]}, r: {tf.math.exp(r)[-1]/150e6}, f: {tf.math.exp(f)[-1]}')\n",
    "            \n",
    "            pinn_loss = self.pinn_loss(p, r, f_p, f_r)\n",
    "            total_loss = alpha*pinn_loss + (1-alpha)*boundary_loss\n",
    "        \n",
    "        # Backpropagation\n",
    "        gradients = t2.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Return losses\n",
    "        return pinn_loss.numpy(), boundary_loss.numpy()\n",
    "    \n",
    "    '''\n",
    "    Description: The fit function used to iterate through epoch * steps_per_epoch steps of train_step. \n",
    "    \n",
    "    Inputs: \n",
    "        P_predict: (N, 2) array: Input data for entire spatial and temporal domain. Used for vizualization for\n",
    "        predictions at the end of each epoch. Michael created a very pretty video file with it. \n",
    "        \n",
    "        alpha: weight on pinn_loss\n",
    "        \n",
    "        batchsize: batchsize for (p, r) in train step\n",
    "        \n",
    "        boundary_batchsize: batchsize for (x_lower, t_boundary) and (x_upper, t_boundary) in train step\n",
    "        \n",
    "        epochs: epochs\n",
    "        \n",
    "        lr: learning rate\n",
    "        \n",
    "        size: size of the prediction data (i.e. len(p) and len(r))\n",
    "        \n",
    "        save: Whether or not to save the model to a checkpoint every 10 epochs\n",
    "        \n",
    "        load_epoch: If -1, a saved model will not be loaded. Otherwise, the model will be \n",
    "        loaded from the provided epoch\n",
    "        \n",
    "        lr_decay: If -1, learning rate will not be decayed. Otherwise, lr = lr_decay*lr if loss doesn't\n",
    "        decrease for 3 epochs\n",
    "        \n",
    "        weight_change: If -1, alpha will not be changed. Otherwise, alpha = weight_change*alpha if loss \n",
    "        doesn't decrease for 3 epochs\n",
    "        \n",
    "        patience: Number of epochs to check whether loss has decreased before updating lr or alpha\n",
    "        \n",
    "        filename: Name for the checkpoint file\n",
    "    \n",
    "    Outputs: Losses for each equation (Total, PDE, Boundary Value), and predictions for each epoch.\n",
    "    '''\n",
    "    def fit(self, P_predict, alpha=1, batchsize=64, boundary_batchsize=16, epochs=20, lr=3e-3, size=256, \n",
    "            save=False, load_epoch=-1, lr_decay=-1, weight_change=-1, patience=3, filename=''):\n",
    "        # If load == True, load the weights\n",
    "        if load_epoch != -1:\n",
    "            name = './ckpts/pinn_' + filename + '_epoch_' + str(load_epoch)\n",
    "            self.load_weights(name)\n",
    "        \n",
    "        # Initialize losses as zeros\n",
    "        steps_per_epoch = np.ceil(self.n_samples / batchsize).astype(int)\n",
    "        total_pinn_loss = np.zeros((epochs, ))\n",
    "        total_boundary_loss = np.zeros((epochs, ))\n",
    "        predictions = np.zeros((size**2, 1, epochs))\n",
    "        \n",
    "        # For each epoch, sample new values in the PINN and boundary areas and pass them to train_step\n",
    "        for epoch in range(epochs):\n",
    "            # Compile\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "            self.compile(optimizer=opt)\n",
    "\n",
    "            # Reset loss variables\n",
    "            sum_loss = np.zeros((steps_per_epoch,))\n",
    "            pinn_loss = np.zeros((steps_per_epoch,))\n",
    "            boundary_loss = np.zeros((steps_per_epoch,))\n",
    "            \n",
    "            # For each step, get PINN and boundary variables and pass them to train_step\n",
    "            for step in range(steps_per_epoch):\n",
    "                # Get PINN p and r variables via uniform distribution sampling between lower and upper bounds\n",
    "                p = tf.Variable(tf.random.uniform((batchsize, 1), minval=self.lower_bound[0], maxval=self.upper_bound[0]))\n",
    "                r = tf.Variable(tf.random.uniform((batchsize, 1), minval=self.lower_bound[1], maxval=self.upper_bound[1]))\n",
    "                \n",
    "                # Randomly sample boundary_batchsize from p_boundary and f_boundary\n",
    "                p_idx = np.expand_dims(np.random.choice(self.f_boundary.shape[0], boundary_batchsize, replace=False), axis=1)\n",
    "                p_boundary = self.p[p_idx]\n",
    "                f_boundary = self.f_boundary[p_idx]\n",
    "                \n",
    "                # Create r_boundary array = r_HP\n",
    "                upper_bound = np.zeros((boundary_batchsize, 1))\n",
    "                upper_bound[:] = self.upper_bound[1]\n",
    "                r_boundary = tf.Variable(upper_bound, dtype=tf.float32)\n",
    "                \n",
    "                # Pass variables through the model via train_step and get losses\n",
    "                losses = self.train_step(p, r, p_boundary, r_boundary, f_boundary, alpha)\n",
    "                pinn_loss[step] = losses[0]\n",
    "                boundary_loss[step] = losses[1]\n",
    "            \n",
    "            # Calculate and print total losses for the epoch\n",
    "            total_pinn_loss[epoch] = np.sum(pinn_loss)\n",
    "            total_boundary_loss[epoch] = np.sum(boundary_loss)\n",
    "            print(f'Training loss for epoch {epoch}: pinn: {total_pinn_loss[epoch]:.4f}, boundary: {total_boundary_loss[epoch]:.4f}, total: {(total_boundary_loss[epoch]+total_pinn_loss[epoch]):.4f}')\n",
    "            \n",
    "            # Predict\n",
    "            predictions[:, :, epoch] = self.predict(P_predict, size)\n",
    "            \n",
    "            # Determine if loss has decreased since the last patience epoch\n",
    "            if (epoch > patience):\n",
    "                hasDecreased = False\n",
    "                if (total_pinn_loss[epoch] + total_boundary_loss[epoch]) < (total_pinn_loss[epoch-patience] + total_boundary_loss[epoch-patience]):\n",
    "                    hasDecreased = True\n",
    "                        \n",
    "                # If loss hasn't decreased for the past 2 epochs, decrease lr by lr_decay\n",
    "                if (lr_decay != -1) & (not hasDecreased):\n",
    "                    lr = lr_decay*lr\n",
    "\n",
    "                # If pinn loss hasn't decreased for the past 2 epochs, increase alpha by weight_change\n",
    "                if (weight_change != -1) & (not hasDecreased):\n",
    "                    alpha = np.tanh(weight_change*alpha)\n",
    "\n",
    "            # If the epoch is a multiple of 10, save to a checkpoint\n",
    "            if (epoch%10 == 0) & (save == True):\n",
    "                name = './ckpts/pinn_' + filename + '_epoch_' + str(epoch)\n",
    "                self.save_weights(name, overwrite=True, save_format=None, options=None)\n",
    "        \n",
    "        # Return epoch losses\n",
    "        return total_pinn_loss, total_boundary_loss, predictions\n",
    "    \n",
    "    # Predict for some P's the value of the neural network f(r, p)\n",
    "    def predict(self, P, size, batchsize=2048):\n",
    "        steps_per_epoch = np.ceil(P.shape[0] / batchsize).astype(int)\n",
    "        preds = np.zeros((size**2, 1))\n",
    "        \n",
    "        # For each step calculate start and end index values for prediction data\n",
    "        for step in range(steps_per_epoch):\n",
    "            start_idx = step * 64\n",
    "            \n",
    "            # If last step of the epoch, end_idx is shape-1. Else, end_idx is start_idx + 64 \n",
    "            if step == steps_per_epoch - 1:\n",
    "                end_idx = P.shape[0] - 1\n",
    "            else:\n",
    "                end_idx = start_idx + 64\n",
    "                \n",
    "            # Pass prediction data through the model\n",
    "            preds[start_idx:end_idx, :] = self.tf_call(P[start_idx:end_idx, :]).numpy()\n",
    "        \n",
    "        # Return f\n",
    "        return preds\n",
    "    \n",
    "    def evaluate(self, ): \n",
    "        pass\n",
    "    \n",
    "    # pinn_loss calculates the PINN loss by calculating the MAE of the pinn function\n",
    "    @tf.function\n",
    "    def pinn_loss(self, p, r, f_p, f_r): # To-do: add loss pass-through!\n",
    "        # Note: p and r are taken out of logspace for the PINN calculation\n",
    "        p = tf.math.exp(p) # GeV/c\n",
    "        r = tf.math.exp(r) # km\n",
    "        V = 400 # 400 km/s\n",
    "        m = 0.938 # GeV/c^2\n",
    "        k_0 = 1e11 # km^2/s\n",
    "        k_1 = k_0 * tf.math.divide(r, 150e6) # km^2/s\n",
    "        k_2 = p # unitless, k_2 = p/p0 and p0 = 1 GeV/c\n",
    "        R = p # GV\n",
    "        beta = tf.math.divide(p, tf.math.sqrt(tf.math.square(p) + tf.math.square(m))) \n",
    "        k = beta*k_1*k_2\n",
    "        \n",
    "        # Calculate physics loss\n",
    "        l_f = tf.math.reduce_mean(tf.math.abs(f_r + (tf.math.divide(R*V, 3*k) * f_p)))\n",
    "        \n",
    "        return l_f\n",
    "    \n",
    "    # tf_call passes inputs through the neural network\n",
    "    @tf.function\n",
    "    def tf_call(self, inputs): \n",
    "        return self.call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_r: [0.11243305], r: [119.888405], f: [0.24094352]\n",
      "f_r: [-0.40531927], r: [119.46361], f: [2.4677431e-17]\n",
      "f_r: [3.817642], r: [119.0201], f: [inf]\n",
      "f_r: [0.8145855], r: [119.91813], f: [7.903894e+10]\n",
      "f_r: [-0.18340082], r: [119.795135], f: [1.7358079e-07]\n",
      "f_r: [-0.0682313], r: [119.48889], f: [2.481569e-07]\n",
      "f_r: [0.02960273], r: [119.7675], f: [0.00191598]\n",
      "f_r: [0.15711254], r: [119.47318], f: [0.08355512]\n",
      "f_r: [0.17032117], r: [119.95199], f: [0.07672039]\n",
      "f_r: [0.15539767], r: [119.88017], f: [2.2920258]\n",
      "f_r: [0.81583107], r: [119.523315], f: [0.00038325]\n",
      "f_r: [0.33480275], r: [119.85365], f: [3.5493188e-12]\n",
      "f_r: [0.20989785], r: [119.78897], f: [20.128105]\n",
      "f_r: [0.03791428], r: [119.26872], f: [8.505934e-08]\n",
      "f_r: [0.20013623], r: [119.46314], f: [1.9118847e-13]\n",
      "f_r: [1.1151339], r: [119.86371], f: [0.0181007]\n",
      "f_r: [0.05704463], r: [119.995926], f: [16.250704]\n",
      "f_r: [0.12915403], r: [119.94559], f: [4.4815038e-10]\n",
      "f_r: [0.55110043], r: [119.98219], f: [0.00516541]\n",
      "f_r: [0.15273924], r: [119.80565], f: [7.918914e-11]\n",
      "f_r: [0.81143165], r: [119.80291], f: [0.00059004]\n",
      "f_r: [0.27989712], r: [119.09482], f: [16.427404]\n",
      "f_r: [0.19834062], r: [119.51922], f: [2.24355]\n",
      "f_r: [0.29867166], r: [119.68187], f: [1.0760355]\n",
      "f_r: [0.43735114], r: [119.697845], f: [2.4299217e-12]\n",
      "f_r: [0.06598603], r: [119.80314], f: [173.55237]\n",
      "f_r: [1.0463026], r: [119.05121], f: [1.3838439e-08]\n",
      "f_r: [0.48070362], r: [119.47158], f: [5.9216236e-14]\n",
      "f_r: [0.9987178], r: [119.40483], f: [2.6902848e-11]\n",
      "f_r: [0.53766704], r: [119.838104], f: [6.964692e-05]\n",
      "f_r: [0.343934], r: [119.95107], f: [5.660108e-10]\n",
      "f_r: [0.577773], r: [119.31218], f: [2.5736663e-06]\n",
      "f_r: [0.51830804], r: [119.96777], f: [1.5125553e-07]\n",
      "f_r: [0.15142787], r: [119.755844], f: [1.5107048]\n",
      "f_r: [0.5565733], r: [119.55432], f: [7.305031e-08]\n",
      "f_r: [0.58580554], r: [119.78121], f: [5.8385033e-12]\n",
      "f_r: [0.9248329], r: [119.96298], f: [4.910829e-10]\n",
      "f_r: [0.20109458], r: [119.54748], f: [2.2734462e-11]\n",
      "f_r: [0.15516436], r: [119.51398], f: [4.415356e-11]\n",
      "f_r: [0.13081667], r: [119.11481], f: [1.0044408e-11]\n",
      "Training loss for epoch 0: pinn: 16.6368, boundary: 357.3709, total: 374.0077\n",
      "f_r: [0.0802629], r: [119.13048], f: [3.4167642e-13]\n",
      "f_r: [0.26783404], r: [119.05371], f: [766755.94]\n",
      "f_r: [-0.0980899], r: [119.46907], f: [10.036963]\n",
      "f_r: [0.01299755], r: [119.64763], f: [0.1647735]\n",
      "f_r: [-0.03226281], r: [119.682556], f: [0.00493795]\n",
      "f_r: [0.07906184], r: [119.34222], f: [0.00098975]\n",
      "f_r: [0.05875405], r: [119.09618], f: [0.00156911]\n",
      "f_r: [0.05036268], r: [119.261665], f: [0.00190205]\n",
      "f_r: [0.13330783], r: [119.67068], f: [0.00045887]\n",
      "f_r: [0.0137842], r: [119.16752], f: [0.00214293]\n",
      "f_r: [0.03227343], r: [119.508736], f: [0.00545589]\n",
      "f_r: [0.13381197], r: [119.90395], f: [1.2095844e-08]\n",
      "f_r: [0.15206009], r: [119.1523], f: [1.1488749]\n",
      "f_r: [0.69403404], r: [119.75814], f: [1.5056128e-05]\n",
      "f_r: [0.5254017], r: [119.91493], f: [3.873205e-11]\n",
      "f_r: [0.53117085], r: [119.584206], f: [5.1614617e-08]\n",
      "f_r: [0.18689424], r: [119.27555], f: [4.8683604e-09]\n",
      "f_r: [-0.0408068], r: [119.05031], f: [1.0079577e-09]\n",
      "f_r: [0.22204903], r: [119.62961], f: [3.7747068e-05]\n",
      "f_r: [0.03014387], r: [119.840614], f: [0.40871504]\n",
      "f_r: [0.22613737], r: [119.427155], f: [1.9623647e-08]\n",
      "f_r: [0.04593841], r: [119.26076], f: [0.55519724]\n",
      "f_r: [0.36925066], r: [119.648994], f: [9.89207e-10]\n",
      "f_r: [-0.04865243], r: [119.11322], f: [1.456368e-12]\n",
      "f_r: [0.65604484], r: [119.087326], f: [0.0001679]\n",
      "f_r: [0.06743326], r: [119.03668], f: [318.5215]\n",
      "f_r: [0.04846699], r: [119.857086], f: [98.178825]\n",
      "f_r: [0.5732916], r: [119.82394], f: [2.382949e-09]\n",
      "f_r: [0.07965031], r: [119.58374], f: [46.901028]\n",
      "f_r: [0.8190031], r: [119.4333], f: [3.7507952e-08]\n",
      "f_r: [0.19548817], r: [119.856384], f: [2.2516782]\n",
      "f_r: [0.05710156], r: [119.80772], f: [4.6008905e-13]\n",
      "f_r: [0.5016434], r: [119.71429], f: [0.00018895]\n",
      "f_r: [0.3022964], r: [119.27077], f: [0.3960439]\n",
      "f_r: [0.2052167], r: [119.5671], f: [3.1981647]\n",
      "f_r: [0.07149236], r: [119.61865], f: [138.73361]\n",
      "f_r: [0.22001553], r: [119.54931], f: [27.204136]\n",
      "f_r: [0.2968371], r: [119.19617], f: [2.4572944e-12]\n",
      "f_r: [0.41062388], r: [119.68918], f: [1.4611408e-05]\n",
      "f_r: [0.6837755], r: [119.76681], f: [3.6992176e-10]\n",
      "Training loss for epoch 1: pinn: 9.6169, boundary: 191.5880, total: 201.2049\n",
      "f_r: [0.057052], r: [119.61386], f: [922.907]\n",
      "f_r: [0.0574152], r: [119.520134], f: [5.300399e-07]\n",
      "f_r: [0.41519222], r: [119.795135], f: [2.9973046e-15]\n",
      "f_r: [0.16547033], r: [119.512146], f: [0.10385721]\n",
      "f_r: [0.28559706], r: [119.905556], f: [8.622913]\n",
      "f_r: [0.03645927], r: [119.35269], f: [232.84682]\n",
      "f_r: [0.31008455], r: [119.67274], f: [1.8739022]\n",
      "f_r: [-0.01089436], r: [119.69579], f: [4.1334662]\n",
      "f_r: [0.31531826], r: [119.5085], f: [0.01685963]\n",
      "f_r: [0.3371634], r: [119.100716], f: [6.346356e-05]\n",
      "f_r: [0.03756041], r: [119.33471], f: [0.03438535]\n",
      "f_r: [0.30270815], r: [119.822784], f: [0.00151976]\n",
      "f_r: [0.05697155], r: [119.09277], f: [2.0587531e-07]\n",
      "f_r: [0.4978203], r: [119.509865], f: [0.06108591]\n",
      "f_r: [0.4222796], r: [119.363846], f: [7.013837e-05]\n",
      "f_r: [0.38195038], r: [119.74443], f: [0.02279214]\n",
      "f_r: [0.44967306], r: [119.10504], f: [748.81726]\n",
      "f_r: [0.850016], r: [119.84794], f: [4.6255227e-06]\n",
      "f_r: [0.0244402], r: [119.76568], f: [1.0574987e-11]\n",
      "f_r: [0.6610711], r: [119.75493], f: [1.0329192e-07]\n",
      "f_r: [0.9787488], r: [119.57279], f: [8.53246e-10]\n",
      "f_r: [0.510491], r: [119.97487], f: [135.40366]\n",
      "f_r: [0.50467736], r: [119.5215], f: [4251.2285]\n",
      "f_r: [0.43472815], r: [119.16867], f: [8.019225e-05]\n",
      "f_r: [0.3428703], r: [119.97694], f: [1.8808943e-13]\n",
      "f_r: [1.7871671], r: [119.023285], f: [3.4322536e-08]\n",
      "f_r: [0.5065345], r: [119.80222], f: [3.0356608e-05]\n",
      "f_r: [0.39938542], r: [119.34267], f: [4.4339834e-14]\n",
      "f_r: [1.0772641], r: [119.30194], f: [4.5081115e-06]\n",
      "f_r: [0.54930717], r: [119.24028], f: [0.00895798]\n",
      "f_r: [0.23427385], r: [119.53518], f: [1.6361444e-14]\n",
      "f_r: [0.52440107], r: [119.7168], f: [0.72386825]\n",
      "f_r: [0.39097404], r: [119.858215], f: [1.5173647e-11]\n",
      "f_r: [0.4241418], r: [119.579185], f: [1676.6514]\n",
      "f_r: [0.5121491], r: [119.77093], f: [0.07813398]\n",
      "f_r: [0.510579], r: [119.09914], f: [0.00012975]\n",
      "f_r: [0.90526325], r: [119.21095], f: [2.9820474e-10]\n",
      "f_r: [0.627089], r: [119.23187], f: [7.860872e-11]\n",
      "f_r: [0.38236082], r: [119.908066], f: [15.258395]\n",
      "f_r: [0.5208895], r: [119.60177], f: [2.8055475e-12]\n",
      "Training loss for epoch 2: pinn: 18.6117, boundary: 194.9656, total: 213.5773\n",
      "f_r: [0.29666436], r: [119.50121], f: [0.07338393]\n",
      "f_r: [0.73365027], r: [119.088684], f: [4.1107735e+09]\n",
      "f_r: [0.6077583], r: [119.22346], f: [2.9161913]\n",
      "f_r: [0.32166857], r: [119.42351], f: [5.11052]\n",
      "f_r: [0.41621503], r: [119.946266], f: [2.2259945e-14]\n",
      "f_r: [0.44463515], r: [119.89413], f: [5.237183e-13]\n",
      "f_r: [0.01357121], r: [119.30625], f: [1.0573167e-12]\n",
      "f_r: [0.17421862], r: [119.31922], f: [0.00061363]\n",
      "f_r: [0.21121277], r: [119.73849], f: [0.04533817]\n",
      "f_r: [1.2284259], r: [119.648544], f: [9.325994e-05]\n",
      "f_r: [0.2773989], r: [119.33516], f: [4435.8486]\n",
      "f_r: [0.09466138], r: [119.388435], f: [3.892568e-07]\n",
      "f_r: [0.00954317], r: [119.20891], f: [5.3940617e-08]\n",
      "f_r: [0.19467796], r: [119.594246], f: [0.28114572]\n",
      "f_r: [0.13247965], r: [119.93482], f: [8.756758e-09]\n",
      "f_r: [0.15020454], r: [119.50554], f: [2.2578355e-09]\n",
      "f_r: [0.04302778], r: [119.52856], f: [7.911109e-11]\n",
      "f_r: [0.14869615], r: [119.31809], f: [1.8550807e-10]\n",
      "f_r: [1.3305062], r: [119.07438], f: [0.00012416]\n",
      "f_r: [0.2731475], r: [119.1773], f: [0.06273157]\n",
      "f_r: [0.22899407], r: [119.87377], f: [115.22967]\n",
      "f_r: [0.27839294], r: [119.525375], f: [2.1146274e-11]\n",
      "f_r: [0.2371956], r: [119.79354], f: [125.59862]\n",
      "f_r: [0.26412544], r: [119.57531], f: [278.30588]\n",
      "f_r: [0.4309256], r: [119.81823], f: [6.1804513e-09]\n",
      "f_r: [1.3093143], r: [119.06665], f: [1.468822e-07]\n",
      "f_r: [0.22945821], r: [119.01443], f: [15.244639]\n",
      "f_r: [0.3762412], r: [119.25257], f: [4.002797e-15]\n",
      "f_r: [0.26988915], r: [119.51306], f: [6.632456]\n",
      "f_r: [0.7673454], r: [119.680954], f: [1.5710876e-09]\n",
      "f_r: [0.5995185], r: [119.18754], f: [6.8731167e-12]\n",
      "f_r: [0.77425116], r: [119.52126], f: [1.9516229e-11]\n",
      "f_r: [0.72771066], r: [119.46269], f: [3.3690143e-12]\n",
      "f_r: [0.27182993], r: [119.192535], f: [0.41274533]\n",
      "f_r: [0.27440965], r: [119.654015], f: [1.6952197e-07]\n",
      "f_r: [0.37810814], r: [119.2164], f: [5.071161e-07]\n",
      "f_r: [0.25470954], r: [119.38479], f: [214.59305]\n",
      "f_r: [0.46550325], r: [119.38752], f: [2.5932881e-15]\n",
      "f_r: [0.28389966], r: [119.274864], f: [21.66198]\n",
      "f_r: [0.40934822], r: [119.64718], f: [6.110647e-06]\n",
      "Training loss for epoch 3: pinn: 14.5016, boundary: 143.1588, total: 157.6605\n",
      "f_r: [0.25239497], r: [119.55798], f: [0.01588117]\n",
      "f_r: [0.7401839], r: [119.62482], f: [0.05088563]\n",
      "f_r: [0.43021488], r: [119.09914], f: [8932.743]\n",
      "f_r: [0.19502231], r: [119.61272], f: [1.8783348e-07]\n",
      "f_r: [0.23568967], r: [119.56459], f: [1.945664e-12]\n",
      "f_r: [0.3035938], r: [119.238014], f: [1.8517098e-12]\n",
      "f_r: [0.29990357], r: [119.977844], f: [2.612833e-09]\n",
      "f_r: [0.11400303], r: [119.40528], f: [0.00020739]\n",
      "f_r: [0.13942516], r: [119.38297], f: [0.02133008]\n",
      "f_r: [0.16060285], r: [119.682556], f: [8.820003e-09]\n",
      "f_r: [0.24709737], r: [119.133896], f: [2.7531156e-08]\n",
      "f_r: [0.3295507], r: [119.44652], f: [1.4236753e-06]\n",
      "f_r: [-0.02455459], r: [119.54748], f: [14.142574]\n",
      "f_r: [0.75194], r: [119.69716], f: [3.8132308e-10]\n",
      "f_r: [0.01362828], r: [119.111626], f: [1.0609179e-17]\n",
      "f_r: [0.14266679], r: [119.98837], f: [17.828459]\n",
      "f_r: [0.14861585], r: [119.79423], f: [0.9350107]\n",
      "f_r: [0.2249883], r: [119.04303], f: [4.197219e-10]\n",
      "f_r: [0.06329515], r: [119.46885], f: [2.1695e-10]\n",
      "f_r: [0.13234366], r: [119.63896], f: [124.733505]\n",
      "f_r: [0.30753836], r: [119.19094], f: [1.7165629e-06]\n",
      "f_r: [0.31891656], r: [119.855255], f: [0.00023519]\n",
      "f_r: [0.1661575], r: [119.12527], f: [8.818817]\n",
      "f_r: [0.0570609], r: [119.95954], f: [1.5753642e-12]\n",
      "f_r: [0.5679223], r: [119.60587], f: [1.3931967e-10]\n",
      "f_r: [0.48013857], r: [119.40438], f: [1.1855722e-05]\n",
      "f_r: [0.13805097], r: [119.51078], f: [89.86634]\n",
      "f_r: [0.15611202], r: [119.48024], f: [38.704967]\n",
      "f_r: [0.11759783], r: [119.95107], f: [2.5512066e-13]\n",
      "f_r: [0.09072008], r: [119.623665], f: [7.935257e-15]\n",
      "f_r: [0.23527229], r: [119.93278], f: [0.01893707]\n",
      "f_r: [0.05858836], r: [119.34222], f: [8.82231e-16]\n",
      "f_r: [0.6578424], r: [119.57098], f: [1.4661458e-11]\n",
      "f_r: [0.793981], r: [119.08051], f: [4.76969e-10]\n",
      "f_r: [0.20161514], r: [119.67137], f: [1.2666635e-13]\n",
      "f_r: [0.22084776], r: [119.481606], f: [0.01602239]\n",
      "f_r: [0.61635876], r: [119.20777], f: [7.531556e-12]\n",
      "f_r: [0.3151573], r: [119.432846], f: [1.1647238e-13]\n",
      "f_r: [0.3592831], r: [119.30262], f: [4.877032e-07]\n",
      "f_r: [0.5114674], r: [119.28055], f: [1.4547772e-12]\n",
      "Training loss for epoch 4: pinn: 11.5003, boundary: 118.6418, total: 130.1420\n",
      "f_r: [0.15808073], r: [119.74809], f: [0.41817188]\n",
      "f_r: [0.65150595], r: [119.278496], f: [3.899982e-14]\n",
      "f_r: [0.05132303], r: [119.03305], f: [0.0013677]\n",
      "f_r: [0.07241614], r: [119.75105], f: [0.0294268]\n",
      "f_r: [0.265905], r: [119.196396], f: [3.4591757e-10]\n",
      "f_r: [0.16819684], r: [119.941246], f: [182.79013]\n",
      "f_r: [0.28981817], r: [119.57554], f: [0.19384615]\n",
      "f_r: [0.26406473], r: [119.52719], f: [0.9113011]\n",
      "f_r: [0.17085506], r: [119.255066], f: [0.01910915]\n",
      "f_r: [0.15562242], r: [119.57599], f: [0.00773301]\n",
      "f_r: [0.20474653], r: [119.97876], f: [5.6558674e-06]\n",
      "f_r: [0.1416957], r: [119.202995], f: [0.00551079]\n",
      "f_r: [0.15741697], r: [119.83468], f: [0.00192333]\n",
      "f_r: [0.17838399], r: [119.87537], f: [2.309617e-06]\n",
      "f_r: [0.32100356], r: [119.944435], f: [4.102839e-06]\n",
      "f_r: [0.17621772], r: [119.99707], f: [4.639456e-08]\n",
      "f_r: [0.22160444], r: [119.250755], f: [3.5254295]\n",
      "f_r: [0.11881542], r: [119.4447], f: [2.3624785e-10]\n",
      "f_r: [1.5664717], r: [119.349724], f: [0.00013194]\n",
      "f_r: [0.1252727], r: [119.03032], f: [8.433958e-13]\n",
      "f_r: [0.16764514], r: [119.42306], f: [10.95313]\n",
      "f_r: [0.3195941], r: [119.0612], f: [1.7321476e-08]\n",
      "f_r: [0.7623447], r: [119.3288], f: [0.0003681]\n",
      "f_r: [0.05464444], r: [119.40961], f: [9.9711135e-11]\n",
      "f_r: [0.175049], r: [119.00421], f: [8.540915e-09]\n",
      "f_r: [0.06089808], r: [119.44242], f: [1.0545988e-10]\n",
      "f_r: [0.1569089], r: [119.561165], f: [0.10626522]\n",
      "f_r: [0.5452153], r: [119.95839], f: [1.11555536e-07]\n",
      "f_r: [0.18935908], r: [119.08959], f: [30.90951]\n",
      "f_r: [0.19756559], r: [119.96594], f: [2.702324e-11]\n",
      "f_r: [0.30748352], r: [119.5085], f: [0.0006264]\n",
      "f_r: [0.19713984], r: [119.88519], f: [0.12596957]\n",
      "f_r: [0.6925633], r: [119.59561], f: [8.96836e-11]\n",
      "f_r: [0.22182547], r: [119.27896], f: [389.27158]\n",
      "f_r: [0.9846749], r: [119.34563], f: [4.409287e-06]\n",
      "f_r: [0.39169407], r: [119.38683], f: [2.5643315e-08]\n",
      "f_r: [0.20222534], r: [119.72387], f: [14.212538]\n",
      "f_r: [0.63956773], r: [119.403915], f: [3.227243e-09]\n",
      "f_r: [0.20656523], r: [119.18413], f: [13.192695]\n",
      "f_r: [0.8029008], r: [119.018974], f: [1.7885962e-10]\n",
      "Training loss for epoch 5: pinn: 10.3973, boundary: 155.5123, total: 165.9096\n",
      "f_r: [0.43096972], r: [119.594925], f: [1.9820316e-05]\n",
      "f_r: [0.7717629], r: [119.979], f: [1.3861928]\n",
      "f_r: [0.25166357], r: [119.34267], f: [10.632192]\n",
      "f_r: [0.06139934], r: [119.581696], f: [0.07434699]\n",
      "f_r: [0.2547176], r: [119.95954], f: [2.2878996e-05]\n",
      "f_r: [0.40297967], r: [119.352005], f: [1.4085526e-13]\n",
      "f_r: [0.13565968], r: [119.96183], f: [3.216525e-13]\n",
      "f_r: [0.08559994], r: [119.05984], f: [0.00695945]\n",
      "f_r: [0.19402425], r: [119.39937], f: [9.249687e-05]\n",
      "f_r: [0.14583561], r: [119.61956], f: [0.24297778]\n",
      "f_r: [0.15063491], r: [119.25688], f: [10.994814]\n",
      "f_r: [0.14740363], r: [119.94673], f: [72.76352]\n",
      "f_r: [0.13775088], r: [119.69259], f: [131.032]\n",
      "f_r: [0.10401373], r: [119.071884], f: [7.2352147]\n",
      "f_r: [0.49280947], r: [119.7611], f: [9.754166e-08]\n",
      "f_r: [0.09269861], r: [119.38479], f: [8.424316]\n",
      "f_r: [0.51823986], r: [119.93437], f: [5.2785207e-09]\n",
      "f_r: [0.00019993], r: [119.22254], f: [0.00446494]\n",
      "f_r: [0.3668573], r: [119.21254], f: [9.9696834e-08]\n",
      "f_r: [0.08554178], r: [119.81137], f: [19.231262]\n",
      "f_r: [0.29796782], r: [119.34085], f: [1.6055903e-08]\n",
      "f_r: [-0.00628435], r: [119.28624], f: [8.7891104e-11]\n",
      "f_r: [0.06792845], r: [119.92842], f: [1.3693877]\n",
      "f_r: [0.07394315], r: [119.11094], f: [14.652404]\n",
      "f_r: [0.03718793], r: [119.453575], f: [4.0834236e-13]\n",
      "f_r: [0.11235712], r: [119.1523], f: [174.3824]\n",
      "f_r: [0.24665628], r: [119.36634], f: [0.66804487]\n",
      "f_r: [0.5756843], r: [119.03009], f: [1.313703e-06]\n",
      "f_r: [0.10313262], r: [119.02283], f: [21.30494]\n",
      "f_r: [0.43975654], r: [119.673416], f: [1.4521139e-11]\n",
      "f_r: [0.09641819], r: [119.86622], f: [5.1807837]\n",
      "f_r: [0.24876186], r: [119.511696], f: [0.00057975]\n",
      "f_r: [0.11483007], r: [119.55843], f: [74.000435]\n",
      "f_r: [0.24312332], r: [119.35292], f: [0.00020617]\n",
      "f_r: [0.19994834], r: [119.83696], f: [3.1686195e-14]\n",
      "f_r: [0.18825327], r: [119.72821], f: [9.873485e-06]\n",
      "f_r: [0.66648144], r: [119.25916], f: [5.431413e-12]\n",
      "f_r: [0.27385417], r: [119.91653], f: [1.05294816e-07]\n",
      "f_r: [0.13072835], r: [119.28009], f: [443.1373]\n",
      "f_r: [0.3028767], r: [119.589455], f: [1.2090557e-07]\n",
      "Training loss for epoch 6: pinn: 11.2235, boundary: 108.6714, total: 119.8949\n",
      "f_r: [0.05273913], r: [119.537674], f: [0.00130948]\n",
      "f_r: [0.21369067], r: [119.89389], f: [8066.945]\n",
      "f_r: [0.52608454], r: [119.85365], f: [3.7693178e-07]\n",
      "f_r: [0.05534831], r: [119.747856], f: [0.01156254]\n",
      "f_r: [0.25808576], r: [119.55843], f: [0.0004167]\n",
      "f_r: [0.41700393], r: [119.38069], f: [1.4130018e-06]\n",
      "f_r: [0.15842968], r: [119.61568], f: [1.3952724e-06]\n",
      "f_r: [0.7076696], r: [119.35883], f: [4.2060484e-11]\n",
      "f_r: [0.21227422], r: [119.041], f: [3.3743565e-13]\n",
      "f_r: [0.1232319], r: [119.651054], f: [0.01984397]\n",
      "f_r: [0.23518524], r: [119.22959], f: [0.00206296]\n",
      "f_r: [0.18094988], r: [119.44059], f: [0.32591823]\n",
      "f_r: [0.66128623], r: [119.4456], f: [1.8046225e-07]\n",
      "f_r: [0.08559071], r: [119.9687], f: [92.50893]\n",
      "f_r: [0.67876107], r: [119.226875], f: [9.60791e-11]\n",
      "f_r: [0.14309286], r: [119.7915], f: [0.10073917]\n",
      "f_r: [-0.01763325], r: [119.75562], f: [1.6805789e-15]\n",
      "f_r: [1.2837013], r: [119.4333], f: [4.024709e-05]\n",
      "f_r: [0.15343463], r: [119.56231], f: [7.5422006]\n",
      "f_r: [0.5916016], r: [119.61408], f: [5.7393645e-08]\n",
      "f_r: [0.09292145], r: [119.30352], f: [5.371347e-06]\n",
      "f_r: [0.03978132], r: [119.8141], f: [4.6658764]\n",
      "f_r: [0.37425455], r: [119.27645], f: [1.4587404e-07]\n",
      "f_r: [0.04335081], r: [119.19617], f: [34.046032]\n",
      "f_r: [0.95462346], r: [119.92408], f: [0.00025088]\n",
      "f_r: [0.7962759], r: [119.6442], f: [6.7823365e-08]\n",
      "f_r: [0.5187963], r: [119.55387], f: [3.659688e-07]\n",
      "f_r: [0.05550962], r: [119.35109], f: [0.15966764]\n",
      "f_r: [0.04449013], r: [119.303986], f: [1.9960878]\n",
      "f_r: [0.03259142], r: [119.88109], f: [27.311144]\n",
      "f_r: [0.06952421], r: [119.63325], f: [1.3606536]\n",
      "f_r: [0.63267505], r: [119.05644], f: [6.7425445e-12]\n",
      "f_r: [0.14158258], r: [119.23392], f: [0.21636042]\n",
      "f_r: [0.6261195], r: [119.119804], f: [4.346407e-10]\n",
      "f_r: [0.4270901], r: [119.02895], f: [1.9874524e-07]\n",
      "f_r: [0.45571485], r: [119.15593], f: [3.7686885e-11]\n",
      "f_r: [0.15609975], r: [119.68392], f: [0.00374478]\n",
      "f_r: [0.13088694], r: [119.66247], f: [3.620624e-14]\n",
      "f_r: [0.01506418], r: [119.09572], f: [121.70446]\n",
      "f_r: [0.3448819], r: [119.44334], f: [2.678725e-06]\n",
      "Training loss for epoch 7: pinn: 9.6486, boundary: 98.2139, total: 107.8625\n",
      "f_r: [0.5075668], r: [119.73713], f: [6.324035e-13]\n",
      "f_r: [-0.02005044], r: [119.87811], f: [0.22682515]\n",
      "f_r: [0.3427844], r: [119.07483], f: [6.71353e-08]\n",
      "f_r: [0.37867492], r: [119.11254], f: [1.8851281e-06]\n",
      "f_r: [0.3118021], r: [119.91744], f: [0.00010889]\n",
      "f_r: [0.0429883], r: [119.98106], f: [251.5975]\n",
      "f_r: [0.38300788], r: [119.23027], f: [3.4977016e-05]\n",
      "f_r: [0.32324094], r: [119.774574], f: [1.3181517e-10]\n",
      "f_r: [0.14373472], r: [119.801544], f: [6.207956e-07]\n",
      "f_r: [0.01519713], r: [119.34062], f: [9.906795e-05]\n",
      "f_r: [0.15219992], r: [119.73598], f: [9.199206e-13]\n",
      "f_r: [0.00264179], r: [119.71132], f: [2.5697792e-13]\n",
      "f_r: [0.00017735], r: [119.91355], f: [0.03583948]\n",
      "f_r: [0.00204911], r: [119.653786], f: [5.4635886e-13]\n",
      "f_r: [0.02393195], r: [119.08323], f: [321.11554]\n",
      "f_r: [0.01263374], r: [119.867134], f: [4.9119123e-15]\n",
      "f_r: [0.6459672], r: [119.39299], f: [1.2882309e-10]\n",
      "f_r: [0.02640143], r: [119.65014], f: [2.9257495e-16]\n",
      "f_r: [0.00341986], r: [119.96938], f: [0.12183263]\n",
      "f_r: [-0.0054868], r: [119.57554], f: [0.1722511]\n",
      "f_r: [0.07661692], r: [119.31149], f: [5.240103e-12]\n",
      "f_r: [-0.00537317], r: [119.04031], f: [5.3327384]\n",
      "f_r: [0.3622367], r: [119.68894], f: [4.962227e-07]\n",
      "f_r: [0.00379609], r: [119.603134], f: [53.587948]\n",
      "f_r: [0.23392831], r: [119.38707], f: [8.286958e-06]\n",
      "f_r: [0.01088305], r: [119.58854], f: [0.23882292]\n",
      "f_r: [-0.02063063], r: [119.44675], f: [6.2844086]\n",
      "f_r: [0.03296429], r: [119.64512], f: [0.24756947]\n",
      "f_r: [0.5971796], r: [119.42624], f: [0.04812311]\n",
      "f_r: [-0.10052542], r: [119.70538], f: [2.9243868e-13]\n",
      "f_r: [0.32004794], r: [119.278275], f: [7.3741404e-09]\n",
      "f_r: [0.00451995], r: [119.04666], f: [8.674226]\n",
      "f_r: [0.40981883], r: [119.62207], f: [1.5697285e-08]\n",
      "f_r: [0.39818797], r: [119.98699], f: [1.173019e-10]\n",
      "f_r: [0.30347845], r: [119.16162], f: [8.226182e-07]\n",
      "f_r: [0.26500645], r: [119.66475], f: [1.4784823e-11]\n",
      "f_r: [0.00466511], r: [119.91104], f: [21.632057]\n",
      "f_r: [0.50834554], r: [119.82576], f: [1.3970345e-09]\n",
      "f_r: [0.48750126], r: [119.216866], f: [5.4516027e-11]\n",
      "f_r: [-0.00487622], r: [119.02034], f: [18.862759]\n",
      "Training loss for epoch 8: pinn: 7.1550, boundary: 114.5001, total: 121.6551\n",
      "f_r: [0.01345801], r: [119.977615], f: [0.06068434]\n",
      "f_r: [0.07194147], r: [119.13276], f: [2487456.8]\n",
      "f_r: [0.31016564], r: [119.261894], f: [0.11355516]\n",
      "f_r: [-0.00932747], r: [119.36134], f: [2.6653384e-12]\n",
      "f_r: [0.07510813], r: [119.1598], f: [4.939778e-06]\n",
      "f_r: [-0.109133], r: [119.67274], f: [1.051535e-15]\n",
      "f_r: [0.28384897], r: [119.67068], f: [0.02016358]\n",
      "f_r: [0.35027033], r: [119.70675], f: [1.3320512e-08]\n",
      "f_r: [-0.00179708], r: [119.38092], f: [2.9816117]\n",
      "f_r: [0.12002861], r: [119.00853], f: [6.801113e-10]\n",
      "f_r: [-0.00096818], r: [119.64946], f: [6.696583]\n",
      "f_r: [0.45840973], r: [119.509415], f: [5.7104196e-11]\n",
      "f_r: [0.414111], r: [119.89504], f: [0.00340361]\n",
      "f_r: [-0.04270172], r: [119.66954], f: [216.84293]\n",
      "f_r: [0.33134577], r: [119.1432], f: [1.6918873e-11]\n",
      "f_r: [0.04579594], r: [119.80725], f: [1.5589553e-14]\n",
      "f_r: [0.34425262], r: [119.04621], f: [5.4344913e-08]\n",
      "f_r: [0.15436867], r: [119.33789], f: [1.5421311e-10]\n",
      "f_r: [0.1711052], r: [119.51899], f: [2.783828e-05]\n",
      "f_r: [0.33293083], r: [119.92408], f: [1.0574016e-06]\n",
      "f_r: [0.10537477], r: [119.40233], f: [2.9140898e-05]\n",
      "f_r: [0.17255825], r: [119.82645], f: [1.4366103e-06]\n",
      "f_r: [0.00396917], r: [119.351326], f: [7114.0723]\n",
      "f_r: [0.1920016], r: [119.86805], f: [2.862281e-07]\n",
      "f_r: [0.00336959], r: [119.57371], f: [0.25352266]\n",
      "f_r: [-0.05611208], r: [119.18526], f: [3.6180836e-14]\n",
      "f_r: [0.24966477], r: [119.70196], f: [4.908851e-07]\n",
      "f_r: [0.00926238], r: [119.67205], f: [2.4410212]\n",
      "f_r: [-0.01257965], r: [119.73483], f: [1.24026e-14]\n",
      "f_r: [0.5473873], r: [119.648544], f: [3.525569e-12]\n",
      "f_r: [0.44464692], r: [119.57075], f: [0.00026107]\n",
      "f_r: [0.17846325], r: [119.79788], f: [0.00017199]\n",
      "f_r: [0.26722825], r: [119.712456], f: [5.494885e-07]\n",
      "f_r: [0.00274813], r: [119.34609], f: [29.963545]\n",
      "f_r: [9.048727e-05], r: [119.22346], f: [0.17937031]\n",
      "f_r: [0.11686666], r: [119.43193], f: [6.127807e-05]\n",
      "f_r: [0.00158774], r: [119.12458], f: [57.283176]\n",
      "f_r: [0.10771838], r: [119.83034], f: [2.1198372e-05]\n",
      "f_r: [0.25985155], r: [119.45062], f: [6.9716866e-06]\n",
      "f_r: [-0.01876485], r: [119.22005], f: [17.63164]\n",
      "Training loss for epoch 9: pinn: 6.2991, boundary: 89.1879, total: 95.4870\n",
      "f_r: [0.50924635], r: [119.522865], f: [3.3309282e-11]\n",
      "f_r: [0.4276409], r: [119.13957], f: [2.6409623e-12]\n",
      "f_r: [0.18437885], r: [119.43558], f: [2.6582386e-10]\n",
      "f_r: [-0.00541285], r: [119.681404], f: [0.31784803]\n",
      "f_r: [0.3083738], r: [119.060074], f: [5.553791e-05]\n",
      "f_r: [0.00014311], r: [119.96435], f: [2.393227]\n",
      "f_r: [0.27027428], r: [119.073235], f: [0.04070674]\n",
      "f_r: [0.01289285], r: [119.39777], f: [117.75303]\n",
      "f_r: [0.00534969], r: [119.7136], f: [55.308815]\n",
      "f_r: [0.34982634], r: [119.727295], f: [6.850133e-07]\n",
      "f_r: [0.0043851], r: [119.315125], f: [3.1783245]\n",
      "f_r: [0.10623197], r: [119.929115], f: [0.00025905]\n",
      "f_r: [0.29147875], r: [119.11685], f: [1.1020846e-09]\n",
      "f_r: [0.16379674], r: [119.72456], f: [2.405844e-08]\n",
      "f_r: [0.00490934], r: [119.55935], f: [0.01957741]\n",
      "f_r: [0.20249225], r: [119.54839], f: [1.3752733e-05]\n",
      "f_r: [-0.02860108], r: [119.40279], f: [6.9800036e-13]\n",
      "f_r: [-0.05322645], r: [119.633934], f: [1.79466e-12]\n",
      "f_r: [0.08567579], r: [119.23642], f: [18.15214]\n",
      "f_r: [0.02832848], r: [119.01329], f: [19.30436]\n",
      "f_r: [0.20070276], r: [119.71886], f: [1.4341202e-08]\n",
      "f_r: [0.0330238], r: [119.14799], f: [4.5528846]\n",
      "f_r: [0.02709659], r: [119.329926], f: [2.818918e-13]\n",
      "f_r: [0.62894535], r: [119.87217], f: [0.00979202]\n",
      "f_r: [0.01611356], r: [119.54839], f: [4.8380003]\n",
      "f_r: [0.01450403], r: [119.678444], f: [4.3123956]\n",
      "f_r: [0.7172469], r: [119.339935], f: [1.8043014e-08]\n",
      "f_r: [0.02342318], r: [119.24483], f: [110.38121]\n",
      "f_r: [0.01484401], r: [119.02919], f: [42.950912]\n",
      "f_r: [0.37708196], r: [119.46246], f: [1.17697425e-07]\n",
      "f_r: [-0.08777748], r: [119.16412], f: [7.6617146e-15]\n",
      "f_r: [0.00172962], r: [119.45016], f: [32.958237]\n",
      "f_r: [1.2132966e-05], r: [119.45039], f: [17.834309]\n",
      "f_r: [0.24569055], r: [119.8644], f: [3.7761342e-06]\n",
      "f_r: [0.16923825], r: [119.8916], f: [5.5472817e-08]\n",
      "f_r: [0.2306608], r: [119.903725], f: [4.868909e-07]\n",
      "f_r: [-0.05655294], r: [119.8148], f: [40.209892]\n",
      "f_r: [-0.02612015], r: [119.16935], f: [142.96144]\n",
      "f_r: [0.5750256], r: [119.45199], f: [0.0724667]\n",
      "f_r: [0.34073833], r: [119.10663], f: [2.0761798e-08]\n",
      "Training loss for epoch 10: pinn: 6.1536, boundary: 119.9575, total: 126.1111\n",
      "f_r: [0.19347607], r: [119.33016], f: [4.1625735e-05]\n",
      "f_r: [7.619008e-05], r: [119.377045], f: [0.20096985]\n",
      "f_r: [-0.07177899], r: [119.49482], f: [14.073093]\n",
      "f_r: [0.11048719], r: [119.71154], f: [1.5655434e-07]\n",
      "f_r: [0.09023485], r: [119.24301], f: [1.6746654e-06]\n",
      "f_r: [-1.3521608e-09], r: [119.261444], f: [0.76298076]\n",
      "f_r: [0.17242855], r: [119.73004], f: [0.00026119]\n",
      "f_r: [-0.04413674], r: [119.986084], f: [4.0468484e-10]\n",
      "f_r: [-0.13252236], r: [119.05826], f: [1.4703851e-12]\n",
      "f_r: [-0.00230747], r: [119.88292], f: [0.0347834]\n",
      "f_r: [-0.01169797], r: [119.77481], f: [5.403554]\n",
      "f_r: [-0.15442699], r: [119.73004], f: [5.5096e-14]\n",
      "f_r: [0.00147505], r: [119.7675], f: [68.73038]\n",
      "f_r: [0.00290281], r: [119.78897], f: [0.8222149]\n",
      "f_r: [0.22270064], r: [119.32765], f: [1.1848532e-07]\n",
      "f_r: [0.03602465], r: [119.50258], f: [2.1402865e-13]\n",
      "f_r: [-0.0002076], r: [119.680275], f: [32.17239]\n",
      "f_r: [-0.14458491], r: [119.673416], f: [2.0556517e-14]\n",
      "f_r: [-1.546681e-08], r: [119.55136], f: [0.3002149]\n",
      "f_r: [0.21277873], r: [119.31308], f: [1.6729367e-06]\n",
      "f_r: [-8.75914e-10], r: [119.90304], f: [0.2231889]\n",
      "f_r: [0.15080935], r: [119.2942], f: [0.00064557]\n",
      "f_r: [0.00880829], r: [119.7031], f: [381.2107]\n",
      "f_r: [0.09354564], r: [119.82119], f: [6.7038306e-12]\n",
      "f_r: [0.10415609], r: [119.8164], f: [4.696861e-05]\n",
      "f_r: [0.3663036], r: [119.07391], f: [7.684907e-09]\n",
      "f_r: [0.22281063], r: [119.22959], f: [2.5126855e-08]\n",
      "f_r: [-0.12094629], r: [119.83971], f: [0.19998726]\n",
      "f_r: [0.39872566], r: [119.840164], f: [6.4925084e-12]\n",
      "f_r: [0.4112493], r: [119.10481], f: [3.17161e-12]\n",
      "f_r: [0.3273173], r: [119.19866], f: [4.629009e-06]\n",
      "f_r: [-0.00875147], r: [119.71771], f: [22.66121]\n",
      "f_r: [0.01527175], r: [119.70538], f: [9.758173e-14]\n",
      "f_r: [0.09820383], r: [119.8148], f: [1.3817769e-05]\n",
      "f_r: [0.2512305], r: [119.56755], f: [5.527106e-13]\n",
      "f_r: [-0.00714997], r: [119.96366], f: [37.657177]\n",
      "f_r: [0.00321945], r: [119.421], f: [5.761294e-14]\n",
      "f_r: [-0.00645366], r: [119.15844], f: [66.1779]\n",
      "f_r: [0.12454929], r: [119.83034], f: [0.0042927]\n",
      "f_r: [-0.00701459], r: [119.49368], f: [70.5184]\n",
      "Training loss for epoch 11: pinn: 4.9456, boundary: 57.2807, total: 62.2263\n",
      "f_r: [-0.01539861], r: [119.26736], f: [14.441141]\n",
      "f_r: [0.30483454], r: [119.71886], f: [9.98212e-17]\n",
      "f_r: [-0.16429979], r: [119.790344], f: [1.9430657e-18]\n",
      "f_r: [0.08305447], r: [119.13981], f: [9.904666e-13]\n",
      "f_r: [0.01217207], r: [119.97442], f: [15093.72]\n",
      "f_r: [0.20772101], r: [119.48821], f: [3.3673768e-08]\n",
      "f_r: [0.05403059], r: [119.75859], f: [3.607336e-13]\n",
      "f_r: [0.03290468], r: [119.94329], f: [6.49491e-05]\n",
      "f_r: [0.11908769], r: [119.48092], f: [2.2715696e-07]\n",
      "f_r: [-0.02334457], r: [119.16639], f: [0.02315634]\n",
      "f_r: [-0.00714186], r: [119.417366], f: [0.01693558]\n",
      "f_r: [-0.0146648], r: [119.251434], f: [0.08130318]\n",
      "f_r: [-0.01521538], r: [119.82302], f: [1.7943982]\n",
      "f_r: [-0.01706492], r: [119.04894], f: [5.5721326]\n",
      "f_r: [0.2460048], r: [119.24642], f: [1.934218e-06]\n",
      "f_r: [-0.00459336], r: [119.62778], f: [268.09094]\n",
      "f_r: [0.20190988], r: [119.61568], f: [8.836173e-06]\n",
      "f_r: [0.14488354], r: [119.88017], f: [7.632807e-11]\n",
      "f_r: [0.03579425], r: [119.97236], f: [5.4095306]\n",
      "f_r: [0.22850128], r: [119.493004], f: [1.6021914e-08]\n",
      "f_r: [-0.02945324], r: [119.79195], f: [32.957542]\n",
      "f_r: [-0.02970816], r: [119.49733], f: [1.3783641]\n",
      "f_r: [-0.01025838], r: [119.82851], f: [0.00216274]\n",
      "f_r: [-0.02439952], r: [119.62686], f: [9.059501]\n",
      "f_r: [-0.13457136], r: [119.70104], f: [3.7205976e-12]\n",
      "f_r: [0.10867943], r: [119.119804], f: [5.317585e-10]\n",
      "f_r: [0.08579654], r: [119.31331], f: [2.43366e-12]\n",
      "f_r: [-0.04295523], r: [119.994095], f: [1.6810999e-13]\n",
      "f_r: [0.09239342], r: [119.20231], f: [1.6699885e-05]\n",
      "f_r: [-0.01806004], r: [119.73323], f: [90.15257]\n",
      "f_r: [0.08297647], r: [119.56162], f: [8.890049e-06]\n",
      "f_r: [-0.00159848], r: [119.89183], f: [0.00092162]\n",
      "f_r: [0.25753498], r: [119.493004], f: [1.4386077e-08]\n",
      "f_r: [-0.01253764], r: [119.892296], f: [2.9523476e-13]\n",
      "f_r: [0.11226278], r: [119.011475], f: [1.1286998e-07]\n",
      "f_r: [-0.01895201], r: [119.10436], f: [2.428277e-12]\n",
      "f_r: [-0.08413172], r: [119.60291], f: [19.694023]\n",
      "f_r: [0.00059346], r: [119.42283], f: [0.51184136]\n",
      "f_r: [-0.08013826], r: [119.21322], f: [29.794209]\n",
      "f_r: [-0.01915335], r: [119.415985], f: [0.00076898]\n",
      "Training loss for epoch 12: pinn: 3.6083, boundary: 85.5164, total: 89.1247\n",
      "f_r: [-0.05818005], r: [119.339485], f: [75.15108]\n",
      "f_r: [-0.02972203], r: [119.51055], f: [1.5627306e-10]\n",
      "f_r: [-0.01654227], r: [119.996155], f: [6.483047e-14]\n",
      "f_r: [0.00431343], r: [119.680954], f: [0.26469666]\n",
      "f_r: [0.08428258], r: [119.508736], f: [0.00070505]\n",
      "f_r: [-0.0175308], r: [119.39709], f: [86.79389]\n",
      "f_r: [-0.018377], r: [119.26736], f: [524.7897]\n",
      "f_r: [0.00873895], r: [119.24369], f: [0.0043071]\n",
      "f_r: [-0.01459679], r: [119.36224], f: [7.734031]\n",
      "f_r: [6.429001e-06], r: [119.63029], f: [0.19846894]\n",
      "f_r: [0.00317001], r: [119.876976], f: [7.377425e-11]\n",
      "f_r: [0.01850803], r: [119.790115], f: [0.00047072]\n",
      "f_r: [-0.02978851], r: [119.06347], f: [3.9446316e-13]\n",
      "f_r: [-0.09400303], r: [119.90419], f: [9.29581e-13]\n",
      "f_r: [0.04541628], r: [119.523315], f: [3.1059766e-10]\n",
      "f_r: [-0.02731573], r: [119.87857], f: [1.260411e-11]\n",
      "f_r: [0.05373451], r: [119.44924], f: [5.6248374e-11]\n",
      "f_r: [0.09957676], r: [119.631424], f: [8.236155e-08]\n",
      "f_r: [0.04006674], r: [119.58489], f: [9.21118e-13]\n",
      "f_r: [-0.04736396], r: [119.060074], f: [5.732839]\n",
      "f_r: [-0.21124782], r: [119.42396], f: [5.1716894e-16]\n",
      "f_r: [0.00792699], r: [119.112305], f: [1.2381716]\n",
      "f_r: [0.00030099], r: [119.233], f: [2.2776128e-11]\n",
      "f_r: [0.01730504], r: [119.15207], f: [3.49578e-11]\n",
      "f_r: [-0.07515457], r: [119.375916], f: [4.4488645]\n",
      "f_r: [0.10298098], r: [119.35678], f: [3.252482e-06]\n",
      "f_r: [0.01196869], r: [119.26053], f: [0.01044058]\n",
      "f_r: [-0.10983429], r: [119.52126], f: [3.655348e-13]\n",
      "f_r: [0.28460905], r: [119.304436], f: [4.361817e-08]\n",
      "f_r: [0.17759591], r: [119.80542], f: [1.42296255e-08]\n",
      "f_r: [0.08884104], r: [119.11662], f: [7.936261e-10]\n",
      "f_r: [0.07892586], r: [119.64284], f: [5.921902e-08]\n",
      "f_r: [-0.0382701], r: [119.43421], f: [70.8831]\n",
      "f_r: [0.02252588], r: [119.45586], f: [0.00098864]\n",
      "f_r: [-0.03251605], r: [119.4962], f: [128.93018]\n",
      "f_r: [0.02730255], r: [119.20709], f: [0.01592074]\n",
      "f_r: [0.04976524], r: [119.74946], f: [8.076242e-05]\n",
      "f_r: [-0.09711479], r: [119.189575], f: [60.87562]\n",
      "f_r: [0.12835579], r: [119.45016], f: [8.510194e-06]\n",
      "f_r: [0.0878337], r: [119.041214], f: [1.9561013e-12]\n",
      "Training loss for epoch 13: pinn: 2.8798, boundary: 83.3506, total: 86.2305\n",
      "f_r: [-0.0278056], r: [119.94924], f: [3.0607479]\n",
      "f_r: [-0.27899414], r: [119.71177], f: [1.2103952e-18]\n",
      "f_r: [0.17597735], r: [119.71771], f: [1.6198646e-06]\n",
      "f_r: [0.16859902], r: [119.51078], f: [1.6583526e-12]\n",
      "f_r: [0.35436133], r: [119.88863], f: [4.555165e-08]\n",
      "f_r: [0.01519949], r: [119.58899], f: [0.0013904]\n",
      "f_r: [0.03887965], r: [119.122986], f: [9.062777e-12]\n",
      "f_r: [0.05135351], r: [119.61842], f: [5.946454e-11]\n",
      "f_r: [-0.10664883], r: [119.58877], f: [5.2636884e-14]\n",
      "f_r: [0.3099948], r: [119.4399], f: [1.4422242e-05]\n",
      "f_r: [0.10224994], r: [119.81457], f: [2.3991603e-10]\n",
      "f_r: [-0.17725503], r: [119.16276], f: [1.4128321e-15]\n",
      "f_r: [0.0059337], r: [119.417816], f: [4.6428153e-10]\n",
      "f_r: [-0.04239621], r: [119.10095], f: [186.20392]\n",
      "f_r: [-0.12204715], r: [119.7321], f: [5.8129]\n",
      "f_r: [-0.0838052], r: [119.65698], f: [0.00215919]\n",
      "f_r: [-0.02628445], r: [119.39982], f: [489.03186]\n",
      "f_r: [-0.06486589], r: [119.34426], f: [1.1701349e-09]\n",
      "f_r: [-0.08360885], r: [119.839935], f: [1.8877913e-13]\n",
      "f_r: [-0.09340647], r: [119.54976], f: [0.00435998]\n",
      "f_r: [-0.09467421], r: [119.17571], f: [0.00223681]\n",
      "f_r: [-0.01660754], r: [119.107544], f: [4.2597253e-07]\n",
      "f_r: [-3.5719913e-05], r: [119.992714], f: [65.445404]\n",
      "f_r: [-0.01238104], r: [119.38024], f: [4.1536072e-07]\n",
      "f_r: [-0.23732588], r: [119.23687], f: [4.3826641e-16]\n",
      "f_r: [-0.00808679], r: [119.54611], f: [3.6878653e-08]\n",
      "f_r: [-0.08528231], r: [119.039635], f: [0.00792593]\n",
      "f_r: [-0.10830406], r: [119.855484], f: [0.01364796]\n",
      "f_r: [-0.08000524], r: [119.612946], f: [16.378254]\n",
      "f_r: [-0.01974371], r: [119.23006], f: [0.00052843]\n",
      "f_r: [-0.09285419], r: [119.42259], f: [0.16997838]\n",
      "f_r: [-0.08078448], r: [119.66726], f: [0.24510092]\n",
      "f_r: [-0.05787063], r: [119.89983], f: [4.534108e-09]\n",
      "f_r: [0.00144269], r: [119.235504], f: [0.00021285]\n",
      "f_r: [-0.06570376], r: [119.92432], f: [7.801971e-08]\n",
      "f_r: [-0.05705169], r: [119.67776], f: [1.5177767e-10]\n",
      "f_r: [-0.01712422], r: [119.16502], f: [1.7200771e-09]\n",
      "f_r: [-0.03078119], r: [119.27623], f: [1.8262008e-11]\n",
      "f_r: [0.03055304], r: [119.48616], f: [5.3199572e-05]\n",
      "f_r: [-0.04983082], r: [119.73278], f: [0.04342422]\n",
      "Training loss for epoch 14: pinn: 2.9101, boundary: 53.7464, total: 56.6565\n",
      "f_r: [-0.04459775], r: [119.83217], f: [0.00544262]\n",
      "f_r: [0.04986179], r: [119.3684], f: [4.1994148e-13]\n",
      "f_r: [-0.00432625], r: [119.84153], f: [2.0226712e-06]\n",
      "f_r: [0.11055514], r: [119.456314], f: [0.0001335]\n",
      "f_r: [-0.01072289], r: [119.837654], f: [4.5124373]\n",
      "f_r: [0.00184352], r: [119.271454], f: [294.8559]\n",
      "f_r: [0.02010776], r: [119.514656], f: [399.36346]\n",
      "f_r: [0.09385972], r: [119.210724], f: [0.00480392]\n",
      "f_r: [0.00037219], r: [119.111855], f: [59.171783]\n",
      "f_r: [-0.01155754], r: [119.142525], f: [0.00325564]\n",
      "f_r: [0.00193335], r: [119.76499], f: [2.5397756]\n",
      "f_r: [-0.10512868], r: [119.44538], f: [1.3174307e-13]\n",
      "f_r: [-0.14835232], r: [119.566635], f: [2.2138625e-15]\n",
      "f_r: [-0.02806905], r: [119.58602], f: [5.5171874e-12]\n",
      "f_r: [-0.1658594], r: [119.2603], f: [9.974208e-16]\n",
      "f_r: [-0.02861018], r: [119.549545], f: [1.1922752e-11]\n",
      "f_r: [0.08177543], r: [119.690994], f: [1.8052343e-06]\n",
      "f_r: [-0.0276053], r: [119.04758], f: [2.0888435e-11]\n",
      "f_r: [-0.00399999], r: [119.46201], f: [627.56506]\n",
      "f_r: [0.12107032], r: [119.41986], f: [9.807628e-09]\n",
      "f_r: [0.08961599], r: [119.96732], f: [1.2134902e-11]\n",
      "f_r: [0.12926926], r: [119.29648], f: [3.312211e-07]\n",
      "f_r: [0.03009474], r: [119.58443], f: [0.00473271]\n",
      "f_r: [-0.13739146], r: [119.464745], f: [4.965546e-16]\n",
      "f_r: [0.03285528], r: [119.18639], f: [0.0378499]\n",
      "f_r: [0.0477783], r: [119.72616], f: [7.2560596e-10]\n",
      "f_r: [0.02557941], r: [119.459045], f: [3.2966477e-10]\n",
      "f_r: [0.05718908], r: [119.4062], f: [0.01224559]\n",
      "f_r: [0.00856842], r: [119.21936], f: [3.3911745e-11]\n",
      "f_r: [0.13322407], r: [119.03668], f: [2.9217492e-06]\n",
      "f_r: [-0.0689349], r: [119.2114], f: [0.71399486]\n",
      "f_r: [-0.01956314], r: [119.06279], f: [418.6303]\n",
      "f_r: [0.14202756], r: [119.909676], f: [2.730411e-05]\n",
      "f_r: [0.03470691], r: [119.33221], f: [2.4478802e-10]\n",
      "f_r: [0.02816354], r: [119.34996], f: [0.01560317]\n",
      "f_r: [0.04024391], r: [119.12548], f: [6.1035836e-11]\n",
      "f_r: [-0.19589092], r: [119.444466], f: [4.2936516e-16]\n",
      "f_r: [0.01401651], r: [119.00966], f: [0.00556997]\n",
      "f_r: [0.03394946], r: [119.92842], f: [1.109741e-10]\n",
      "f_r: [-0.05111674], r: [119.45837], f: [159.08815]\n",
      "Training loss for epoch 15: pinn: 2.1626, boundary: 121.1542, total: 123.3168\n",
      "f_r: [-0.05899949], r: [119.44583], f: [47.863094]\n",
      "f_r: [-0.0590025], r: [119.73689], f: [9.6885145e-05]\n",
      "f_r: [-0.01158238], r: [119.24619], f: [6.4814585e-16]\n",
      "f_r: [0.11859823], r: [119.063705], f: [1.1915661e-05]\n",
      "f_r: [0.15690762], r: [119.86532], f: [0.00349928]\n",
      "f_r: [0.07792252], r: [119.41827], f: [1.0266491e-08]\n",
      "f_r: [-0.02813567], r: [119.28987], f: [5.0712695e-10]\n",
      "f_r: [-0.0353738], r: [119.53495], f: [3.5665178]\n",
      "f_r: [-0.07987419], r: [119.50394], f: [2.2084001e-12]\n",
      "f_r: [0.02836077], r: [119.52651], f: [5.862898e-08]\n",
      "f_r: [0.06980663], r: [119.7241], f: [3.3864676e-06]\n",
      "f_r: [-0.00303902], r: [119.54224], f: [1.326119]\n",
      "f_r: [-0.00922941], r: [119.70378], f: [2.9612627]\n",
      "f_r: [0.02603108], r: [119.66748], f: [0.00232612]\n",
      "f_r: [0.07869094], r: [119.79171], f: [7.121252e-07]\n",
      "f_r: [0.13852607], r: [119.2901], f: [4.475254e-05]\n",
      "f_r: [-0.00029011], r: [119.69625], f: [14.872486]\n",
      "f_r: [-0.00058895], r: [119.83582], f: [18.630232]\n",
      "f_r: [-0.17989266], r: [119.60769], f: [1.5304873e-16]\n",
      "f_r: [0.], r: [119.59972], f: [47.909485]\n",
      "f_r: [0.05672448], r: [119.12798], f: [1.4448949e-07]\n",
      "f_r: [-0.00212701], r: [119.59105], f: [0.31819376]\n",
      "f_r: [-0.0203846], r: [119.447426], f: [0.43250114]\n",
      "f_r: [0.00154908], r: [119.22209], f: [1.0829913e-08]\n",
      "f_r: [-0.03425607], r: [119.16617], f: [46.779324]\n",
      "f_r: [-0.00020231], r: [119.3734], f: [22.491398]\n",
      "f_r: [-0.0152602], r: [119.58581], f: [2.711932e-08]\n",
      "f_r: [-0.1308741], r: [119.327194], f: [6.017082e-13]\n",
      "f_r: [-0.00718118], r: [119.00784], f: [125.035065]\n",
      "f_r: [-0.01145263], r: [119.9449], f: [102.61977]\n",
      "f_r: [-0.02116038], r: [119.57348], f: [0.00226234]\n",
      "f_r: [-0.071763], r: [119.96411], f: [43.79843]\n",
      "f_r: [-0.03773119], r: [119.46817], f: [1.5604663]\n",
      "f_r: [0.06788226], r: [119.37045], f: [9.636349e-07]\n",
      "f_r: [0.07403555], r: [119.941246], f: [1.3818487e-06]\n",
      "f_r: [-0.02462144], r: [119.28555], f: [0.57440764]\n",
      "f_r: [0.0932699], r: [119.32901], f: [3.2678453e-09]\n",
      "f_r: [0.10052485], r: [119.07391], f: [2.1026906e-05]\n",
      "f_r: [-0.00837527], r: [119.41235], f: [0.00881585]\n",
      "f_r: [0.08327696], r: [119.96411], f: [1.5911119e-05]\n",
      "Training loss for epoch 16: pinn: 2.0972, boundary: 81.6361, total: 83.7332\n",
      "f_r: [-0.01356642], r: [119.43741], f: [0.04342881]\n",
      "f_r: [-0.28723517], r: [119.876976], f: [1.1527603e-21]\n",
      "f_r: [-0.18624604], r: [119.19935], f: [3.2903334e-18]\n",
      "f_r: [0.09633064], r: [119.288734], f: [5.4787844e-05]\n",
      "f_r: [0.03134778], r: [119.11391], f: [1.2829889e-09]\n",
      "f_r: [-0.0118147], r: [119.99226], f: [203.99883]\n",
      "f_r: [0.0535214], r: [119.975784], f: [3.953545e-06]\n",
      "f_r: [-0.01501617], r: [119.804054], f: [1.3765466e-08]\n",
      "f_r: [0.02730774], r: [119.498245], f: [4.5990863e-08]\n",
      "f_r: [0.01078536], r: [119.7803], f: [4.3097894e-09]\n",
      "f_r: [-0.05563858], r: [119.34882], f: [1.5058352]\n",
      "f_r: [-0.03251227], r: [119.337204], f: [6.258669e-05]\n",
      "f_r: [-0.06432307], r: [119.62435], f: [3.6963673]\n",
      "f_r: [0.08026515], r: [119.26689], f: [5.8966845e-13]\n",
      "f_r: [-0.00977116], r: [119.09141], f: [11163.598]\n",
      "f_r: [0.02837551], r: [119.13866], f: [0.02675217]\n",
      "f_r: [-0.10932194], r: [119.30194], f: [5.0472045e-13]\n",
      "f_r: [0.00013412], r: [119.17661], f: [298.60452]\n",
      "f_r: [0.013091], r: [119.964806], f: [164.5236]\n",
      "f_r: [-0.01547797], r: [119.91699], f: [2.0322232]\n",
      "f_r: [-0.01757246], r: [119.56414], f: [0.7361142]\n",
      "f_r: [-0.00092224], r: [119.727295], f: [5.7830925]\n",
      "f_r: [0.09715792], r: [119.20003], f: [5.664798e-09]\n",
      "f_r: [0.16855046], r: [119.38662], f: [9.324503e-10]\n",
      "f_r: [-0.00446045], r: [119.11094], f: [5.901569]\n",
      "f_r: [-0.00574135], r: [119.25325], f: [12.562233]\n",
      "f_r: [0.15782467], r: [119.083694], f: [8.161923e-11]\n",
      "f_r: [-0.01120866], r: [119.90419], f: [46.1196]\n",
      "f_r: [0.08290088], r: [119.82714], f: [0.00689955]\n",
      "f_r: [0.06851628], r: [119.73392], f: [0.0315088]\n",
      "f_r: [-0.08690821], r: [119.0612], f: [5.594197e-14]\n",
      "f_r: [-0.0484597], r: [119.86966], f: [2.399808]\n",
      "f_r: [0.04388916], r: [119.70812], f: [0.00056278]\n",
      "f_r: [-0.03576677], r: [119.525826], f: [1.4041136e-09]\n",
      "f_r: [-0.01039014], r: [119.626175], f: [215.98683]\n",
      "f_r: [-0.00916531], r: [119.42579], f: [0.00038265]\n",
      "f_r: [-0.01490355], r: [119.28055], f: [117.42166]\n",
      "f_r: [-0.00962987], r: [119.014206], f: [2.3272237e-13]\n",
      "f_r: [0.00465001], r: [119.55958], f: [0.00273652]\n",
      "f_r: [0.06203059], r: [119.30034], f: [3.3696698e-12]\n",
      "Training loss for epoch 17: pinn: 2.0277, boundary: 94.1535, total: 96.1812\n",
      "f_r: [0.04571209], r: [119.82736], f: [2.0716811e-07]\n",
      "f_r: [-0.16038567], r: [119.84268], f: [4.532362e-20]\n",
      "f_r: [-0.04555203], r: [119.051895], f: [0.01613979]\n",
      "f_r: [0.01392564], r: [119.94284], f: [5.4299503e-09]\n",
      "f_r: [0.06163644], r: [119.731636], f: [1.774471e-06]\n",
      "f_r: [0.04946306], r: [119.51671], f: [6.9036255e-06]\n",
      "f_r: [0.05413623], r: [119.32219], f: [0.03179266]\n",
      "f_r: [-0.01717591], r: [119.33266], f: [5.712231e-10]\n",
      "f_r: [-0.00596381], r: [119.04713], f: [32.394287]\n",
      "f_r: [0.00027541], r: [119.57782], f: [15.076815]\n",
      "f_r: [0.01217168], r: [119.11026], f: [1.2413567e-09]\n",
      "f_r: [-0.0026171], r: [119.848854], f: [1.7980342e-09]\n",
      "f_r: [0.02893855], r: [119.954285], f: [1.4507643e-09]\n",
      "f_r: [-0.00472379], r: [119.612946], f: [1.6208521]\n",
      "f_r: [0.00321825], r: [119.19776], f: [9.5843574e-14]\n",
      "f_r: [0.03757844], r: [119.80063], f: [0.00087184]\n",
      "f_r: [0.05341801], r: [119.92133], f: [6.702003e-08]\n",
      "f_r: [0.07230444], r: [119.99067], f: [0.00458496]\n",
      "f_r: [-0.07240509], r: [119.6239], f: [6.7653575e-16]\n",
      "f_r: [0.00028641], r: [119.91744], f: [64.58022]\n",
      "f_r: [-0.02184334], r: [119.95747], f: [5.7151685]\n",
      "f_r: [-0.00395248], r: [119.89892], f: [56.856102]\n",
      "f_r: [-2.0969976e-10], r: [119.96503], f: [2.2089698]\n",
      "f_r: [-0.01072227], r: [119.35542], f: [75.10766]\n",
      "f_r: [0.03372646], r: [119.49893], f: [7.872117e-09]\n",
      "f_r: [0.04430132], r: [119.89366], f: [0.0020174]\n",
      "f_r: [-0.02363431], r: [119.52081], f: [2.1384775e-14]\n",
      "f_r: [0.12518212], r: [119.39027], f: [4.930435e-10]\n",
      "f_r: [0.08278967], r: [119.1064], f: [2.2455171e-10]\n",
      "f_r: [0.0108386], r: [119.21868], f: [479.1258]\n",
      "f_r: [-0.01158167], r: [119.10663], f: [83.71041]\n",
      "f_r: [-3.0635582e-07], r: [119.55455], f: [1.0873269]\n",
      "f_r: [-0.0209047], r: [119.32447], f: [2.6462415e-12]\n",
      "f_r: [-0.00167321], r: [119.38297], f: [7.3672517e-09]\n",
      "f_r: [0.03243628], r: [119.72114], f: [0.07950518]\n",
      "f_r: [-0.03495536], r: [119.93437], f: [4.053606]\n",
      "f_r: [-0.00882308], r: [119.9513], f: [152.47896]\n",
      "f_r: [-0.00085642], r: [119.95084], f: [2.0869086]\n",
      "f_r: [0.02402795], r: [119.94993], f: [0.02291197]\n",
      "f_r: [-0.02367351], r: [119.83193], f: [1.104958e-12]\n",
      "Training loss for epoch 18: pinn: 1.5767, boundary: 69.7946, total: 71.3712\n",
      "f_r: [-0.02104681], r: [119.16116], f: [93.79043]\n",
      "f_r: [0.06789908], r: [119.72799], f: [0.00073586]\n",
      "f_r: [0.2797367], r: [119.58283], f: [0.00020051]\n",
      "f_r: [0.11173529], r: [119.178665], f: [4.3494417e-14]\n",
      "f_r: [0.08846392], r: [119.64192], f: [2.1549501e-10]\n",
      "f_r: [0.17204572], r: [119.268936], f: [5.7101e-05]\n",
      "f_r: [0.00347071], r: [119.18754], f: [0.6000627]\n",
      "f_r: [0.02007441], r: [119.92934], f: [9.478205e-11]\n",
      "f_r: [0.06817796], r: [119.24642], f: [1.962772e-05]\n",
      "f_r: [0.00910413], r: [119.39504], f: [0.00587178]\n",
      "f_r: [-0.00761118], r: [119.04713], f: [85.83513]\n",
      "f_r: [-0.01543632], r: [119.27077], f: [115.24154]\n",
      "f_r: [-0.00316219], r: [119.73826], f: [605.9335]\n",
      "f_r: [0.00027933], r: [119.37067], f: [6.636992]\n",
      "f_r: [-0.03763717], r: [119.73483], f: [8.717938e-05]\n",
      "f_r: [-0.02454509], r: [119.10822], f: [4.2736145e-10]\n",
      "f_r: [-0.03442867], r: [119.24779], f: [0.00028123]\n",
      "f_r: [-0.02687097], r: [119.79446], f: [10.464977]\n",
      "f_r: [-0.03683555], r: [119.25347], f: [0.00017907]\n",
      "f_r: [-0.0003643], r: [119.56254], f: [75.52407]\n",
      "f_r: [0.09849193], r: [119.82074], f: [3.509556e-11]\n",
      "f_r: [0.03275635], r: [119.168884], f: [1.0764569e-06]\n",
      "f_r: [-0.04218352], r: [119.09959], f: [0.00015186]\n",
      "f_r: [-0.0077077], r: [119.421], f: [0.00548047]\n",
      "f_r: [-0.08992102], r: [119.63302], f: [2.9877742e-14]\n",
      "f_r: [-0.00571577], r: [119.996605], f: [9.418658e-12]\n",
      "f_r: [-0.00524083], r: [119.89755], f: [225.23102]\n",
      "f_r: [-0.04975825], r: [119.81274], f: [19.665703]\n",
      "f_r: [-0.04381557], r: [119.43604], f: [25.64605]\n",
      "f_r: [-0.00430255], r: [119.72616], f: [6.2919003e-09]\n",
      "f_r: [-0.04415976], r: [119.6328], f: [1.7938542e-10]\n",
      "f_r: [-0.01345709], r: [119.61455], f: [134.81454]\n",
      "f_r: [-0.01023521], r: [119.60976], f: [1.0097521e-07]\n",
      "f_r: [0.02982611], r: [119.288734], f: [5.8314877e-06]\n",
      "f_r: [-0.05120051], r: [119.70812], f: [19.600899]\n",
      "f_r: [0.03191603], r: [119.82325], f: [1.4564122e-05]\n",
      "f_r: [0.02317345], r: [119.76819], f: [5.3335843e-06]\n",
      "f_r: [-0.03015003], r: [119.05416], f: [0.00082322]\n",
      "f_r: [0.02051272], r: [119.81868], f: [2.3779654e-15]\n",
      "f_r: [0.02908272], r: [119.17525], f: [1.8880845e-15]\n",
      "Training loss for epoch 19: pinn: 1.4764, boundary: 41.7640, total: 43.2405\n",
      "f_r: [0.0033696], r: [119.22914], f: [0.01696458]\n",
      "f_r: [-0.07275352], r: [119.018974], f: [2.5106525e-13]\n",
      "f_r: [-0.03368906], r: [119.115036], f: [0.00055416]\n",
      "f_r: [-0.00350327], r: [119.50234], f: [5.296091e-08]\n",
      "f_r: [-0.0014073], r: [119.05484], f: [0.01032618]\n",
      "f_r: [0.01587096], r: [119.189804], f: [0.08747295]\n",
      "f_r: [0.0516676], r: [119.89778], f: [0.00038677]\n",
      "f_r: [0.00977622], r: [119.45289], f: [0.02848625]\n",
      "f_r: [0.04735284], r: [119.733696], f: [7.8801175e-05]\n",
      "f_r: [0.00272637], r: [119.65562], f: [25.52341]\n",
      "f_r: [0.00234874], r: [119.78624], f: [0.17154709]\n",
      "f_r: [-0.01379436], r: [119.86211], f: [2.876445]\n",
      "f_r: [-0.00124757], r: [119.602], f: [0.02743652]\n",
      "f_r: [-0.02328737], r: [119.78235], f: [2.4809263e-12]\n",
      "f_r: [0.02874694], r: [119.869194], f: [0.00579625]\n",
      "f_r: [0.04320215], r: [119.351776], f: [3.00546e-09]\n",
      "f_r: [0.03149839], r: [119.81159], f: [0.00059945]\n",
      "f_r: [-0.06013769], r: [119.96343], f: [1.3986605e-13]\n",
      "f_r: [-0.05433986], r: [119.85251], f: [5.5988673e-12]\n",
      "f_r: [0.01169161], r: [119.96686], f: [81.15132]\n",
      "f_r: [0.01219455], r: [119.29579], f: [43.733047]\n",
      "f_r: [-0.00534444], r: [119.577354], f: [24.338879]\n",
      "f_r: [0.02308728], r: [119.04803], f: [2.7668194e-11]\n",
      "f_r: [0.01641813], r: [119.57258], f: [4.91257]\n",
      "f_r: [0.00420414], r: [119.90395], f: [184.64433]\n",
      "f_r: [-0.04293622], r: [119.24984], f: [1.8615643e-13]\n",
      "f_r: [0.05615144], r: [119.78349], f: [0.21620539]\n",
      "f_r: [0.07957038], r: [119.63713], f: [6.2017538e-09]\n",
      "f_r: [0.06013523], r: [119.90281], f: [1.6459819e-07]\n",
      "f_r: [0.02784489], r: [119.83034], f: [0.0180564]\n",
      "f_r: [0.03901332], r: [119.48525], f: [0.0012271]\n",
      "f_r: [0.00318367], r: [119.31559], f: [253.35555]\n",
      "f_r: [0.04070334], r: [119.43217], f: [0.36718524]\n",
      "f_r: [0.0199612], r: [119.14094], f: [1.1600697e-10]\n",
      "f_r: [0.04226175], r: [119.34154], f: [7.343965e-12]\n",
      "f_r: [0.03687375], r: [119.40506], f: [8.0679115e-07]\n",
      "f_r: [0.00931601], r: [119.6036], f: [0.00051244]\n",
      "f_r: [0.02176297], r: [119.60907], f: [1.3959199e-07]\n",
      "f_r: [-1.7361948e-07], r: [119.51626], f: [0.87240857]\n",
      "f_r: [0.02291131], r: [119.51626], f: [0.02571396]\n",
      "Training loss for epoch 20: pinn: 1.2631, boundary: 89.7576, total: 91.0207\n",
      "f_r: [0.06401589], r: [119.7924], f: [1.1258349e-05]\n",
      "f_r: [-0.04307181], r: [119.32059], f: [3.744108]\n",
      "f_r: [-0.04038496], r: [119.19117], f: [4.7767775e-12]\n",
      "f_r: [0.00135633], r: [119.61706], f: [543.76685]\n",
      "f_r: [0.04638046], r: [119.98242], f: [0.06465874]\n",
      "f_r: [0.05310303], r: [119.48936], f: [7.612253e-06]\n",
      "f_r: [0.01083422], r: [119.33972], f: [43.636227]\n",
      "f_r: [0.00630567], r: [119.42031], f: [8.1206455]\n",
      "f_r: [-0.05225654], r: [119.62914], f: [4.560409e-11]\n",
      "f_r: [-0.02384994], r: [119.84474], f: [3.217141e-06]\n",
      "f_r: [0.01903873], r: [119.94101], f: [6.222638e-05]\n",
      "f_r: [0.00185427], r: [119.20822], f: [0.25708356]\n",
      "f_r: [0.05724551], r: [119.20049], f: [3.0961775e-07]\n",
      "f_r: [0.02795961], r: [119.95702], f: [1.7790944e-05]\n",
      "f_r: [0.02276007], r: [119.398224], f: [1.1091767e-05]\n",
      "f_r: [0.08812084], r: [119.80177], f: [0.948785]\n",
      "f_r: [-0.08318014], r: [119.492325], f: [6.671481e-16]\n",
      "f_r: [0.00413384], r: [119.111855], f: [2.0668401e-11]\n",
      "f_r: [0.01431211], r: [119.15911], f: [23.774508]\n",
      "f_r: [-0.03795847], r: [119.77664], f: [8.8378766e-15]\n",
      "f_r: [-0.00050084], r: [119.35678], f: [0.9449262]\n",
      "f_r: [-0.02506495], r: [119.135475], f: [2.8468226e-06]\n",
      "f_r: [0.08995855], r: [119.56938], f: [5.0056855e-12]\n",
      "f_r: [0.06992574], r: [119.27555], f: [3.7164494e-08]\n",
      "f_r: [-0.00375544], r: [119.34403], f: [6.059715e-05]\n",
      "f_r: [0.18030521], r: [119.27737], f: [3.9038187e-12]\n",
      "f_r: [-0.01944587], r: [119.54931], f: [7.940352]\n",
      "f_r: [0.00041987], r: [119.05031], f: [171.86494]\n",
      "f_r: [-0.01028839], r: [119.46589], f: [1.1346889e-14]\n",
      "f_r: [0.00969024], r: [119.34471], f: [7.269487e-09]\n",
      "f_r: [-0.04281968], r: [119.29693], f: [26.77977]\n",
      "f_r: [-0.02687212], r: [119.001945], f: [1.2356071e-09]\n",
      "f_r: [-0.02763641], r: [119.291916], f: [0.00334433]\n",
      "f_r: [-0.00157949], r: [119.61683], f: [4.4140215]\n",
      "f_r: [-0.03774215], r: [119.84177], f: [226.82074]\n",
      "f_r: [-0.05057692], r: [119.50075], f: [14.706104]\n",
      "f_r: [-0.03706994], r: [119.152534], f: [4.1399675e-09]\n",
      "f_r: [-0.0236919], r: [119.0385], f: [215.17473]\n",
      "f_r: [-0.03434277], r: [119.875595], f: [2.422807e-13]\n",
      "f_r: [-0.02454706], r: [119.406425], f: [82.68046]\n",
      "Training loss for epoch 21: pinn: 1.2130, boundary: 61.9597, total: 63.1727\n",
      "f_r: [-0.04762037], r: [119.5329], f: [6.4047796e-05]\n",
      "f_r: [-0.07536481], r: [119.39777], f: [9.550444e-12]\n",
      "f_r: [-0.0353097], r: [119.712006], f: [1.9670276e-18]\n",
      "f_r: [-0.00061144], r: [119.99639], f: [9.28253e-15]\n",
      "f_r: [-0.02548359], r: [119.59994], f: [0.00046009]\n",
      "f_r: [-0.00539763], r: [119.690544], f: [65.07807]\n",
      "f_r: [0.01110168], r: [119.68803], f: [0.09418746]\n",
      "f_r: [-0.01817758], r: [119.45541], f: [7.240676e-09]\n",
      "f_r: [0.01224248], r: [119.92889], f: [25.210934]\n",
      "f_r: [0.01169164], r: [119.225044], f: [0.0099797]\n",
      "f_r: [0.00413237], r: [119.59674], f: [3.752169e-08]\n",
      "f_r: [-0.03762424], r: [119.470665], f: [7.3383308e-06]\n",
      "f_r: [-0.01043235], r: [119.16594], f: [0.24448888]\n",
      "f_r: [-0.03953011], r: [119.61431], f: [2.901003e-10]\n",
      "f_r: [-0.00381024], r: [119.994095], f: [1.3039824]\n",
      "f_r: [0.01129913], r: [119.068016], f: [31.126709]\n",
      "f_r: [0.01961637], r: [119.90738], f: [61.933395]\n",
      "f_r: [0.00082764], r: [119.98197], f: [3.9675797e-12]\n",
      "f_r: [0.0293323], r: [119.876976], f: [3.752761e-09]\n",
      "f_r: [8.5076505e-07], r: [119.49164], f: [1.3942112]\n",
      "f_r: [-7.269957e-07], r: [119.84817], f: [0.90681875]\n",
      "f_r: [0.06644356], r: [119.99501], f: [6.2413672e-12]\n",
      "f_r: [0.09181403], r: [119.16139], f: [2.7254922e-08]\n",
      "f_r: [-1.470056e-06], r: [119.406876], f: [2.1472225]\n",
      "f_r: [0.05401039], r: [119.76247], f: [0.02251991]\n",
      "f_r: [0.0357458], r: [119.34154], f: [4.626078e-08]\n",
      "f_r: [0.03972704], r: [119.388885], f: [0.00616775]\n",
      "f_r: [0.01537071], r: [119.578735], f: [1.8135093e-05]\n",
      "f_r: [-0.01888962], r: [119.81502], f: [3.9144105e-10]\n",
      "f_r: [0.02836424], r: [119.142525], f: [8.5062565e-12]\n",
      "f_r: [0.02065024], r: [119.99982], f: [0.05720328]\n",
      "f_r: [-0.01055165], r: [119.96205], f: [5.833783]\n",
      "f_r: [0.05541311], r: [119.24597], f: [3.8130055e-10]\n",
      "f_r: [-0.01879695], r: [119.512146], f: [0.00019461]\n",
      "f_r: [-0.01854682], r: [119.33289], f: [6.663259]\n",
      "f_r: [-0.02865741], r: [119.71337], f: [9.895551e-12]\n",
      "f_r: [-0.000298], r: [119.44538], f: [2.1233854]\n",
      "f_r: [-0.01448469], r: [119.68507], f: [1.1146742e-08]\n",
      "f_r: [0.00015869], r: [119.76408], f: [439.59885]\n",
      "f_r: [0.11120639], r: [119.34586], f: [5.6243124e-07]\n",
      "Training loss for epoch 22: pinn: 1.0221, boundary: 82.2133, total: 83.2354\n",
      "f_r: [0.02900818], r: [119.06665], f: [7.329523e-12]\n",
      "f_r: [0.03036477], r: [119.77002], f: [0.27404833]\n",
      "f_r: [0.01599152], r: [119.14662], f: [0.02998742]\n",
      "f_r: [-0.00297585], r: [119.53904], f: [8.570523]\n",
      "f_r: [-0.0017428], r: [119.576904], f: [0.02825024]\n",
      "f_r: [0.00694431], r: [119.281456], f: [6.8049803]\n",
      "f_r: [0.1567896], r: [119.228455], f: [1.6371399e-07]\n",
      "f_r: [0.00848368], r: [119.526276], f: [0.1659028]\n",
      "f_r: [0.01653017], r: [119.7892], f: [7.0767475e-10]\n",
      "f_r: [-0.02007703], r: [119.13639], f: [3.2501152e-14]\n",
      "f_r: [-0.01828886], r: [119.46178], f: [177.14313]\n",
      "f_r: [-0.02636077], r: [119.24915], f: [1.1257498e-13]\n",
      "f_r: [-0.00604565], r: [119.44515], f: [0.00025896]\n",
      "f_r: [-0.00193684], r: [119.50349], f: [1.5696377e-13]\n",
      "f_r: [0.00326482], r: [119.68666], f: [202.75064]\n",
      "f_r: [-0.01595138], r: [119.22299], f: [79.30858]\n",
      "f_r: [0.02480943], r: [119.871254], f: [3.7579433e-11]\n",
      "f_r: [-0.00445977], r: [119.40097], f: [0.00114463]\n",
      "f_r: [0.01753175], r: [119.86828], f: [0.0664957]\n",
      "f_r: [-0.00445516], r: [119.63006], f: [5.2963284e-10]\n",
      "f_r: [-0.00823619], r: [119.13366], f: [0.000176]\n",
      "f_r: [-0.01621305], r: [119.70059], f: [38.583054]\n",
      "f_r: [0.02351302], r: [119.96594], f: [2.7357375e-15]\n",
      "f_r: [-0.00984711], r: [119.22323], f: [1.1450894]\n",
      "f_r: [0.01355425], r: [119.33812], f: [0.7219404]\n",
      "f_r: [-0.02062967], r: [119.7803], f: [119.74107]\n",
      "f_r: [0.0329011], r: [119.68232], f: [1.877771e-14]\n",
      "f_r: [-0.0054405], r: [119.62641], f: [4.048745]\n",
      "f_r: [0.0024822], r: [119.09345], f: [1.87204e-05]\n",
      "f_r: [-0.01397785], r: [119.50326], f: [2.4486731e-05]\n",
      "f_r: [-0.0454844], r: [119.922485], f: [3.4364737e-07]\n",
      "f_r: [0.00386868], r: [119.97189], f: [1.367067e-08]\n",
      "f_r: [0.01667478], r: [119.8987], f: [3.345305e-11]\n",
      "f_r: [-0.01514891], r: [119.055756], f: [48.256413]\n",
      "f_r: [0.02134792], r: [119.51739], f: [127.15096]\n",
      "f_r: [0.00251229], r: [119.1814], f: [4.0652926e-06]\n",
      "f_r: [0.00868975], r: [119.63805], f: [2.3539783e-13]\n",
      "f_r: [-0.00223624], r: [119.787605], f: [16.077765]\n",
      "f_r: [-0.00449382], r: [119.646034], f: [3.3919594]\n",
      "f_r: [-0.00474459], r: [119.0796], f: [1.9044226e-14]\n",
      "Training loss for epoch 23: pinn: 0.6877, boundary: 38.0640, total: 38.7517\n",
      "f_r: [-0.01373489], r: [119.496414], f: [4.388706e-15]\n",
      "f_r: [0.06492811], r: [119.91355], f: [1.4532936e-08]\n",
      "f_r: [-0.01668798], r: [119.18048], f: [1.55827e-05]\n",
      "f_r: [0.01056057], r: [119.42556], f: [0.00037281]\n",
      "f_r: [-0.0156313], r: [119.36999], f: [0.42591417]\n",
      "f_r: [-0.05548826], r: [119.281456], f: [2.6758931e-08]\n",
      "f_r: [-0.02955889], r: [119.6741], f: [5.769972e-06]\n",
      "f_r: [-0.08629552], r: [119.65287], f: [1.3452404e-13]\n",
      "f_r: [0.01848088], r: [119.807945], f: [2.0268622e-09]\n",
      "f_r: [0.04539536], r: [119.98472], f: [0.0001175]\n",
      "f_r: [-0.03361149], r: [119.88223], f: [1.2374784e-11]\n",
      "f_r: [0.00680828], r: [119.74969], f: [1.3580163e-14]\n",
      "f_r: [0.03958916], r: [119.30604], f: [0.01059275]\n",
      "f_r: [0.0008596], r: [119.9545], f: [64.36809]\n",
      "f_r: [-0.00027325], r: [119.08437], f: [0.00021678]\n",
      "f_r: [0.06209747], r: [119.43421], f: [2.5179917e-08]\n",
      "f_r: [0.01072158], r: [119.66018], f: [1.0107421e-08]\n",
      "f_r: [-0.01127304], r: [119.08982], f: [1.7391374e-10]\n",
      "f_r: [-0.00543949], r: [119.0344], f: [2.988434]\n",
      "f_r: [-0.0078673], r: [119.85845], f: [2.0061228e-10]\n",
      "f_r: [-0.01918119], r: [119.367035], f: [2.0458877]\n",
      "f_r: [0.0313943], r: [119.16139], f: [5.3354196e-12]\n",
      "f_r: [-0.00746614], r: [119.68049], f: [1.6011395e-13]\n",
      "f_r: [-0.02505888], r: [119.94856], f: [43.177635]\n",
      "f_r: [-0.00391657], r: [119.65949], f: [0.00189412]\n",
      "f_r: [0.00820502], r: [119.35702], f: [3.6127499e-12]\n",
      "f_r: [-0.03839323], r: [119.76727], f: [4.895611e-07]\n",
      "f_r: [-0.00617325], r: [119.39664], f: [0.00206738]\n",
      "f_r: [0.04061519], r: [119.25961], f: [6.09726e-13]\n",
      "f_r: [-0.00133042], r: [119.55911], f: [0.92951995]\n",
      "f_r: [0.02118228], r: [119.225044], f: [1.915609e-08]\n",
      "f_r: [0.0087024], r: [119.70926], f: [81.03099]\n",
      "f_r: [-0.00820113], r: [119.98791], f: [48.158165]\n",
      "f_r: [0.00267825], r: [119.044846], f: [8.4624094e-14]\n",
      "f_r: [0.04249509], r: [119.17004], f: [9.054243e-08]\n",
      "f_r: [0.02236353], r: [119.472946], f: [148.50406]\n",
      "f_r: [-0.00051744], r: [119.28419], f: [0.00957132]\n",
      "f_r: [0.02047882], r: [119.10163], f: [223.95596]\n",
      "f_r: [-0.0357112], r: [119.05847], f: [3.880285e-07]\n",
      "f_r: [-0.01014018], r: [119.57326], f: [2.1831613e-06]\n",
      "Training loss for epoch 24: pinn: 0.6761, boundary: 52.9497, total: 53.6258\n",
      "f_r: [-0.00019635], r: [119.83902], f: [28.613428]\n",
      "f_r: [0.00911872], r: [119.167755], f: [23704.982]\n",
      "f_r: [0.03319794], r: [119.228455], f: [0.00973621]\n",
      "f_r: [0.00403608], r: [119.390945], f: [82.1074]\n",
      "f_r: [-0.04081086], r: [119.842445], f: [4.140579e-11]\n",
      "f_r: [-0.02407417], r: [119.72227], f: [1.0042576e-17]\n",
      "f_r: [-0.02083205], r: [119.7241], f: [1.1133215e-05]\n",
      "f_r: [-0.00395446], r: [119.83834], f: [2.583037e-06]\n",
      "f_r: [0.00648632], r: [119.09777], f: [10.2403]\n",
      "f_r: [0.00172374], r: [119.09414], f: [7.6212654]\n",
      "f_r: [0.03932815], r: [119.19798], f: [1.8945483e-12]\n",
      "f_r: [-0.00156193], r: [119.46975], f: [35.69953]\n",
      "f_r: [0.00868028], r: [119.221634], f: [25.67847]\n",
      "f_r: [0.04683067], r: [119.13934], f: [0.03542138]\n",
      "f_r: [0.00329081], r: [119.55524], f: [3.869332e-07]\n",
      "f_r: [-0.0106397], r: [119.96983], f: [1.4682296e-07]\n",
      "f_r: [-0.00078001], r: [119.49482], f: [2.0558262]\n",
      "f_r: [-0.05100265], r: [119.46451], f: [4.4389235e-11]\n",
      "f_r: [0.00587303], r: [119.14139], f: [0.2519725]\n",
      "f_r: [-0.0235262], r: [119.02169], f: [2.7807706e-11]\n",
      "f_r: [0.01776216], r: [119.73278], f: [1.0760199]\n",
      "f_r: [0.02227198], r: [119.62778], f: [1.51224385e-05]\n",
      "f_r: [0.01274103], r: [119.54703], f: [7.122018e-13]\n",
      "f_r: [0.00312788], r: [119.493454], f: [0.01362547]\n",
      "f_r: [0.00461618], r: [119.67706], f: [1.7225012e-15]\n",
      "f_r: [-0.00993889], r: [119.64009], f: [1.9879245e-07]\n",
      "f_r: [0.02048997], r: [119.73027], f: [7.237501e-05]\n",
      "f_r: [0.01174928], r: [119.35587], f: [3.3963224e-06]\n",
      "f_r: [0.02568863], r: [119.251884], f: [0.0002741]\n",
      "f_r: [0.03372865], r: [119.103676], f: [0.00092591]\n",
      "f_r: [0.02242199], r: [119.32925], f: [0.00111907]\n",
      "f_r: [-0.0296909], r: [119.817764], f: [8.302272e-08]\n",
      "f_r: [-0.02644639], r: [119.95107], f: [7.503686e-11]\n",
      "f_r: [0.00015904], r: [119.44811], f: [110.25049]\n",
      "f_r: [-0.01329285], r: [119.107765], f: [1.4178686e-07]\n",
      "f_r: [0.0077273], r: [119.015564], f: [500.5642]\n",
      "f_r: [-0.01087631], r: [119.51443], f: [5.564529e-10]\n",
      "f_r: [0.00284665], r: [119.61706], f: [824.945]\n",
      "f_r: [0.00130384], r: [119.68894], f: [332.41574]\n",
      "f_r: [-0.00095161], r: [119.53746], f: [0.00031616]\n",
      "Training loss for epoch 25: pinn: 0.7497, boundary: 77.6421, total: 78.3919\n",
      "f_r: [-0.02895566], r: [119.64535], f: [4.868098e-10]\n",
      "f_r: [0.019641], r: [119.773445], f: [0.00010734]\n",
      "f_r: [-0.0028582], r: [119.23573], f: [1.4865535e-06]\n",
      "f_r: [0.02231027], r: [119.875145], f: [0.00675897]\n",
      "f_r: [-0.04110158], r: [119.788284], f: [4.564347e-09]\n",
      "f_r: [-0.02631557], r: [119.3577], f: [0.0085561]\n",
      "f_r: [-0.07725039], r: [119.301025], f: [2.3541343e-14]\n",
      "f_r: [-0.02057414], r: [119.78737], f: [0.47061446]\n",
      "f_r: [0.0003066], r: [119.93163], f: [3.4451662e-07]\n",
      "f_r: [0.07529597], r: [119.58238], f: [3.182955e-08]\n",
      "f_r: [0.00258882], r: [119.103], f: [6.9845457]\n",
      "f_r: [-1.9910779e-07], r: [119.95267], f: [5.951382]\n",
      "f_r: [0.02713901], r: [119.47682], f: [5.124855e-07]\n",
      "f_r: [0.01688658], r: [119.690544], f: [0.01079526]\n",
      "f_r: [0.00834438], r: [119.33129], f: [1.3820184e-12]\n",
      "f_r: [-0.00598517], r: [119.36179], f: [6.914079e-07]\n",
      "f_r: [-0.03768245], r: [119.75882], f: [3.0976696e-14]\n",
      "f_r: [0.00380595], r: [119.342445], f: [0.00010405]\n",
      "f_r: [-0.00541311], r: [119.80976], f: [9.998146e-13]\n",
      "f_r: [0.00057746], r: [119.650826], f: [3.8770208]\n",
      "f_r: [0.01547978], r: [119.58581], f: [3.269023e-13]\n",
      "f_r: [-0.00093724], r: [119.1423], f: [54.77756]\n",
      "f_r: [0.00568703], r: [119.064156], f: [3.612346e-05]\n",
      "f_r: [-0.014601], r: [119.0469], f: [1.7892318e-09]\n",
      "f_r: [-0.00044494], r: [119.275085], f: [1.0299265]\n",
      "f_r: [0.00472065], r: [119.80086], f: [669.9401]\n",
      "f_r: [0.11057282], r: [119.74991], f: [1.3779421]\n",
      "f_r: [0.01083427], r: [119.85113], f: [47.89232]\n",
      "f_r: [0.02859805], r: [119.314674], f: [1.1948878e-05]\n",
      "f_r: [-0.00345868], r: [119.80063], f: [148.45067]\n",
      "f_r: [0.01579556], r: [119.58123], f: [46.875072]\n",
      "f_r: [0.0283879], r: [119.02601], f: [3.5550445e-06]\n",
      "f_r: [0.0589145], r: [119.35975], f: [4.0357936e-05]\n",
      "f_r: [0.01331471], r: [119.14844], f: [1.1880519e-07]\n",
      "f_r: [0.02865898], r: [119.17548], f: [0.04254349]\n",
      "f_r: [0.0202589], r: [119.31559], f: [2.2200791e-07]\n",
      "f_r: [0.00919614], r: [119.28214], f: [0.01399375]\n",
      "f_r: [0.00273868], r: [119.060524], f: [0.07551946]\n",
      "f_r: [0.00333724], r: [119.12617], f: [0.01767928]\n",
      "f_r: [0.00863665], r: [119.442635], f: [112.11748]\n",
      "Training loss for epoch 26: pinn: 0.7203, boundary: 67.0456, total: 67.7659\n",
      "f_r: [-0.03128732], r: [119.10936], f: [2.6523976e-11]\n",
      "f_r: [0.00448782], r: [119.96732], f: [0.0003202]\n",
      "f_r: [0.00169075], r: [119.41986], f: [3211.1875]\n",
      "f_r: [0.01509175], r: [119.64147], f: [0.08438605]\n",
      "f_r: [-0.00788657], r: [119.103676], f: [0.00661488]\n",
      "f_r: [0.00725107], r: [119.207306], f: [6.5745786e-05]\n",
      "f_r: [-0.0393669], r: [119.55615], f: [1.3611095e-11]\n",
      "f_r: [-0.00022965], r: [119.41645], f: [395.29538]\n",
      "f_r: [-0.01065165], r: [119.66726], f: [1.7252884e-07]\n",
      "f_r: [-0.01156423], r: [119.336525], f: [3.182379]\n",
      "f_r: [-0.01259882], r: [119.35951], f: [3.1704814]\n",
      "f_r: [-0.00096321], r: [119.888405], f: [1.8475911e-10]\n",
      "f_r: [-0.00660258], r: [119.86508], f: [0.16461086]\n",
      "f_r: [-0.0284712], r: [119.21254], f: [6.618024e-12]\n",
      "f_r: [0.00235627], r: [119.58329], f: [64.98935]\n",
      "f_r: [0.00774847], r: [119.873535], f: [0.0007122]\n",
      "f_r: [-0.00168732], r: [119.40961], f: [4.9991096e-09]\n",
      "f_r: [-0.00237456], r: [119.12548], f: [131.00195]\n",
      "f_r: [0.00124101], r: [119.32901], f: [0.3333844]\n",
      "f_r: [0.02410381], r: [119.71085], f: [8.111877e-06]\n",
      "f_r: [0.02696143], r: [119.80542], f: [1.6793474e-05]\n",
      "f_r: [-0.00040734], r: [119.549995], f: [38.724564]\n",
      "f_r: [0.00259102], r: [119.565735], f: [0.00014905]\n",
      "f_r: [-0.03628607], r: [119.470436], f: [5.537115e-11]\n",
      "f_r: [0.01480801], r: [119.11094], f: [0.00010895]\n",
      "f_r: [0.007045], r: [119.943756], f: [0.0292456]\n",
      "f_r: [-0.00930813], r: [119.59036], f: [7.778177]\n",
      "f_r: [-0.01203097], r: [119.738945], f: [5.3206946e-08]\n",
      "f_r: [-0.01215711], r: [119.94901], f: [0.0574981]\n",
      "f_r: [2.7271586e-05], r: [119.03419], f: [347.6439]\n",
      "f_r: [-0.00530727], r: [119.18821], f: [0.1725219]\n",
      "f_r: [0.00635371], r: [119.2205], f: [104.19648]\n",
      "f_r: [-0.0089765], r: [119.76568], f: [6.931364e-14]\n",
      "f_r: [0.00198094], r: [119.97602], f: [5.625877e-06]\n",
      "f_r: [0.01273569], r: [119.69418], f: [3.3537113e-08]\n",
      "f_r: [0.00019045], r: [119.64946], f: [0.75430703]\n",
      "f_r: [0.00171666], r: [119.22254], f: [2.3604142e-15]\n",
      "f_r: [-0.00231164], r: [119.82783], f: [213.59412]\n",
      "f_r: [0.00066633], r: [119.538826], f: [1.6548101e-07]\n",
      "f_r: [0.00323676], r: [119.995926], f: [3.4494463e-09]\n",
      "Training loss for epoch 27: pinn: 0.5353, boundary: 36.0632, total: 36.5985\n",
      "f_r: [0.01789187], r: [119.8477], f: [202.16562]\n",
      "f_r: [-0.03391786], r: [119.24597], f: [0.32234132]\n",
      "f_r: [-0.02549353], r: [119.17435], f: [7.556668e-15]\n",
      "f_r: [-0.01788326], r: [119.65904], f: [4.3176508e-11]\n",
      "f_r: [0.03524182], r: [119.241875], f: [0.04151179]\n",
      "f_r: [0.00034279], r: [119.869194], f: [8.904124]\n",
      "f_r: [0.00358628], r: [119.14139], f: [952.28314]\n",
      "f_r: [0.04542903], r: [119.62162], f: [7.780171e-08]\n",
      "f_r: [-0.00259144], r: [119.95107], f: [3.171156e-12]\n",
      "f_r: [-0.01316005], r: [119.17298], f: [3.276731e-14]\n",
      "f_r: [-0.00453499], r: [119.93095], f: [4.301542e-10]\n",
      "f_r: [-0.00185908], r: [119.295334], f: [29.912666]\n",
      "f_r: [-0.02883432], r: [119.70949], f: [9.302086]\n",
      "f_r: [-0.05733975], r: [119.03077], f: [1.3638535e-15]\n",
      "f_r: [0.0055291], r: [119.38479], f: [1137.1757]\n",
      "f_r: [0.00601354], r: [119.727295], f: [2428.6194]\n",
      "f_r: [-0.06954893], r: [119.157295], f: [8.665169e-11]\n",
      "f_r: [-0.06417599], r: [119.206406], f: [1.07990436e-10]\n",
      "f_r: [0.01055994], r: [119.052345], f: [1.2578019e-07]\n",
      "f_r: [-0.00095422], r: [119.68209], f: [5.659694]\n",
      "f_r: [0.0128629], r: [119.05326], f: [0.00114638]\n",
      "f_r: [-0.00227134], r: [119.49254], f: [3.389949e-09]\n",
      "f_r: [0.03675245], r: [119.07438], f: [3.060492e-12]\n",
      "f_r: [0.02095833], r: [119.08073], f: [1.2264868e-06]\n",
      "f_r: [0.00657424], r: [119.46338], f: [70.149185]\n",
      "f_r: [-0.0021468], r: [119.0058], f: [1.0719439e-14]\n",
      "f_r: [0.02623545], r: [119.84976], f: [0.03002862]\n",
      "f_r: [0.00868024], r: [119.00353], f: [9.3302766e-08]\n",
      "f_r: [-0.005145], r: [119.81593], f: [145.07475]\n",
      "f_r: [-0.01651315], r: [119.02419], f: [1.9118571e-15]\n",
      "f_r: [-0.00675605], r: [119.032135], f: [15.549523]\n",
      "f_r: [-0.0018779], r: [119.666115], f: [261.502]\n",
      "f_r: [-0.00692123], r: [119.96366], f: [0.00013266]\n",
      "f_r: [-0.01990631], r: [119.872406], f: [3.5643992e-05]\n",
      "f_r: [-0.02560937], r: [119.15411], f: [1.5434229e-10]\n",
      "f_r: [-0.02671263], r: [119.522865], f: [1.1872183e-07]\n",
      "f_r: [-0.0217642], r: [119.10504], f: [2.7165745e-09]\n",
      "f_r: [0.0039889], r: [119.40893], f: [30.200352]\n",
      "f_r: [1.4978581e-05], r: [119.89115], f: [4.794692]\n",
      "f_r: [-0.00159335], r: [119.36134], f: [5.3795643]\n",
      "Training loss for epoch 28: pinn: 0.7766, boundary: 65.4966, total: 66.2732\n",
      "f_r: [0.00287994], r: [119.57098], f: [1.0361535e-14]\n",
      "f_r: [0.04197604], r: [119.456314], f: [0.00075573]\n",
      "f_r: [0.00035649], r: [119.61956], f: [4543.524]\n",
      "f_r: [-0.01060253], r: [119.84817], f: [2.0544901e-08]\n",
      "f_r: [-0.02683311], r: [119.52126], f: [0.00010726]\n",
      "f_r: [-0.0122134], r: [119.09141], f: [3.4352381]\n",
      "f_r: [-0.02886977], r: [119.92157], f: [3.3570948e-09]\n",
      "f_r: [-0.04867108], r: [119.75471], f: [1.9630298e-13]\n",
      "f_r: [0.00291393], r: [119.1298], f: [2.2911713e-08]\n",
      "f_r: [0.00771876], r: [119.70447], f: [89.48683]\n",
      "f_r: [0.00514183], r: [119.88383], f: [46.727615]\n",
      "f_r: [0.00123327], r: [119.621155], f: [215.38672]\n",
      "f_r: [0.03790997], r: [119.06302], f: [3.4623857e-09]\n",
      "f_r: [-0.00347149], r: [119.653786], f: [2.5065588e-06]\n",
      "f_r: [0.01109166], r: [119.48344], f: [4.6809055e-07]\n",
      "f_r: [0.01616986], r: [119.584206], f: [2.2620252e-09]\n",
      "f_r: [-0.00296273], r: [119.57189], f: [4.8662827e-12]\n",
      "f_r: [-0.00256575], r: [119.90715], f: [130.54468]\n",
      "f_r: [-0.00324526], r: [119.59949], f: [123.431366]\n",
      "f_r: [-0.00906802], r: [119.01306], f: [0.00070418]\n",
      "f_r: [-0.01381341], r: [119.60976], f: [2.6081112e-14]\n",
      "f_r: [-0.00280874], r: [119.178894], f: [73.0138]\n",
      "f_r: [0.00025901], r: [119.05757], f: [0.05084298]\n",
      "f_r: [-0.02358676], r: [119.60381], f: [2.9958722e-10]\n",
      "f_r: [-8.8627945e-05], r: [119.193665], f: [1.1966664]\n",
      "f_r: [-0.00423907], r: [119.06665], f: [2.272443e-09]\n",
      "f_r: [-0.00036051], r: [119.79903], f: [2.6243083]\n",
      "f_r: [0.01491632], r: [119.27873], f: [7.004264e-09]\n",
      "f_r: [0.00038765], r: [119.90853], f: [2.3747947]\n",
      "f_r: [0.00098235], r: [119.30967], f: [2.5879265e-06]\n",
      "f_r: [0.00114944], r: [119.70538], f: [2.2755105e-06]\n",
      "f_r: [0.00016804], r: [119.646034], f: [4.823763e-07]\n",
      "f_r: [-0.00506678], r: [119.18685], f: [0.11696816]\n",
      "f_r: [-2.0601125e-05], r: [119.98723], f: [5.980276e-07]\n",
      "f_r: [0.00309316], r: [119.68939], f: [7.825837e-05]\n",
      "f_r: [-0.0121046], r: [119.39869], f: [1.2564557e-14]\n",
      "f_r: [0.0051819], r: [119.144806], f: [2.9004374e-07]\n",
      "f_r: [0.0186346], r: [119.09164], f: [63.643635]\n",
      "f_r: [0.00580025], r: [119.85251], f: [1.0005172e-11]\n",
      "f_r: [0.00788619], r: [119.042816], f: [0.05298772]\n",
      "Training loss for epoch 29: pinn: 0.5210, boundary: 41.0047, total: 41.5257\n",
      "f_r: [-0.00608123], r: [119.53267], f: [11.20472]\n",
      "f_r: [-0.03588767], r: [119.4611], f: [2.5442259e-15]\n",
      "f_r: [-0.01844148], r: [119.58147], f: [0.00514693]\n",
      "f_r: [0.01207365], r: [119.3124], f: [0.08149279]\n",
      "f_r: [0.03586384], r: [119.67798], f: [0.17337598]\n",
      "f_r: [0.0019234], r: [119.85617], f: [1.07639515e-08]\n",
      "f_r: [0.01094261], r: [119.62754], f: [26.70947]\n",
      "f_r: [0.02023649], r: [119.74739], f: [0.30178046]\n",
      "f_r: [0.00091584], r: [119.091866], f: [0.23022215]\n",
      "f_r: [0.0096398], r: [119.07528], f: [0.00443742]\n",
      "f_r: [-0.00421644], r: [119.43217], f: [30.441753]\n",
      "f_r: [-0.03168603], r: [119.9099], f: [3.3297177e-13]\n",
      "f_r: [0.00541233], r: [119.90693], f: [1.2846444e-05]\n",
      "f_r: [0.02521516], r: [119.11004], f: [1.6429157e-09]\n",
      "f_r: [0.00405076], r: [119.991585], f: [6.681756e-09]\n",
      "f_r: [0.0118815], r: [119.192535], f: [1.4137238e-12]\n",
      "f_r: [0.01502053], r: [119.8324], f: [2.7270683e-15]\n",
      "f_r: [0.00282636], r: [119.49505], f: [67.34501]\n",
      "f_r: [-0.00576967], r: [119.01375], f: [26.584795]\n",
      "f_r: [0.02146897], r: [119.90098], f: [8.815619e-15]\n",
      "f_r: [0.01464223], r: [119.89641], f: [4.3067182e-08]\n",
      "f_r: [-0.00228854], r: [119.89938], f: [2.528547]\n",
      "f_r: [0.0147285], r: [119.44424], f: [5.150939e-06]\n",
      "f_r: [-0.00298489], r: [119.57258], f: [1.0833664]\n",
      "f_r: [0.00061031], r: [119.43376], f: [0.95643324]\n",
      "f_r: [-0.0152498], r: [119.09437], f: [2.9139933e-12]\n",
      "f_r: [-0.02524784], r: [119.58351], f: [5.989167e-13]\n",
      "f_r: [3.832337e-06], r: [119.12845], f: [2.0301769]\n",
      "f_r: [-0.00944615], r: [119.75859], f: [3.8853173e-07]\n",
      "f_r: [-0.00568199], r: [119.23279], f: [166.56427]\n",
      "f_r: [0.01281691], r: [119.81914], f: [1.5551659e-14]\n",
      "f_r: [0.00376385], r: [119.225044], f: [0.00144842]\n",
      "f_r: [0.00945393], r: [119.24438], f: [1.00787794e-07]\n",
      "f_r: [0.00455133], r: [119.39982], f: [0.10412815]\n",
      "f_r: [-0.01516931], r: [119.73461], f: [3.4399457e-09]\n",
      "f_r: [0.00071155], r: [119.13184], f: [256.5536]\n",
      "f_r: [-0.00359337], r: [119.36043], f: [5.9072794e-05]\n",
      "f_r: [0.02781655], r: [119.66132], f: [4.7312948e-12]\n",
      "f_r: [-0.00704063], r: [119.77732], f: [7.522308e-09]\n",
      "f_r: [0.00721166], r: [119.192535], f: [0.00719989]\n",
      "Training loss for epoch 30: pinn: 0.5011, boundary: 52.6749, total: 53.1760\n",
      "f_r: [-0.00689615], r: [119.9465], f: [1.4124614e-06]\n",
      "f_r: [0.06305589], r: [119.64192], f: [2.086916e-11]\n",
      "f_r: [0.0186251], r: [119.6951], f: [131.19986]\n",
      "f_r: [0.00265241], r: [119.25302], f: [2.6348368e-10]\n",
      "f_r: [-0.01009642], r: [119.060074], f: [1.3831788]\n",
      "f_r: [-0.01259192], r: [119.10163], f: [36.932545]\n",
      "f_r: [-0.00709562], r: [119.268936], f: [1.1665434]\n",
      "f_r: [-0.00065045], r: [119.70241], f: [0.48171693]\n",
      "f_r: [-0.01425233], r: [119.276], f: [3.1953256e-09]\n",
      "f_r: [-0.0218578], r: [119.495285], f: [7.9528723e-13]\n",
      "f_r: [-0.00147191], r: [119.895256], f: [2.723935]\n",
      "f_r: [-0.03632883], r: [119.77436], f: [2.9059034e-14]\n",
      "f_r: [-0.0047874], r: [119.585106], f: [3.2097005e-06]\n",
      "f_r: [0.00044495], r: [119.250755], f: [0.00093739]\n",
      "f_r: [-0.00307932], r: [119.68507], f: [7.142139e-07]\n",
      "f_r: [0.00273898], r: [119.33311], f: [70.30262]\n",
      "f_r: [0.00190683], r: [119.100044], f: [60.922897]\n",
      "f_r: [0.01707928], r: [119.73278], f: [3.7541265e-10]\n",
      "f_r: [-0.00031968], r: [119.57371], f: [7.8434315]\n",
      "f_r: [0.01174878], r: [119.71405], f: [4.882674e-08]\n",
      "f_r: [0.00687555], r: [119.179115], f: [0.00012498]\n",
      "f_r: [0.00602596], r: [119.92019], f: [2.5354779e-05]\n",
      "f_r: [-0.00378846], r: [119.202545], f: [7.2091823]\n",
      "f_r: [0.01195273], r: [119.11049], f: [0.0339825]\n",
      "f_r: [0.01176174], r: [119.73438], f: [0.0054212]\n",
      "f_r: [0.00220294], r: [119.919044], f: [4.070341e-11]\n",
      "f_r: [0.00435664], r: [119.34177], f: [1.4761756e-06]\n",
      "f_r: [0.0043328], r: [119.272354], f: [4.632522e-05]\n",
      "f_r: [0.00547234], r: [119.40097], f: [0.00078477]\n",
      "f_r: [0.00113276], r: [119.04848], f: [0.00540504]\n",
      "f_r: [-0.00540889], r: [119.6919], f: [0.09625848]\n",
      "f_r: [-0.02038958], r: [119.821884], f: [8.2020415e-12]\n",
      "f_r: [0.00120709], r: [119.89252], f: [2.6698529e-11]\n",
      "f_r: [-0.0007111], r: [119.33447], f: [4.328714]\n",
      "f_r: [0.00169713], r: [119.39117], f: [2.3594515e-07]\n",
      "f_r: [0.01193227], r: [119.22527], f: [39.01643]\n",
      "f_r: [-0.00017565], r: [119.33584], f: [1.8886903e-05]\n",
      "f_r: [0.00503782], r: [119.24597], f: [11.6720705]\n",
      "f_r: [-0.00010917], r: [119.35998], f: [308.54562]\n",
      "f_r: [-0.00446978], r: [119.23051], f: [4.0487275]\n",
      "Training loss for epoch 31: pinn: 0.4270, boundary: 35.5952, total: 36.0222\n",
      "f_r: [-0.00420636], r: [119.3297], f: [4.2498414e-05]\n",
      "f_r: [-0.00360237], r: [119.4864], f: [8.571001]\n",
      "f_r: [0.0277113], r: [119.79423], f: [4.219055e-08]\n",
      "f_r: [0.00266613], r: [119.506454], f: [3.489276]\n",
      "f_r: [-0.02283039], r: [119.794685], f: [7.045375e-08]\n",
      "f_r: [-0.04043624], r: [119.60222], f: [3.9152863e-07]\n",
      "f_r: [-0.07015682], r: [119.48092], f: [8.551259e-14]\n",
      "f_r: [-0.05180311], r: [119.224144], f: [1.0577756e-10]\n",
      "f_r: [-0.030127], r: [119.890465], f: [3.9585297e-13]\n",
      "f_r: [0.00054908], r: [119.59812], f: [6.6329058e-06]\n",
      "f_r: [-0.01191958], r: [119.776405], f: [3.5855159e-09]\n",
      "f_r: [-0.01075652], r: [119.48297], f: [6.966496e-08]\n",
      "f_r: [-0.04521193], r: [119.68049], f: [9.054128e-14]\n",
      "f_r: [0.00029011], r: [119.7136], f: [82.42919]\n",
      "f_r: [-0.00816977], r: [119.741455], f: [8.345186e-08]\n",
      "f_r: [0.01261228], r: [119.57758], f: [0.00121225]\n",
      "f_r: [-0.00029696], r: [119.27918], f: [62.144405]\n",
      "f_r: [0.00272899], r: [119.363396], f: [3.170573e-06]\n",
      "f_r: [0.00084574], r: [119.01284], f: [3.8953684e-05]\n",
      "f_r: [-0.00895591], r: [119.91699], f: [6.170349e-08]\n",
      "f_r: [-0.01051394], r: [119.05598], f: [2.995336e-13]\n",
      "f_r: [-0.00190812], r: [119.97625], f: [2.0124926e-06]\n",
      "f_r: [0.00663095], r: [119.50121], f: [0.00127264]\n",
      "f_r: [0.03027213], r: [119.772064], f: [2.94761e-13]\n",
      "f_r: [-0.00634679], r: [119.33084], f: [1.4938797e-06]\n",
      "f_r: [0.00258668], r: [119.32856], f: [2.9720514e-15]\n",
      "f_r: [0.00785197], r: [119.731636], f: [0.00010721]\n",
      "f_r: [0.00951644], r: [119.30717], f: [9.822057e-10]\n",
      "f_r: [-0.00409251], r: [119.00103], f: [6.542769e-08]\n",
      "f_r: [-0.02053368], r: [119.53495], f: [29.522236]\n",
      "f_r: [0.00274772], r: [119.25939], f: [0.00165976]\n",
      "f_r: [-0.01454884], r: [119.74237], f: [42.537598]\n",
      "f_r: [-0.02480261], r: [119.38638], f: [1.3023284e-09]\n",
      "f_r: [-0.01672569], r: [119.871704], f: [20.391037]\n",
      "f_r: [0.00151783], r: [119.65493], f: [1.0648153]\n",
      "f_r: [0.00468019], r: [119.733696], f: [5.1068313e-11]\n",
      "f_r: [0.00542756], r: [119.12048], f: [36.23256]\n",
      "f_r: [0.0050622], r: [119.74032], f: [0.00046316]\n",
      "f_r: [0.02141113], r: [119.69716], f: [9.831656e-13]\n",
      "f_r: [-0.00173488], r: [119.97213], f: [1.2440684e-07]\n",
      "Training loss for epoch 32: pinn: 0.4454, boundary: 37.8521, total: 38.2975\n",
      "f_r: [-0.01294775], r: [119.59834], f: [2.3457519e-11]\n",
      "f_r: [0.01660232], r: [119.54064], f: [1.9643941]\n",
      "f_r: [-0.01349114], r: [119.36954], f: [3.1223254]\n",
      "f_r: [-2.263379e-06], r: [119.19708], f: [0.30683818]\n",
      "f_r: [-0.00849649], r: [119.68711], f: [0.00417187]\n",
      "f_r: [-0.01823344], r: [119.26212], f: [0.37869364]\n",
      "f_r: [0.01399763], r: [119.15458], f: [2.250853e-16]\n",
      "f_r: [-0.018166], r: [119.945816], f: [1.8349506e-11]\n",
      "f_r: [-0.01536685], r: [119.89961], f: [1.4182504e-12]\n",
      "f_r: [0.04481472], r: [119.47227], f: [1.0081992e-05]\n",
      "f_r: [0.02028797], r: [119.526276], f: [0.00377623]\n",
      "f_r: [0.01647496], r: [119.91447], f: [3.6152443e-07]\n",
      "f_r: [-0.03324815], r: [119.51351], f: [2.2175735e-11]\n",
      "f_r: [-0.00769996], r: [119.70903], f: [0.00157209]\n",
      "f_r: [-0.0152432], r: [119.11685], f: [0.00168346]\n",
      "f_r: [-0.01704139], r: [119.91538], f: [0.00022257]\n",
      "f_r: [-0.04559245], r: [119.56048], f: [5.946882e-12]\n",
      "f_r: [-0.02068197], r: [119.552505], f: [6.812472e-14]\n",
      "f_r: [0.00409576], r: [119.4201], f: [2.3067753e-06]\n",
      "f_r: [0.00246043], r: [119.874916], f: [0.0001417]\n",
      "f_r: [-0.00416539], r: [119.28464], f: [2.6325195]\n",
      "f_r: [-0.01639692], r: [119.73849], f: [39.855324]\n",
      "f_r: [-0.02219916], r: [119.85296], f: [3.3014063e-09]\n",
      "f_r: [-0.02262184], r: [119.33016], f: [31.94306]\n",
      "f_r: [-0.01005963], r: [119.663155], f: [1.4957599e-10]\n",
      "f_r: [0.00114966], r: [119.852745], f: [4260.003]\n",
      "f_r: [-0.02737175], r: [119.88519], f: [0.2680652]\n",
      "f_r: [0.00503336], r: [119.435814], f: [0.06602112]\n",
      "f_r: [0.0086857], r: [119.352455], f: [503.73685]\n",
      "f_r: [0.0010705], r: [119.04031], f: [1.3570087]\n",
      "f_r: [0.0130629], r: [119.25029], f: [0.11342525]\n",
      "f_r: [0.0865142], r: [119.86988], f: [5.1361393e-10]\n",
      "f_r: [4.1903186e-05], r: [119.1432], f: [1.6226268]\n",
      "f_r: [7.46536e-06], r: [119.4144], f: [99.711555]\n",
      "f_r: [0.06664249], r: [119.89434], f: [6.3632477e-10]\n",
      "f_r: [-9.036783e-07], r: [119.30922], f: [2.1737473]\n",
      "f_r: [0.02198341], r: [119.66041], f: [6.649655e-05]\n",
      "f_r: [-0.02484206], r: [119.64558], f: [9.0341525e-14]\n",
      "f_r: [-0.00010467], r: [119.57051], f: [470.5775]\n",
      "f_r: [-0.00704608], r: [119.870575], f: [4.284289]\n",
      "Training loss for epoch 33: pinn: 0.6494, boundary: 58.4409, total: 59.0903\n",
      "f_r: [-0.0237462], r: [119.05871], f: [8.057656e-14]\n",
      "f_r: [-0.01647855], r: [119.53039], f: [1.7793826e-09]\n",
      "f_r: [-0.00142501], r: [119.61568], f: [0.46637413]\n",
      "f_r: [0.06264651], r: [119.77687], f: [0.04168067]\n",
      "f_r: [0.05604582], r: [119.79309], f: [0.00011605]\n",
      "f_r: [0.0159371], r: [119.5101], f: [1089.2203]\n",
      "f_r: [-0.00306258], r: [119.156395], f: [6.665929e-14]\n",
      "f_r: [0.01124211], r: [119.73964], f: [11.5937195]\n",
      "f_r: [-0.02511152], r: [119.39641], f: [4.5901877e-17]\n",
      "f_r: [-0.03182285], r: [119.6919], f: [1.10117575e-11]\n",
      "f_r: [-0.01029699], r: [119.95496], f: [0.5099697]\n",
      "f_r: [-0.00025673], r: [119.03419], f: [95.64028]\n",
      "f_r: [0.00563482], r: [119.14935], f: [0.00010214]\n",
      "f_r: [0.00083859], r: [119.0285], f: [708.37524]\n",
      "f_r: [-0.00973254], r: [119.76568], f: [1.3683922e-12]\n",
      "f_r: [-0.01167146], r: [119.06642], f: [4.0846826e-05]\n",
      "f_r: [-0.01796598], r: [119.298744], f: [0.00382166]\n",
      "f_r: [-0.00102517], r: [119.39959], f: [167.21307]\n",
      "f_r: [0.00242508], r: [119.361115], f: [2.4813411e-13]\n",
      "f_r: [0.00028692], r: [119.52468], f: [681.69635]\n",
      "f_r: [-0.00068489], r: [119.620705], f: [230.91022]\n",
      "f_r: [-0.00048091], r: [119.20959], f: [9.300038e-06]\n",
      "f_r: [-0.01581009], r: [119.523094], f: [3.3286294e-11]\n",
      "f_r: [3.5035882e-05], r: [119.26485], f: [1.6691956e-05]\n",
      "f_r: [-0.00281856], r: [119.88017], f: [8.083604e-08]\n",
      "f_r: [0.00615973], r: [119.19821], f: [1.3921427e-09]\n",
      "f_r: [0.0033926], r: [119.822334], f: [259.8471]\n",
      "f_r: [0.02292168], r: [119.484116], f: [0.00107785]\n",
      "f_r: [-0.00013659], r: [119.8413], f: [4.208663e-08]\n",
      "f_r: [0.00709157], r: [119.919044], f: [26.892738]\n",
      "f_r: [0.02926025], r: [119.49323], f: [7.2054238e-12]\n",
      "f_r: [-0.00095008], r: [119.24779], f: [337.3142]\n",
      "f_r: [-0.00239595], r: [119.99569], f: [5.047763e-13]\n",
      "f_r: [-0.00011924], r: [119.28942], f: [3.2953485e-05]\n",
      "f_r: [-0.00546894], r: [119.655846], f: [1.2574483e-14]\n",
      "f_r: [0.00325727], r: [119.400055], f: [11.581219]\n",
      "f_r: [0.04232771], r: [119.95839], f: [1.0294961e-12]\n",
      "f_r: [0.00080702], r: [119.36316], f: [8.441]\n",
      "f_r: [0.00102908], r: [119.00898], f: [0.00113246]\n",
      "f_r: [0.0004529], r: [119.2553], f: [3.537879e-14]\n",
      "Training loss for epoch 34: pinn: 0.4711, boundary: 39.5844, total: 40.0554\n",
      "f_r: [-0.01678153], r: [119.63805], f: [7.374545e-10]\n",
      "f_r: [-0.00332479], r: [119.43217], f: [3.233399]\n",
      "f_r: [-0.03203112], r: [119.66177], f: [0.02604431]\n",
      "f_r: [-0.01347504], r: [119.75265], f: [1.5596379e-16]\n",
      "f_r: [0.00270027], r: [119.50737], f: [5293.7476]\n",
      "f_r: [0.035961], r: [119.11754], f: [1.5220488e-11]\n",
      "f_r: [0.00652333], r: [119.24711], f: [515.3881]\n",
      "f_r: [-0.00450187], r: [119.23347], f: [2.436798e-10]\n",
      "f_r: [0.00954795], r: [119.69648], f: [5.917307e-06]\n",
      "f_r: [-0.02451726], r: [119.1723], f: [1.7910395e-11]\n",
      "f_r: [-0.01015724], r: [119.98334], f: [1.7516629e-12]\n",
      "f_r: [0.0048339], r: [119.93208], f: [4.8667555]\n",
      "f_r: [0.01025422], r: [119.86096], f: [1.5404556e-06]\n",
      "f_r: [0.03343739], r: [119.85113], f: [3.251235e-08]\n",
      "f_r: [-0.01151961], r: [119.866684], f: [2.1795632e-09]\n",
      "f_r: [0.00228133], r: [119.658356], f: [14.521255]\n",
      "f_r: [-0.00296999], r: [119.23528], f: [2.032624]\n",
      "f_r: [-0.00604839], r: [119.60428], f: [1.35098e-05]\n",
      "f_r: [0.00077606], r: [119.75493], f: [299.46063]\n",
      "f_r: [-0.04059732], r: [119.552505], f: [6.466163e-11]\n",
      "f_r: [-0.00071702], r: [119.49323], f: [2.5629933]\n",
      "f_r: [-0.0373769], r: [119.88657], f: [1.8841394e-10]\n",
      "f_r: [-0.0365064], r: [119.92842], f: [2.2079097e-10]\n",
      "f_r: [-0.03512797], r: [119.01693], f: [7.8940684e-13]\n",
      "f_r: [-0.0054335], r: [119.20959], f: [0.01874359]\n",
      "f_r: [-0.00184088], r: [119.70834], f: [4.7055806e-07]\n",
      "f_r: [0.00475172], r: [119.99067], f: [115.03159]\n",
      "f_r: [0.00643699], r: [119.412575], f: [0.09269408]\n",
      "f_r: [0.00095533], r: [119.90464], f: [426.10022]\n",
      "f_r: [-0.01605573], r: [119.91059], f: [1.8097107e-10]\n",
      "f_r: [0.00943338], r: [119.54042], f: [0.00014261]\n",
      "f_r: [0.0021589], r: [119.11775], f: [4.451746]\n",
      "f_r: [0.01340858], r: [119.25484], f: [6.070266e-14]\n",
      "f_r: [0.0038905], r: [119.5256], f: [0.0286004]\n",
      "f_r: [6.062587e-05], r: [119.61796], f: [458.12122]\n",
      "f_r: [0.0175558], r: [119.192535], f: [5.7528246e-15]\n",
      "f_r: [-0.00158391], r: [119.86828], f: [12.488306]\n",
      "f_r: [0.00412196], r: [119.088905], f: [0.00013352]\n",
      "f_r: [-0.00115495], r: [119.73781], f: [294.9712]\n",
      "f_r: [0.00018917], r: [119.21095], f: [1.287e-05]\n",
      "Training loss for epoch 35: pinn: 0.4592, boundary: 37.8405, total: 38.2997\n",
      "f_r: [-0.00040389], r: [119.82896], f: [488.84488]\n",
      "f_r: [-0.00815075], r: [119.75173], f: [6.4752254]\n",
      "f_r: [-0.00688654], r: [119.67867], f: [4.1864873e-11]\n",
      "f_r: [-0.00861326], r: [119.67616], f: [6.8673414e-11]\n",
      "f_r: [0.00056753], r: [119.291916], f: [364.6445]\n",
      "f_r: [-0.00623551], r: [119.46246], f: [1.0768541e-10]\n",
      "f_r: [0.00754453], r: [119.98654], f: [198.80795]\n",
      "f_r: [0.02420194], r: [119.94718], f: [3.9031995e-09]\n",
      "f_r: [-0.00222197], r: [119.19731], f: [2.4151015e-10]\n",
      "f_r: [0.00517711], r: [119.37431], f: [5.3340496e-05]\n",
      "f_r: [-0.0061602], r: [119.84566], f: [0.89262134]\n",
      "f_r: [-0.00251109], r: [119.265076], f: [2.0992354e-06]\n",
      "f_r: [0.00161183], r: [119.5183], f: [505.76025]\n",
      "f_r: [0.01304669], r: [119.34335], f: [0.09515747]\n",
      "f_r: [0.00927597], r: [119.2562], f: [2.0995507e-05]\n",
      "f_r: [0.008514], r: [119.24529], f: [144.40233]\n",
      "f_r: [0.00708825], r: [119.67547], f: [0.6934207]\n",
      "f_r: [-0.00083597], r: [119.22254], f: [3.4038136]\n",
      "f_r: [-0.00609175], r: [119.274185], f: [43.49976]\n",
      "f_r: [-0.0161651], r: [119.24597], f: [7.40219e-11]\n",
      "f_r: [0.01076701], r: [119.36248], f: [1.7521866e-13]\n",
      "f_r: [0.02098533], r: [119.123436], f: [1.4734473e-13]\n",
      "f_r: [0.0115007], r: [119.95016], f: [6.6029955e-08]\n",
      "f_r: [0.04341988], r: [119.3288], f: [5.524866e-15]\n",
      "f_r: [-0.00146035], r: [119.13957], f: [277.11182]\n",
      "f_r: [-0.02510978], r: [119.49893], f: [8.267285e-12]\n",
      "f_r: [0.00838232], r: [119.7063], f: [1.9041199e-08]\n",
      "f_r: [0.00497988], r: [119.23938], f: [2.6460166e-14]\n",
      "f_r: [-0.00342052], r: [119.65813], f: [4.9807763e-10]\n",
      "f_r: [-0.02124229], r: [119.80976], f: [1.5962683e-11]\n",
      "f_r: [-0.0052344], r: [119.938034], f: [2.9972438e-10]\n",
      "f_r: [-0.02471386], r: [119.663605], f: [4.866883e-13]\n",
      "f_r: [-0.00847215], r: [119.76819], f: [1.3848056]\n",
      "f_r: [-0.00218139], r: [119.870575], f: [0.00021179]\n",
      "f_r: [-0.02234508], r: [119.18481], f: [1.5977114e-12]\n",
      "f_r: [0.00549511], r: [119.79788], f: [77.219574]\n",
      "f_r: [0.01517003], r: [119.3281], f: [5.403309e-06]\n",
      "f_r: [0.00401615], r: [119.72114], f: [4.395413]\n",
      "f_r: [0.00804847], r: [119.33379], f: [86.70834]\n",
      "f_r: [0.0052556], r: [119.071884], f: [1.2122629]\n",
      "Training loss for epoch 36: pinn: 0.4267, boundary: 34.3312, total: 34.7578\n",
      "f_r: [0.00871986], r: [119.11572], f: [8.100184e-07]\n",
      "f_r: [0.03010208], r: [119.42351], f: [6.308403e-06]\n",
      "f_r: [0.00214056], r: [119.27645], f: [3848.0083]\n",
      "f_r: [-0.00088375], r: [119.533585], f: [1.7664338e-10]\n",
      "f_r: [-0.01225824], r: [119.16298], f: [0.00142067]\n",
      "f_r: [-0.04160713], r: [119.62503], f: [1.978026e-13]\n",
      "f_r: [-0.04310307], r: [119.210724], f: [6.8799785e-15]\n",
      "f_r: [-0.01955688], r: [119.10345], f: [0.00115096]\n",
      "f_r: [-0.01227379], r: [119.21482], f: [0.00010954]\n",
      "f_r: [0.01370471], r: [119.43172], f: [3.1801894e-05]\n",
      "f_r: [-0.00465507], r: [119.34358], f: [4.459185e-12]\n",
      "f_r: [0.01502623], r: [119.436264], f: [0.41449407]\n",
      "f_r: [-0.00496457], r: [119.3297], f: [7.908831e-11]\n",
      "f_r: [-0.00104586], r: [119.592865], f: [137.43945]\n",
      "f_r: [0.02007286], r: [119.79103], f: [1.1594338e-08]\n",
      "f_r: [0.00321459], r: [119.4144], f: [32.90458]\n",
      "f_r: [0.00441862], r: [119.537224], f: [1.361707e-07]\n",
      "f_r: [0.00914122], r: [119.50281], f: [1.3984096e-06]\n",
      "f_r: [0.00480757], r: [119.57051], f: [14.475688]\n",
      "f_r: [0.00460348], r: [119.05644], f: [0.00613699]\n",
      "f_r: [0.00658788], r: [119.36476], f: [1.6475838e-05]\n",
      "f_r: [0.00057723], r: [119.84657], f: [503.05057]\n",
      "f_r: [-0.01016976], r: [119.28464], f: [7.199089e-05]\n",
      "f_r: [-0.00260345], r: [119.28737], f: [3.7447063e-11]\n",
      "f_r: [0.00722584], r: [119.50964], f: [1.2575123e-06]\n",
      "f_r: [0.00354743], r: [119.375], f: [2.8043408e-14]\n",
      "f_r: [0.00248581], r: [119.72297], f: [5.57912e-10]\n",
      "f_r: [-0.0044267], r: [119.91402], f: [142.59897]\n",
      "f_r: [0.00195557], r: [119.96594], f: [6.537751e-09]\n",
      "f_r: [-0.00328815], r: [119.39664], f: [34.941208]\n",
      "f_r: [-0.00944746], r: [119.97098], f: [8.761047]\n",
      "f_r: [-0.00535296], r: [119.582146], f: [93.95901]\n",
      "f_r: [-0.00323], r: [119.141174], f: [157.53085]\n",
      "f_r: [-0.0033255], r: [119.145485], f: [0.00746394]\n",
      "f_r: [-0.00234683], r: [119.07256], f: [0.4031186]\n",
      "f_r: [0.00982955], r: [119.90304], f: [0.00130731]\n",
      "f_r: [-9.187749e-05], r: [119.09527], f: [2.3689315]\n",
      "f_r: [-0.00542522], r: [119.0939], f: [0.00598475]\n",
      "f_r: [0.0041262], r: [119.05598], f: [0.00046882]\n",
      "f_r: [-0.00616917], r: [119.18571], f: [0.00026241]\n",
      "Training loss for epoch 37: pinn: 0.3468, boundary: 43.7519, total: 44.0987\n",
      "f_r: [-0.00341943], r: [119.17661], f: [6.667683e-05]\n",
      "f_r: [-0.02199449], r: [119.890686], f: [6.485619e-05]\n",
      "f_r: [-0.01970604], r: [119.522865], f: [3.9857707e-11]\n",
      "f_r: [-0.00321968], r: [119.54635], f: [0.0059966]\n",
      "f_r: [0.01281557], r: [119.18889], f: [0.00041967]\n",
      "f_r: [0.02020629], r: [119.0787], f: [6.269217e-11]\n",
      "f_r: [0.01986442], r: [119.084145], f: [0.00744297]\n",
      "f_r: [0.00806751], r: [119.85411], f: [22.25666]\n",
      "f_r: [-0.00040044], r: [119.563225], f: [0.10356647]\n",
      "f_r: [-0.00088224], r: [119.77047], f: [5.5538636e-13]\n",
      "f_r: [-0.00508627], r: [119.90898], f: [1.3458575e-15]\n",
      "f_r: [-0.00596077], r: [119.07915], f: [3.370603e-15]\n",
      "f_r: [-0.02043393], r: [119.81663], f: [0.1183033]\n",
      "f_r: [-0.00386506], r: [119.25052], f: [0.00048013]\n",
      "f_r: [0.00790915], r: [119.167984], f: [8.326838e-06]\n",
      "f_r: [-0.00643689], r: [119.58351], f: [9.864568e-05]\n",
      "f_r: [0.01661117], r: [119.4349], f: [5.4327805e-12]\n",
      "f_r: [0.01753614], r: [119.26053], f: [1.105738e-12]\n",
      "f_r: [-0.00148951], r: [119.18685], f: [1.0131201e-15]\n",
      "f_r: [0.00229073], r: [119.42283], f: [2.2360013e-08]\n",
      "f_r: [-0.00452546], r: [119.71429], f: [0.00745439]\n",
      "f_r: [0.00287846], r: [119.74032], f: [106.84514]\n",
      "f_r: [0.02242623], r: [119.79401], f: [5.3032746e-13]\n",
      "f_r: [0.00315592], r: [119.13229], f: [1.7233437e-10]\n",
      "f_r: [-0.00082395], r: [119.38593], f: [30.90133]\n",
      "f_r: [-0.00226705], r: [119.32037], f: [201.69324]\n",
      "f_r: [0.02402259], r: [119.16139], f: [1.9841816e-13]\n",
      "f_r: [-0.00263243], r: [119.72707], f: [293.0325]\n",
      "f_r: [0.00018643], r: [119.0955], f: [2.5076163e-11]\n",
      "f_r: [-0.00347728], r: [119.7796], f: [6.0935267e-06]\n",
      "f_r: [-0.00410626], r: [119.13526], f: [1.2890833e-07]\n",
      "f_r: [-0.00719491], r: [119.06892], f: [4.8074985e-06]\n",
      "f_r: [-0.0060836], r: [119.822334], f: [1.8871759e-07]\n",
      "f_r: [0.00060986], r: [119.73141], f: [39.07408]\n",
      "f_r: [0.00542271], r: [119.142075], f: [1.1993451e-12]\n",
      "f_r: [-0.00656647], r: [119.71154], f: [3.5424904e-07]\n",
      "f_r: [-0.00065449], r: [119.04531], f: [8.312677e-13]\n",
      "f_r: [-0.00649865], r: [119.24346], f: [1.3999953e-09]\n",
      "f_r: [-0.00607875], r: [119.61067], f: [6.8785234e-11]\n",
      "f_r: [-0.00043706], r: [119.57554], f: [1.9233468]\n",
      "Training loss for epoch 38: pinn: 0.2929, boundary: 37.5014, total: 37.7943\n",
      "f_r: [0.00097808], r: [119.17708], f: [151.93738]\n",
      "f_r: [0.01602165], r: [119.45062], f: [10.911327]\n",
      "f_r: [0.00063804], r: [119.06302], f: [2.9642723]\n",
      "f_r: [0.01230283], r: [119.97694], f: [1.7187976e-13]\n",
      "f_r: [-0.01036301], r: [119.0394], f: [0.00972189]\n",
      "f_r: [-0.02366726], r: [119.1698], f: [1.4817116e-06]\n",
      "f_r: [-0.02448412], r: [119.053474], f: [7.8461846e-07]\n",
      "f_r: [-0.00481337], r: [119.039635], f: [6.418244e-07]\n",
      "f_r: [-0.00488303], r: [119.83696], f: [0.01292144]\n",
      "f_r: [0.00677003], r: [119.69397], f: [0.09396061]\n",
      "f_r: [0.00286679], r: [119.77755], f: [1.8249395e-12]\n",
      "f_r: [0.01219395], r: [119.38683], f: [1.2033714e-06]\n",
      "f_r: [-0.00281643], r: [119.901665], f: [3.5667717e-13]\n",
      "f_r: [-0.0037521], r: [119.549545], f: [1.6244839e-10]\n",
      "f_r: [-0.00465739], r: [119.204124], f: [3.3968064e-11]\n",
      "f_r: [-0.00165656], r: [119.18662], f: [267.01135]\n",
      "f_r: [0.01344011], r: [119.03305], f: [2.5763675e-06]\n",
      "f_r: [0.00492571], r: [119.60724], f: [1.9843359e-10]\n",
      "f_r: [-0.00389692], r: [119.7426], f: [267.11807]\n",
      "f_r: [-0.00393366], r: [119.69716], f: [11.46816]\n",
      "f_r: [-0.00714828], r: [119.22937], f: [39.6621]\n",
      "f_r: [-0.0062702], r: [119.18731], f: [4.115265e-06]\n",
      "f_r: [0.00398068], r: [119.99982], f: [6.4753145e-13]\n",
      "f_r: [0.00405147], r: [119.168884], f: [2.3449342e-10]\n",
      "f_r: [0.01276095], r: [119.715195], f: [8.767865e-05]\n",
      "f_r: [-0.00443317], r: [119.803604], f: [8.714254e-09]\n",
      "f_r: [0.00977349], r: [119.071884], f: [0.00055263]\n",
      "f_r: [0.00150628], r: [119.54202], f: [1.8128492e-12]\n",
      "f_r: [0.00102655], r: [119.3099], f: [158.01648]\n",
      "f_r: [0.00012497], r: [119.26962], f: [2.987568]\n",
      "f_r: [0.0023101], r: [119.20504], f: [0.00028282]\n",
      "f_r: [-0.00244951], r: [119.508736], f: [2.7821857e-12]\n",
      "f_r: [-0.0009254], r: [119.50462], f: [3.0487742]\n",
      "f_r: [-0.00242886], r: [119.85662], f: [1.5855122e-14]\n",
      "f_r: [-0.00385728], r: [119.37158], f: [6.5751822e-12]\n",
      "f_r: [-0.00096801], r: [119.33584], f: [3.5682075]\n",
      "f_r: [-0.00606175], r: [119.998215], f: [3.2489461e-07]\n",
      "f_r: [0.01667713], r: [119.81182], f: [0.00024249]\n",
      "f_r: [-1.8567302e-05], r: [119.33357], f: [4.2872663]\n",
      "f_r: [-0.00261515], r: [119.82919], f: [2.2744248]\n",
      "Training loss for epoch 39: pinn: 0.2533, boundary: 28.6800, total: 28.9334\n",
      "f_r: [-0.0047046], r: [119.444016], f: [3.5850974e-06]\n",
      "f_r: [0.00047664], r: [119.61112], f: [5.9075646]\n",
      "f_r: [-0.01602955], r: [119.71132], f: [8.06954e-06]\n",
      "f_r: [-0.00986184], r: [119.94924], f: [2.197995e-05]\n",
      "f_r: [-0.00154528], r: [119.98517], f: [4.846973e-14]\n",
      "f_r: [-0.0027954], r: [119.56482], f: [9.329704e-05]\n",
      "f_r: [-0.00506076], r: [119.60656], f: [0.00144931]\n",
      "f_r: [0.00246378], r: [119.62778], f: [243.12762]\n",
      "f_r: [0.01984799], r: [119.623436], f: [0.33836666]\n",
      "f_r: [0.01888106], r: [119.48571], f: [3.461846e-08]\n",
      "f_r: [0.01693477], r: [119.27077], f: [2.3512067e-08]\n",
      "f_r: [0.01603984], r: [119.59949], f: [2.225963e-08]\n",
      "f_r: [0.00641814], r: [119.52081], f: [1.0427245e-09]\n",
      "f_r: [0.00153216], r: [119.241875], f: [7.0697446]\n",
      "f_r: [-0.00045951], r: [119.86394], f: [4.3044315e-06]\n",
      "f_r: [-8.933231e-05], r: [119.98425], f: [0.642535]\n",
      "f_r: [-0.00164568], r: [119.97395], f: [0.013709]\n",
      "f_r: [-0.00424255], r: [119.08164], f: [0.23553872]\n",
      "f_r: [-0.0212588], r: [119.78166], f: [1.1139607e-07]\n",
      "f_r: [-0.01172851], r: [119.05053], f: [3.5000577e-14]\n",
      "f_r: [-0.03336576], r: [119.24619], f: [1.3995387e-09]\n",
      "f_r: [-0.00774075], r: [119.89732], f: [5.0362916]\n",
      "f_r: [-0.02858006], r: [119.62914], f: [2.6134524e-08]\n",
      "f_r: [-0.00156321], r: [119.46314], f: [31.490068]\n",
      "f_r: [-0.01037228], r: [119.09755], f: [8.349286e-06]\n",
      "f_r: [-0.03184392], r: [119.87834], f: [4.200593e-09]\n",
      "f_r: [-0.00560819], r: [119.48571], f: [0.16817541]\n",
      "f_r: [-0.00015719], r: [119.2196], f: [7.637915e-08]\n",
      "f_r: [0.00304749], r: [119.03782], f: [518.3481]\n",
      "f_r: [0.00661899], r: [119.625496], f: [5.5698583e-14]\n",
      "f_r: [-0.01016337], r: [119.56504], f: [9.296303e-10]\n",
      "f_r: [0.00365342], r: [119.61386], f: [6.3441082e-15]\n",
      "f_r: [0.00719144], r: [119.66407], f: [2.7849945e-12]\n",
      "f_r: [0.01041743], r: [119.32219], f: [0.29849416]\n",
      "f_r: [0.01200635], r: [119.98014], f: [6.656335e-11]\n",
      "f_r: [0.00449234], r: [119.848854], f: [7.178078e-14]\n",
      "f_r: [0.00106726], r: [119.1939], f: [5.014766]\n",
      "f_r: [-0.00593119], r: [119.43125], f: [2.5801263]\n",
      "f_r: [-0.0078799], r: [119.02238], f: [0.0032467]\n",
      "f_r: [-0.00301182], r: [119.47819], f: [5.050064]\n",
      "Training loss for epoch 40: pinn: 0.3387, boundary: 26.5729, total: 26.9115\n",
      "f_r: [-0.00321119], r: [119.72136], f: [137.89081]\n",
      "f_r: [-0.01974239], r: [119.2487], f: [0.00650035]\n",
      "f_r: [-0.01256118], r: [119.32195], f: [1.5856197e-12]\n",
      "f_r: [0.00432257], r: [119.064156], f: [12.591442]\n",
      "f_r: [-0.00284002], r: [119.471115], f: [110.09551]\n",
      "f_r: [0.01526802], r: [119.31491], f: [1.3462854e-07]\n",
      "f_r: [0.03949768], r: [119.88223], f: [0.00034871]\n",
      "f_r: [0.01454688], r: [119.86485], f: [7.955432e-14]\n",
      "f_r: [-0.00240664], r: [119.90738], f: [0.00046799]\n",
      "f_r: [-0.02537655], r: [119.654015], f: [2.698267e-10]\n",
      "f_r: [0.00055905], r: [119.49938], f: [2.7887204e-12]\n",
      "f_r: [0.00311892], r: [119.05916], f: [4.4776522e-13]\n",
      "f_r: [0.00221255], r: [119.26212], f: [8.222015e-15]\n",
      "f_r: [-0.00058641], r: [119.96252], f: [3.6015904e-12]\n",
      "f_r: [-0.01034471], r: [119.213455], f: [1.1592438e-06]\n",
      "f_r: [-0.01461748], r: [119.33812], f: [0.00503861]\n",
      "f_r: [0.00117579], r: [119.36862], f: [200.25252]\n",
      "f_r: [-0.00020945], r: [119.12753], f: [1.3734319e-05]\n",
      "f_r: [-0.00350325], r: [119.479324], f: [0.00149619]\n",
      "f_r: [-0.01784923], r: [119.4062], f: [1.5170952e-08]\n",
      "f_r: [0.00905561], r: [119.26689], f: [4.8570193e-12]\n",
      "f_r: [0.00563698], r: [119.37523], f: [1.1099637e-13]\n",
      "f_r: [0.00124919], r: [119.23324], f: [6.356168e-16]\n",
      "f_r: [-0.00153724], r: [119.795135], f: [3.474171]\n",
      "f_r: [-0.00023249], r: [119.745575], f: [9.139635]\n",
      "f_r: [0.00491143], r: [119.70949], f: [0.00449755]\n",
      "f_r: [0.00708453], r: [119.00626], f: [2.3901341e-11]\n",
      "f_r: [-0.00308032], r: [119.607475], f: [0.02728588]\n",
      "f_r: [-0.0026104], r: [119.17708], f: [2.0380492e-06]\n",
      "f_r: [-0.00095951], r: [119.350876], f: [209.85823]\n",
      "f_r: [-0.00683678], r: [119.938034], f: [8.555281]\n",
      "f_r: [0.00252522], r: [119.66064], f: [2.8704182e-13]\n",
      "f_r: [-0.00017459], r: [119.65562], f: [2.480294e-14]\n",
      "f_r: [-0.00191223], r: [119.933464], f: [116.461494]\n",
      "f_r: [-0.00834948], r: [119.55046], f: [4.3671008e-07]\n",
      "f_r: [0.00133648], r: [119.89434], f: [281.56122]\n",
      "f_r: [-0.00367911], r: [119.45495], f: [12.473953]\n",
      "f_r: [0.00567476], r: [119.24369], f: [19.642862]\n",
      "f_r: [0.00496854], r: [119.13684], f: [0.3999889]\n",
      "f_r: [-0.00085925], r: [119.55432], f: [0.01699844]\n",
      "Training loss for epoch 41: pinn: 0.3142, boundary: 28.6750, total: 28.9892\n",
      "f_r: [0.02047481], r: [119.87606], f: [8.9342644e-11]\n",
      "f_r: [-0.02113028], r: [119.14502], f: [8.976915e-15]\n",
      "f_r: [0.00474424], r: [119.92546], f: [4.10493e-09]\n",
      "f_r: [0.01398564], r: [119.122986], f: [0.05366968]\n",
      "f_r: [0.00602829], r: [119.57326], f: [4532.955]\n",
      "f_r: [0.00728873], r: [119.839935], f: [0.00364146]\n",
      "f_r: [0.00380963], r: [119.518074], f: [332.76752]\n",
      "f_r: [1.943408e-05], r: [119.14139], f: [3.053286e-06]\n",
      "f_r: [0.0053338], r: [119.03487], f: [3.2859577e-13]\n",
      "f_r: [-0.02550735], r: [119.02692], f: [2.5301838e-10]\n",
      "f_r: [-0.00185555], r: [119.4144], f: [8.399668e-09]\n",
      "f_r: [-0.01075861], r: [119.10571], f: [4.248554]\n",
      "f_r: [0.00592536], r: [119.21891], f: [9.2132844e-14]\n",
      "f_r: [0.00216598], r: [119.771385], f: [3.126608e-06]\n",
      "f_r: [-0.00151401], r: [119.37135], f: [0.00276235]\n",
      "f_r: [-0.00035893], r: [119.819595], f: [5.7479907e-14]\n",
      "f_r: [0.00223177], r: [119.291466], f: [8.362799]\n",
      "f_r: [-0.00248799], r: [119.48275], f: [3.1695052e-12]\n",
      "f_r: [0.00107061], r: [119.34062], f: [375.90933]\n",
      "f_r: [0.00556628], r: [119.24642], f: [0.00016661]\n",
      "f_r: [0.00230678], r: [119.288284], f: [1.7461137e-14]\n",
      "f_r: [0.00466705], r: [119.15162], f: [1.4419811e-12]\n",
      "f_r: [-0.0055508], r: [119.65607], f: [5.163217]\n",
      "f_r: [0.01874916], r: [119.903275], f: [2.2447058e-08]\n",
      "f_r: [0.00038018], r: [119.40233], f: [6.1970794e-14]\n",
      "f_r: [0.00272845], r: [119.05689], f: [1.5637897e-13]\n",
      "f_r: [0.00537634], r: [119.84542], f: [3.9962274e-12]\n",
      "f_r: [0.00037583], r: [119.49802], f: [5.884224e-06]\n",
      "f_r: [-0.00651538], r: [119.05326], f: [0.0004139]\n",
      "f_r: [0.03871981], r: [119.6328], f: [8.070753e-12]\n",
      "f_r: [0.00991791], r: [119.72297], f: [8.4605526e-05]\n",
      "f_r: [0.00798526], r: [119.84268], f: [8.043142e-15]\n",
      "f_r: [-0.00345916], r: [119.536316], f: [108.05785]\n",
      "f_r: [-7.686955e-05], r: [119.40961], f: [2.9047441]\n",
      "f_r: [-0.0002007], r: [119.20118], f: [472.0347]\n",
      "f_r: [0.02203757], r: [119.29055], f: [1.3464602e-05]\n",
      "f_r: [-0.0175485], r: [119.991585], f: [1.2405726e-10]\n",
      "f_r: [-0.0020784], r: [119.92363], f: [3.4814733e-15]\n",
      "f_r: [-0.02050167], r: [119.759735], f: [9.2172533e-11]\n",
      "f_r: [-4.6543584e-05], r: [119.86188], f: [314.8971]\n",
      "Training loss for epoch 42: pinn: 0.2812, boundary: 34.1843, total: 34.4655\n",
      "f_r: [-0.00218659], r: [119.33471], f: [0.05170938]\n",
      "f_r: [-0.00497325], r: [119.939415], f: [5.0518693e-08]\n",
      "f_r: [0.00081677], r: [119.86942], f: [7.779213e-10]\n",
      "f_r: [-0.00399164], r: [119.24346], f: [11.70657]\n",
      "f_r: [0.00392102], r: [119.84383], f: [13.399418]\n",
      "f_r: [-0.04504], r: [119.16434], f: [7.546746e-11]\n",
      "f_r: [0.0009451], r: [119.50895], f: [6.490671]\n",
      "f_r: [0.00275779], r: [119.82736], f: [3.127782e-14]\n",
      "f_r: [0.00400339], r: [119.62482], f: [5.2587802e-05]\n",
      "f_r: [0.00621169], r: [119.304886], f: [22.977135]\n",
      "f_r: [0.04142524], r: [119.21095], f: [2.3237696e-12]\n",
      "f_r: [-0.00184464], r: [119.88772], f: [6.6020375e-12]\n",
      "f_r: [-0.0008809], r: [119.32605], f: [0.04674713]\n",
      "f_r: [-0.00077634], r: [119.87628], f: [149.0941]\n",
      "f_r: [-0.00470402], r: [119.304886], f: [0.00020304]\n",
      "f_r: [0.00306433], r: [119.11367], f: [124.592384]\n",
      "f_r: [0.00312091], r: [119.2164], f: [15.291087]\n",
      "f_r: [0.00613366], r: [119.89413], f: [101.48855]\n",
      "f_r: [0.00418612], r: [119.73051], f: [0.01460413]\n",
      "f_r: [0.00883681], r: [119.24529], f: [4.5886014e-14]\n",
      "f_r: [-0.00186874], r: [119.60587], f: [0.26112697]\n",
      "f_r: [-0.01393981], r: [119.59606], f: [2.1182242e-11]\n",
      "f_r: [0.00821646], r: [119.7819], f: [4.090991e-14]\n",
      "f_r: [0.00414168], r: [119.7063], f: [5.275836e-08]\n",
      "f_r: [-0.00053772], r: [119.19548], f: [0.0473466]\n",
      "f_r: [-0.00950733], r: [119.06165], f: [3.5641893e-12]\n",
      "f_r: [0.01278352], r: [119.71771], f: [8.759662e-06]\n",
      "f_r: [0.00414482], r: [119.051895], f: [81.88789]\n",
      "f_r: [-0.01270541], r: [119.83627], f: [193.67554]\n",
      "f_r: [-0.00257818], r: [119.641235], f: [0.06911226]\n",
      "f_r: [-0.01388671], r: [119.49848], f: [1.589883e-09]\n",
      "f_r: [-0.00947179], r: [119.17661], f: [258.83]\n",
      "f_r: [0.00652108], r: [119.79994], f: [20.893015]\n",
      "f_r: [0.01178138], r: [119.80954], f: [2.6123157e-12]\n",
      "f_r: [0.02458544], r: [119.67525], f: [4.919797e-06]\n",
      "f_r: [-0.00741694], r: [119.98929], f: [1.259194e-09]\n",
      "f_r: [0.00535024], r: [119.73461], f: [18.499031]\n",
      "f_r: [-0.00115969], r: [119.36293], f: [8.580168e-05]\n",
      "f_r: [0.01818603], r: [119.0201], f: [1.4327176e-12]\n",
      "f_r: [-0.01723646], r: [119.40916], f: [3.139719e-10]\n",
      "Training loss for epoch 43: pinn: 0.3236, boundary: 26.6388, total: 26.9624\n",
      "f_r: [-0.00111851], r: [119.10867], f: [9.8740664e-14]\n",
      "f_r: [0.01477083], r: [119.213684], f: [391.31763]\n",
      "f_r: [-0.007878], r: [119.42965], f: [1.0088521e-09]\n",
      "f_r: [-0.00782449], r: [119.34471], f: [1.6376954e-11]\n",
      "f_r: [-0.00240355], r: [119.35429], f: [9.153743]\n",
      "f_r: [-0.01226361], r: [119.49757], f: [1.2675758e-15]\n",
      "f_r: [-0.0092112], r: [119.13003], f: [4.3901537e-06]\n",
      "f_r: [0.00458817], r: [119.4946], f: [5.125297e-06]\n",
      "f_r: [-0.02456881], r: [119.0687], f: [3.9712084e-11]\n",
      "f_r: [0.02669455], r: [119.14617], f: [5.285697e-08]\n",
      "f_r: [-0.00095355], r: [119.33153], f: [483.54077]\n",
      "f_r: [-0.00979733], r: [119.15389], f: [11.275121]\n",
      "f_r: [-0.00169846], r: [119.62961], f: [9.656843e-13]\n",
      "f_r: [0.00110538], r: [119.57258], f: [2.3762516e-15]\n",
      "f_r: [-0.0026842], r: [119.327194], f: [16.10069]\n",
      "f_r: [0.01093522], r: [119.63416], f: [3.5236265e-08]\n",
      "f_r: [0.00935661], r: [119.96983], f: [2.7531987e-05]\n",
      "f_r: [0.0133047], r: [119.73096], f: [2.3234817e-12]\n",
      "f_r: [-0.00019437], r: [119.97053], f: [0.00414161]\n",
      "f_r: [0.00389675], r: [119.193665], f: [2.0210734e-07]\n",
      "f_r: [-0.00018639], r: [119.82783], f: [59.216267]\n",
      "f_r: [0.02396627], r: [119.33174], f: [7.372506e-06]\n",
      "f_r: [0.00542458], r: [119.31581], f: [3.7344344e-15]\n",
      "f_r: [0.00324958], r: [119.65698], f: [0.0022083]\n",
      "f_r: [0.00279048], r: [119.69397], f: [3.1773905e-13]\n",
      "f_r: [-0.00367281], r: [119.72548], f: [8.92076e-15]\n",
      "f_r: [-0.00069193], r: [119.258934], f: [2.7457035]\n",
      "f_r: [-0.00309009], r: [119.45221], f: [4.8208345e-14]\n",
      "f_r: [0.00043208], r: [119.64147], f: [1.485814e-13]\n",
      "f_r: [-0.00214978], r: [119.87079], f: [11.911008]\n",
      "f_r: [0.00195596], r: [119.014656], f: [0.07281714]\n",
      "f_r: [-0.00651758], r: [119.29352], f: [28.663858]\n",
      "f_r: [-0.00528845], r: [119.16231], f: [0.00817647]\n",
      "f_r: [0.00685934], r: [119.2396], f: [17.773586]\n",
      "f_r: [0.00599454], r: [119.30376], f: [108.13115]\n",
      "f_r: [-0.00146026], r: [119.57258], f: [2.2717695e-14]\n",
      "f_r: [-0.01264858], r: [119.018974], f: [1.3625576e-09]\n",
      "f_r: [0.01779682], r: [119.46793], f: [1.482732e-08]\n",
      "f_r: [0.00307722], r: [119.088905], f: [47.04219]\n",
      "f_r: [0.00720316], r: [119.96709], f: [19.633442]\n",
      "Training loss for epoch 44: pinn: 0.3037, boundary: 23.7025, total: 24.0062\n",
      "f_r: [-0.02073885], r: [119.99845], f: [8.690377e-11]\n",
      "f_r: [-0.02081811], r: [119.57827], f: [7.7400574e-16]\n",
      "f_r: [0.00718952], r: [119.615], f: [364.92194]\n",
      "f_r: [-0.00333194], r: [119.226875], f: [6.150966e-10]\n",
      "f_r: [-0.00315879], r: [119.34951], f: [4.376778]\n",
      "f_r: [-0.0051647], r: [119.89115], f: [155.30006]\n",
      "f_r: [0.0037317], r: [119.412575], f: [6.6529054e-08]\n",
      "f_r: [-0.00589507], r: [119.13663], f: [1.3354622e-05]\n",
      "f_r: [0.01549326], r: [119.1939], f: [8.59868e-09]\n",
      "f_r: [-0.00204926], r: [119.28033], f: [2.894889e-14]\n",
      "f_r: [-0.00567878], r: [119.25712], f: [0.00541896]\n",
      "f_r: [-0.00396788], r: [119.13663], f: [0.01344103]\n",
      "f_r: [0.00234633], r: [119.79331], f: [8.3015615e-15]\n",
      "f_r: [-0.00104632], r: [119.92659], f: [0.6107068]\n",
      "f_r: [0.02241357], r: [119.47819], f: [5.924734e-13]\n",
      "f_r: [-0.01303472], r: [119.467476], f: [1.5974288e-11]\n",
      "f_r: [-0.01059462], r: [119.75744], f: [3.8413722e-10]\n",
      "f_r: [0.00553805], r: [119.34678], f: [2.123875e-08]\n",
      "f_r: [0.00132924], r: [119.61249], f: [0.03175135]\n",
      "f_r: [0.00050304], r: [119.03009], f: [2.3524249]\n",
      "f_r: [0.0045527], r: [119.806564], f: [1.9845335e-13]\n",
      "f_r: [-0.00141132], r: [119.28419], f: [254.1218]\n",
      "f_r: [-0.01031987], r: [119.39368], f: [1.0885575e-09]\n",
      "f_r: [0.00114384], r: [119.92797], f: [20.169342]\n",
      "f_r: [0.00067764], r: [119.53836], f: [4.157582e-09]\n",
      "f_r: [0.00230701], r: [119.45152], f: [33.96738]\n",
      "f_r: [-5.1410943e-06], r: [119.759056], f: [638.40686]\n",
      "f_r: [0.00778801], r: [119.70264], f: [2.65451e-06]\n",
      "f_r: [0.00090015], r: [119.890465], f: [5.3201873e-08]\n",
      "f_r: [-0.00750904], r: [119.492325], f: [0.8309241]\n",
      "f_r: [-0.00144521], r: [119.25825], f: [0.01245873]\n",
      "f_r: [0.00078559], r: [119.90304], f: [251.98543]\n",
      "f_r: [0.00072865], r: [119.85159], f: [452.90033]\n",
      "f_r: [0.00837585], r: [119.869194], f: [2.244267e-06]\n",
      "f_r: [0.04486551], r: [119.76476], f: [6.407529e-07]\n",
      "f_r: [0.03289389], r: [119.14299], f: [2.354613e-08]\n",
      "f_r: [0.00289473], r: [119.11481], f: [2.6102076]\n",
      "f_r: [-0.00319479], r: [119.45221], f: [0.24231732]\n",
      "f_r: [0.00154391], r: [119.022606], f: [0.03569485]\n",
      "f_r: [0.00048259], r: [119.97236], f: [1.5151615e-14]\n",
      "Training loss for epoch 45: pinn: 0.2644, boundary: 14.0569, total: 14.3214\n",
      "f_r: [0.0013122], r: [119.63074], f: [377.87073]\n",
      "f_r: [-0.0017459], r: [119.61706], f: [18.480204]\n",
      "f_r: [-0.00728812], r: [119.962746], f: [5.834137]\n",
      "f_r: [0.00603087], r: [119.25598], f: [4.234947e-15]\n",
      "f_r: [-0.01235063], r: [119.10186], f: [1.2848459e-06]\n",
      "f_r: [-0.0053571], r: [119.252335], f: [4.640693e-07]\n",
      "f_r: [-0.00359], r: [119.72821], f: [1.6183747e-15]\n",
      "f_r: [-0.00551955], r: [119.05916], f: [1.1241893]\n",
      "f_r: [0.00090595], r: [119.74854], f: [5.6204676e-09]\n",
      "f_r: [-0.01246814], r: [119.746025], f: [1.1267037e-09]\n",
      "f_r: [0.02392581], r: [119.977844], f: [1.7978551e-06]\n",
      "f_r: [0.01140606], r: [119.51055], f: [1.4211156e-06]\n",
      "f_r: [-0.00075654], r: [119.02442], f: [0.00077244]\n",
      "f_r: [0.00158221], r: [119.12572], f: [1.0077171e-06]\n",
      "f_r: [0.00042071], r: [119.84862], f: [9.540028e-16]\n",
      "f_r: [0.00567911], r: [119.39504], f: [6.5628967e-14]\n",
      "f_r: [-0.00603274], r: [119.30079], f: [0.01459585]\n",
      "f_r: [-0.01402858], r: [119.95496], f: [1.3097579e-11]\n",
      "f_r: [-0.00702861], r: [119.40666], f: [0.02402177]\n",
      "f_r: [-0.01227947], r: [119.940094], f: [2.067298e-05]\n",
      "f_r: [0.02484757], r: [119.53062], f: [2.0752996e-13]\n",
      "f_r: [-0.00418711], r: [119.35382], f: [0.02568519]\n",
      "f_r: [0.00143148], r: [119.64739], f: [32.74179]\n",
      "f_r: [0.0008359], r: [119.87217], f: [2.1107845]\n",
      "f_r: [0.01123915], r: [119.0939], f: [4.294456e-15]\n",
      "f_r: [-0.00338779], r: [119.11094], f: [51.51666]\n",
      "f_r: [0.0065696], r: [119.61887], f: [2.83133e-06]\n",
      "f_r: [0.00466254], r: [119.60587], f: [0.20699501]\n",
      "f_r: [0.03606116], r: [119.46406], f: [3.62055e-13]\n",
      "f_r: [0.05965033], r: [119.72525], f: [2.4842376e-07]\n",
      "f_r: [0.01518231], r: [119.68986], f: [7.973975e-08]\n",
      "f_r: [-0.00093785], r: [119.52126], f: [0.14437976]\n",
      "f_r: [0.00764591], r: [119.51602], f: [5.7280545e-07]\n",
      "f_r: [-0.00415433], r: [119.33926], f: [7.78801]\n",
      "f_r: [-0.00548035], r: [119.54407], f: [1.892398e-06]\n",
      "f_r: [0.01741667], r: [119.78624], f: [3.2811416e-13]\n",
      "f_r: [0.01789181], r: [119.526276], f: [1.6900355e-08]\n",
      "f_r: [0.00142417], r: [119.160706], f: [2.5041866e-13]\n",
      "f_r: [0.00419944], r: [119.925224], f: [2.4988077e-07]\n",
      "f_r: [0.00312551], r: [119.79354], f: [73.324844]\n",
      "Training loss for epoch 46: pinn: 0.3423, boundary: 25.8228, total: 26.1651\n",
      "f_r: [-0.0202027], r: [119.391846], f: [6.570647e-11]\n",
      "f_r: [-0.04015594], r: [119.26826], f: [4.904166e-13]\n",
      "f_r: [-0.00950453], r: [119.182076], f: [7.254745e-10]\n",
      "f_r: [-0.00119729], r: [119.86417], f: [3.5590295e-14]\n",
      "f_r: [0.00591559], r: [119.64467], f: [8468.126]\n",
      "f_r: [0.00820114], r: [119.75242], f: [0.1093052]\n",
      "f_r: [0.01156942], r: [119.53471], f: [1.0954881e-11]\n",
      "f_r: [0.0223328], r: [119.87377], f: [1.082958e-12]\n",
      "f_r: [-0.00675776], r: [119.213455], f: [0.00360925]\n",
      "f_r: [0.00273787], r: [119.70219], f: [1.2585184e-14]\n",
      "f_r: [0.0037011], r: [119.55707], f: [4.9879314e-15]\n",
      "f_r: [-0.01631388], r: [119.22641], f: [2.3379574e-11]\n",
      "f_r: [0.00547208], r: [119.48593], f: [3.811678e-12]\n",
      "f_r: [0.01460462], r: [119.48252], f: [6.6713094e-14]\n",
      "f_r: [-9.7689786e-05], r: [119.0787], f: [81.59537]\n",
      "f_r: [0.00231749], r: [119.86805], f: [201.41365]\n",
      "f_r: [0.00522969], r: [119.79926], f: [4.201782e-15]\n",
      "f_r: [0.00107715], r: [119.07733], f: [7.6871255e-15]\n",
      "f_r: [-0.00107383], r: [119.58694], f: [2.4444539e-15]\n",
      "f_r: [0.0007089], r: [119.7136], f: [48.87727]\n",
      "f_r: [-0.00807263], r: [119.680275], f: [5.7765767e-05]\n",
      "f_r: [-0.00082183], r: [119.391396], f: [2.7395163e-07]\n",
      "f_r: [0.00057379], r: [119.05031], f: [19.072521]\n",
      "f_r: [-0.00226966], r: [119.43398], f: [0.00118389]\n",
      "f_r: [-0.01411777], r: [119.68643], f: [1.9271624e-06]\n",
      "f_r: [0.03535299], r: [119.04645], f: [3.264253e-08]\n",
      "f_r: [-0.00408944], r: [119.58739], f: [0.01534519]\n",
      "f_r: [-0.00074245], r: [119.77526], f: [0.08600074]\n",
      "f_r: [0.00685871], r: [119.97144], f: [2.057094e-15]\n",
      "f_r: [0.0078348], r: [119.08754], f: [1.858529e-15]\n",
      "f_r: [0.00806857], r: [119.47203], f: [1.3527838e-14]\n",
      "f_r: [0.00168628], r: [119.31331], f: [5.9625203e-05]\n",
      "f_r: [0.00784441], r: [119.888855], f: [0.10736647]\n",
      "f_r: [-0.00416427], r: [119.444916], f: [22.204544]\n",
      "f_r: [0.00327163], r: [119.37113], f: [12.869665]\n",
      "f_r: [0.02073399], r: [119.2967], f: [3.525298e-13]\n",
      "f_r: [-0.00322249], r: [119.66407], f: [5.912981]\n",
      "f_r: [-0.00916359], r: [119.60336], f: [2.8745939e-05]\n",
      "f_r: [-0.00282283], r: [119.404144], f: [0.00599606]\n",
      "f_r: [-0.02217304], r: [119.22619], f: [5.851216e-07]\n",
      "Training loss for epoch 47: pinn: 0.3307, boundary: 29.4558, total: 29.7865\n",
      "f_r: [-0.01315099], r: [119.61979], f: [3.742686e-05]\n",
      "f_r: [0.0005519], r: [119.82851], f: [3.631757e-08]\n",
      "f_r: [-0.00440401], r: [119.84839], f: [6.11396e-09]\n",
      "f_r: [-4.98063e-05], r: [119.89115], f: [0.6710021]\n",
      "f_r: [0.00309862], r: [119.51078], f: [3.18349e-15]\n",
      "f_r: [-0.00841534], r: [119.07028], f: [0.00060963]\n",
      "f_r: [0.00127711], r: [119.65014], f: [1.763284]\n",
      "f_r: [-0.01667908], r: [119.34154], f: [8.755948e-07]\n",
      "f_r: [0.03738543], r: [119.771835], f: [9.514168e-09]\n",
      "f_r: [0.00520355], r: [119.193665], f: [0.01696434]\n",
      "f_r: [-0.00191467], r: [119.20504], f: [3.2508073e-08]\n",
      "f_r: [-0.01724704], r: [119.520584], f: [1.2816169e-07]\n",
      "f_r: [-0.00814359], r: [119.51033], f: [3.2793876e-05]\n",
      "f_r: [-0.01055156], r: [119.37431], f: [1.3036275e-10]\n",
      "f_r: [0.00922002], r: [119.348145], f: [4.244716e-15]\n",
      "f_r: [-0.00775321], r: [119.53791], f: [1.8207121e-08]\n",
      "f_r: [-0.00046047], r: [119.05553], f: [1.0555035]\n",
      "f_r: [0.00978801], r: [119.98699], f: [2.3190087e-13]\n",
      "f_r: [-0.01209355], r: [119.7988], f: [7.0866485e-10]\n",
      "f_r: [0.0052757], r: [119.53563], f: [1.242495e-07]\n",
      "f_r: [0.00335685], r: [119.55091], f: [1.4704256e-14]\n",
      "f_r: [0.0033742], r: [119.53107], f: [0.00023175]\n",
      "f_r: [-0.00644567], r: [119.178215], f: [1.4138352e-11]\n",
      "f_r: [0.00846768], r: [119.57098], f: [0.00038634]\n",
      "f_r: [0.01712402], r: [119.43148], f: [3.8606032e-13]\n",
      "f_r: [0.00300605], r: [119.582146], f: [1.1966515e-15]\n",
      "f_r: [0.00965766], r: [119.7924], f: [0.01304351]\n",
      "f_r: [0.0213275], r: [119.534035], f: [1.1869893e-13]\n",
      "f_r: [0.00035102], r: [119.574394], f: [1.3673591e-08]\n",
      "f_r: [0.0033469], r: [119.93095], f: [7.576927e-05]\n",
      "f_r: [-0.00400692], r: [119.66155], f: [1.6301314e-08]\n",
      "f_r: [-0.005234], r: [119.20799], f: [4.836889e-10]\n",
      "f_r: [-0.00272325], r: [119.2155], f: [2.42097e-12]\n",
      "f_r: [-0.00640529], r: [119.01193], f: [5.290364e-09]\n",
      "f_r: [-0.00368563], r: [119.10481], f: [7.756047e-16]\n",
      "f_r: [0.00555299], r: [119.130264], f: [0.10552459]\n",
      "f_r: [-0.00222942], r: [119.3445], f: [2.083309]\n",
      "f_r: [3.2910808e-05], r: [119.24619], f: [0.655204]\n",
      "f_r: [-0.00961061], r: [119.94696], f: [1.7532023e-10]\n",
      "f_r: [-0.01028448], r: [119.568695], f: [4.461624e-06]\n",
      "Training loss for epoch 48: pinn: 0.2381, boundary: 18.4579, total: 18.6960\n",
      "f_r: [0.01175373], r: [119.7522], f: [2.1042824e-06]\n",
      "f_r: [-0.02418344], r: [119.64101], f: [1.366319e-06]\n",
      "f_r: [-0.00288225], r: [119.45928], f: [2.5738034]\n",
      "f_r: [-0.0090591], r: [119.07915], f: [0.71155715]\n",
      "f_r: [0.01059594], r: [119.51101], f: [3.6054997e-09]\n",
      "f_r: [0.00584215], r: [119.31286], f: [2.0694091e-10]\n",
      "f_r: [0.00639602], r: [119.8916], f: [190.05736]\n",
      "f_r: [0.00744783], r: [119.42055], f: [0.00021634]\n",
      "f_r: [0.00782982], r: [119.01261], f: [4.1314354e-15]\n",
      "f_r: [0.00047522], r: [119.79605], f: [25.304012]\n",
      "f_r: [-0.00045995], r: [119.91447], f: [0.56068933]\n",
      "f_r: [0.00120087], r: [119.73232], f: [3.909858e-14]\n",
      "f_r: [0.00712452], r: [119.26985], f: [0.0807616]\n",
      "f_r: [-0.00871354], r: [119.13208], f: [2.8405858e-11]\n",
      "f_r: [0.00406032], r: [119.192764], f: [166.19139]\n",
      "f_r: [-0.00833658], r: [119.60381], f: [4.3021074e-14]\n",
      "f_r: [-0.01811455], r: [119.1648], f: [3.4331872e-13]\n",
      "f_r: [-0.01814664], r: [119.367485], f: [2.6502406e-13]\n",
      "f_r: [-0.00055579], r: [119.34699], f: [0.18716484]\n",
      "f_r: [-0.00155176], r: [119.442635], f: [2.11749e-10]\n",
      "f_r: [1.576487e-05], r: [119.581696], f: [0.76456565]\n",
      "f_r: [-0.0028801], r: [119.75197], f: [18.89591]\n",
      "f_r: [-0.00434181], r: [119.64467], f: [1.6523977e-12]\n",
      "f_r: [0.00218646], r: [119.88062], f: [6.574568]\n",
      "f_r: [-0.00122093], r: [119.67981], f: [1.2979491e-07]\n",
      "f_r: [0.00166599], r: [119.329926], f: [2.3486511e-05]\n",
      "f_r: [0.00205618], r: [119.59333], f: [5.5475062e-11]\n",
      "f_r: [-0.00010087], r: [119.40438], f: [4.2058756e-13]\n",
      "f_r: [-0.00124385], r: [119.255066], f: [1.6059827e-11]\n",
      "f_r: [-0.00040666], r: [119.72365], f: [57.92095]\n",
      "f_r: [-0.00490329], r: [119.545204], f: [9.630821e-12]\n",
      "f_r: [0.00122364], r: [119.52651], f: [0.4923987]\n",
      "f_r: [-0.0024354], r: [119.314445], f: [4.7209554e-12]\n",
      "f_r: [0.00086561], r: [119.80314], f: [0.34380972]\n",
      "f_r: [0.00219707], r: [119.82553], f: [4.1248198]\n",
      "f_r: [8.328888e-05], r: [119.122536], f: [0.20874548]\n",
      "f_r: [-0.00388138], r: [119.0671], f: [2.7305235e-12]\n",
      "f_r: [-0.00438592], r: [119.857765], f: [3.1221766e-12]\n",
      "f_r: [-0.0038199], r: [119.5044], f: [5.683195e-13]\n",
      "f_r: [-0.0004264], r: [119.45768], f: [0.00033235]\n",
      "Training loss for epoch 49: pinn: 0.2554, boundary: 22.5158, total: 22.7712\n",
      "f_r: [0.00023549], r: [119.28624], f: [565.41675]\n",
      "f_r: [-0.0150969], r: [119.20867], f: [1.2813997e-12]\n",
      "f_r: [-0.0066014], r: [119.0276], f: [0.00637851]\n",
      "f_r: [0.00132198], r: [119.67433], f: [4.583579]\n",
      "f_r: [0.00624463], r: [119.821884], f: [3.630648e-12]\n",
      "f_r: [0.00223977], r: [119.28782], f: [1.9852523]\n",
      "f_r: [-0.00031336], r: [119.071884], f: [590.72327]\n",
      "f_r: [0.00177041], r: [119.81274], f: [74.39155]\n",
      "f_r: [-0.00086532], r: [119.62435], f: [1.949524e-06]\n",
      "f_r: [0.00425885], r: [119.58649], f: [0.0166814]\n",
      "f_r: [0.06094794], r: [119.11004], f: [1.2331596e-11]\n",
      "f_r: [0.00542781], r: [119.98334], f: [0.00329746]\n",
      "f_r: [0.00738624], r: [119.21004], f: [0.09913905]\n",
      "f_r: [-0.00189065], r: [119.32515], f: [98.898895]\n",
      "f_r: [-0.00678744], r: [119.92774], f: [2.6766114e-09]\n",
      "f_r: [0.01360044], r: [119.031235], f: [4.6250676e-10]\n",
      "f_r: [-6.92853e-05], r: [119.00513], f: [2.8644662e-14]\n",
      "f_r: [-0.00744246], r: [119.493004], f: [9.523455]\n",
      "f_r: [-0.00219154], r: [119.69625], f: [1.9526719]\n",
      "f_r: [-0.00029667], r: [119.1173], f: [0.36613318]\n",
      "f_r: [-0.00361653], r: [119.103], f: [6.477556e-15]\n",
      "f_r: [0.01289309], r: [119.906235], f: [1.8739858e-10]\n",
      "f_r: [-0.00046866], r: [119.453575], f: [2.3039515e-14]\n",
      "f_r: [0.0056604], r: [119.589905], f: [0.00950406]\n",
      "f_r: [-0.00299616], r: [119.27873], f: [81.24591]\n",
      "f_r: [-0.00548695], r: [119.93506], f: [6.4910923e-06]\n",
      "f_r: [-0.00021746], r: [119.6442], f: [37.696182]\n",
      "f_r: [0.0146139], r: [119.566185], f: [1.0413775e-08]\n",
      "f_r: [0.00255057], r: [119.60153], f: [7.917985e-13]\n",
      "f_r: [0.00480397], r: [119.810455], f: [4.186774e-15]\n",
      "f_r: [0.01588711], r: [119.447426], f: [1.6559063e-08]\n",
      "f_r: [0.00018646], r: [119.83125], f: [4.5541e-14]\n",
      "f_r: [0.02554611], r: [119.707664], f: [3.8441337e-11]\n",
      "f_r: [-0.00010086], r: [119.28168], f: [191.54361]\n",
      "f_r: [-0.0063178], r: [119.10504], f: [1.0742029]\n",
      "f_r: [-0.00159577], r: [119.91836], f: [5.2829093e-14]\n",
      "f_r: [-0.00047625], r: [119.87079], f: [269.1198]\n",
      "f_r: [0.00440105], r: [119.21891], f: [0.00872769]\n",
      "f_r: [-0.00996338], r: [119.736664], f: [5.4476505e-08]\n",
      "f_r: [-0.00938823], r: [119.24346], f: [6.16355e-08]\n",
      "Training loss for epoch 50: pinn: 0.2504, boundary: 22.9511, total: 23.2015\n",
      "f_r: [0.00498989], r: [119.26257], f: [4.8985785e-12]\n",
      "f_r: [0.01610706], r: [119.18844], f: [2.5755456e-09]\n",
      "f_r: [0.00461056], r: [119.35793], f: [804.87555]\n",
      "f_r: [0.00292407], r: [119.78052], f: [0.00363742]\n",
      "f_r: [-0.03406975], r: [119.39504], f: [4.1365475e-10]\n",
      "f_r: [-0.0056189], r: [119.83491], f: [49.14438]\n",
      "f_r: [-0.00723804], r: [119.049164], f: [0.0234201]\n",
      "f_r: [-0.00095884], r: [119.03305], f: [0.00900436]\n",
      "f_r: [0.00634788], r: [119.484116], f: [4.989849e-13]\n",
      "f_r: [0.00650405], r: [119.995926], f: [0.00027757]\n",
      "f_r: [0.00584776], r: [119.44993], f: [3.120839e-05]\n",
      "f_r: [0.00463059], r: [119.08641], f: [405.72855]\n",
      "f_r: [0.00532018], r: [119.35565], f: [0.00415573]\n",
      "f_r: [-0.00262919], r: [119.10163], f: [52.097755]\n",
      "f_r: [-0.01962613], r: [119.40483], f: [1.0062514e-10]\n",
      "f_r: [0.00527338], r: [119.38638], f: [0.00534656]\n",
      "f_r: [0.00771807], r: [119.21482], f: [0.06265055]\n",
      "f_r: [0.0006549], r: [119.87857], f: [502.42322]\n",
      "f_r: [-0.00463438], r: [119.678215], f: [6.7793]\n",
      "f_r: [0.00022809], r: [119.61683], f: [1.9778123]\n",
      "f_r: [-0.00372431], r: [119.86211], f: [0.9985593]\n",
      "f_r: [-0.00107033], r: [119.08301], f: [0.3978257]\n",
      "f_r: [-0.00113499], r: [119.36224], f: [5.0695376e-14]\n",
      "f_r: [-0.00960596], r: [119.75654], f: [1.4434815e-11]\n",
      "f_r: [-0.00415627], r: [119.29601], f: [78.298615]\n",
      "f_r: [-0.00056332], r: [119.74922], f: [1.5682029e-11]\n",
      "f_r: [-0.00611605], r: [119.12753], f: [1.994164e-09]\n",
      "f_r: [0.00364113], r: [119.59994], f: [2.357144e-07]\n",
      "f_r: [0.0424376], r: [119.379326], f: [1.7704527e-12]\n",
      "f_r: [0.00289268], r: [119.275085], f: [8.459154]\n",
      "f_r: [-0.00021021], r: [119.2371], f: [120.61009]\n",
      "f_r: [0.00559544], r: [119.58626], f: [0.0004968]\n",
      "f_r: [-0.0048047], r: [119.848854], f: [19.706352]\n",
      "f_r: [0.00078242], r: [119.08209], f: [279.2381]\n",
      "f_r: [-0.00438304], r: [119.15503], f: [6.817942]\n",
      "f_r: [-0.00063225], r: [119.228455], f: [127.71017]\n",
      "f_r: [0.01083991], r: [119.82257], f: [6.770393e-12]\n",
      "f_r: [-0.00194515], r: [119.752884], f: [0.00024317]\n",
      "f_r: [0.03526018], r: [119.39617], f: [2.7195774e-12]\n",
      "f_r: [0.00139244], r: [119.36634], f: [0.05087992]\n",
      "Training loss for epoch 51: pinn: 0.2844, boundary: 22.8929, total: 23.1773\n",
      "f_r: [-0.01720581], r: [119.91585], f: [1.6128924e-08]\n",
      "f_r: [-0.00352214], r: [119.942375], f: [390.41107]\n",
      "f_r: [-0.00867331], r: [119.42875], f: [34.166267]\n",
      "f_r: [-0.004134], r: [119.54976], f: [6.8387985e-06]\n",
      "f_r: [-0.00906787], r: [119.666115], f: [28.562294]\n",
      "f_r: [-0.00238774], r: [119.868515], f: [3.2403855]\n",
      "f_r: [-0.00571483], r: [119.071884], f: [0.01231939]\n",
      "f_r: [-0.00496508], r: [119.14867], f: [1.4786483]\n",
      "f_r: [0.0079061], r: [119.11912], f: [2.840404e-13]\n",
      "f_r: [0.00673037], r: [119.327194], f: [9.549352e-06]\n",
      "f_r: [0.005884], r: [119.01193], f: [617.5504]\n",
      "f_r: [0.01023796], r: [119.72776], f: [0.732147]\n",
      "f_r: [-0.0039231], r: [119.17548], f: [1.2136732e-07]\n",
      "f_r: [-0.00204632], r: [119.34768], f: [2.1267838e-06]\n",
      "f_r: [-0.00489482], r: [119.52378], f: [2.7815895e-06]\n",
      "f_r: [-0.00450333], r: [119.014656], f: [1.3126862e-15]\n",
      "f_r: [0.00020092], r: [119.95016], f: [0.01337162]\n",
      "f_r: [0.00455963], r: [119.009895], f: [0.0060119]\n",
      "f_r: [-0.00191694], r: [119.16457], f: [6.4775705]\n",
      "f_r: [0.0019099], r: [119.15093], f: [0.3898255]\n",
      "f_r: [-0.01081425], r: [119.0344], f: [8.282608e-09]\n",
      "f_r: [0.00690783], r: [119.53267], f: [0.04012016]\n",
      "f_r: [0.007089], r: [119.47455], f: [0.06014564]\n",
      "f_r: [0.06060297], r: [119.74991], f: [1.8026903e-13]\n",
      "f_r: [-0.0047661], r: [119.348595], f: [2.7425637]\n",
      "f_r: [0.00203191], r: [119.810455], f: [0.00884603]\n",
      "f_r: [-0.01172403], r: [119.262344], f: [2.5703448e-08]\n",
      "f_r: [0.00677955], r: [119.34085], f: [9.850534e-14]\n",
      "f_r: [-0.00940493], r: [119.5582], f: [1.3835338e-10]\n",
      "f_r: [-0.00107227], r: [119.58398], f: [158.9562]\n",
      "f_r: [0.00295942], r: [119.436264], f: [0.00067297]\n",
      "f_r: [0.00200322], r: [119.26689], f: [0.02387703]\n",
      "f_r: [0.00306307], r: [119.74969], f: [0.0001117]\n",
      "f_r: [0.00035931], r: [119.68598], f: [3.5158531e-15]\n",
      "f_r: [0.00748128], r: [119.94856], f: [0.01824085]\n",
      "f_r: [-0.00015928], r: [119.67547], f: [170.19174]\n",
      "f_r: [0.00238412], r: [119.46451], f: [2.9179167e-14]\n",
      "f_r: [0.00504799], r: [119.3281], f: [0.08794309]\n",
      "f_r: [0.02932798], r: [119.672966], f: [4.772667e-13]\n",
      "f_r: [-0.00015859], r: [119.142525], f: [2.4656563e-06]\n",
      "Training loss for epoch 52: pinn: 0.3204, boundary: 28.2594, total: 28.5798\n",
      "f_r: [-0.00634393], r: [119.04553], f: [6.1117964]\n",
      "f_r: [-0.0148012], r: [119.098], f: [4.1027565e-06]\n",
      "f_r: [-0.0219142], r: [119.48593], f: [3.6597922e-09]\n",
      "f_r: [-0.01612928], r: [119.34768], f: [2.4759947e-09]\n",
      "f_r: [0.01588113], r: [119.77687], f: [3.9504652e-10]\n",
      "f_r: [0.01263665], r: [119.336525], f: [0.00022163]\n",
      "f_r: [0.00052872], r: [119.511696], f: [1.5852915]\n",
      "f_r: [0.00694903], r: [119.351776], f: [0.04206188]\n",
      "f_r: [-0.00162906], r: [119.44037], f: [71.17255]\n",
      "f_r: [-0.00040098], r: [119.5053], f: [0.00553842]\n",
      "f_r: [-0.00329797], r: [119.03373], f: [9.6204916e-05]\n",
      "f_r: [0.00248887], r: [119.54566], f: [25.956375]\n",
      "f_r: [-0.00143817], r: [119.91562], f: [5.7709417]\n",
      "f_r: [-0.0109935], r: [119.47363], f: [2.571188e-08]\n",
      "f_r: [0.00334821], r: [119.51922], f: [0.05115122]\n",
      "f_r: [-1.6909455e-05], r: [119.94673], f: [372.2523]\n",
      "f_r: [-0.02201415], r: [119.26985], f: [8.8761964e-10]\n",
      "f_r: [0.00213423], r: [119.79331], f: [1.617638e-14]\n",
      "f_r: [-0.00137009], r: [119.36589], f: [0.00097343]\n",
      "f_r: [0.00150209], r: [119.680275], f: [0.00135022]\n",
      "f_r: [0.00171105], r: [119.21095], f: [0.0563419]\n",
      "f_r: [-0.00146904], r: [119.646034], f: [5.8265136e-11]\n",
      "f_r: [0.0019213], r: [119.762245], f: [1.4119113e-05]\n",
      "f_r: [0.00098868], r: [119.857765], f: [13.370094]\n",
      "f_r: [-0.0024548], r: [119.83491], f: [203.7554]\n",
      "f_r: [-0.0009271], r: [119.168434], f: [0.00011314]\n",
      "f_r: [-0.00053619], r: [119.73598], f: [7.3513497e-16]\n",
      "f_r: [0.00086102], r: [119.47478], f: [1.0725131]\n",
      "f_r: [-0.01125838], r: [119.76568], f: [5.70446e-09]\n",
      "f_r: [0.00441699], r: [119.912636], f: [5.378231e-06]\n",
      "f_r: [-0.00334409], r: [119.15935], f: [4.3078767e-08]\n",
      "f_r: [0.00099376], r: [119.13184], f: [8.386913e-08]\n",
      "f_r: [-0.01479015], r: [119.99937], f: [2.7605072e-09]\n",
      "f_r: [0.00347714], r: [119.2562], f: [22.576956]\n",
      "f_r: [-0.02885034], r: [119.61227], f: [3.257827e-12]\n",
      "f_r: [-0.00077549], r: [119.171165], f: [285.82596]\n",
      "f_r: [0.00297953], r: [119.597435], f: [56.73653]\n",
      "f_r: [0.00675673], r: [119.31035], f: [1.5134315e-14]\n",
      "f_r: [0.00246764], r: [119.935524], f: [9.0256077e-07]\n",
      "f_r: [-0.02612252], r: [119.68894], f: [5.698511e-13]\n",
      "Training loss for epoch 53: pinn: 0.3093, boundary: 19.4066, total: 19.7159\n",
      "f_r: [-0.01247578], r: [119.80269], f: [1.0344598e-13]\n",
      "f_r: [0.00981907], r: [119.65014], f: [0.23363005]\n",
      "f_r: [-0.00410477], r: [119.281], f: [2.2554048e-08]\n",
      "f_r: [-0.01350977], r: [119.50895], f: [2.5631736e-11]\n",
      "f_r: [-0.03120533], r: [119.95496], f: [1.0166719e-12]\n",
      "f_r: [-0.00324576], r: [119.59218], f: [228.4099]\n",
      "f_r: [-0.0048636], r: [119.478874], f: [0.8102695]\n",
      "f_r: [-0.00142803], r: [119.565506], f: [0.25774318]\n",
      "f_r: [0.00735965], r: [119.87628], f: [7.902676e-06]\n",
      "f_r: [-0.0037182], r: [119.526276], f: [3.4753622e-08]\n",
      "f_r: [-0.00196163], r: [119.01306], f: [3.7021978e-13]\n",
      "f_r: [0.00424615], r: [119.06665], f: [0.03678203]\n",
      "f_r: [0.03105062], r: [119.241425], f: [1.8571797e-14]\n",
      "f_r: [0.01134659], r: [119.24006], f: [2.3349027e-07]\n",
      "f_r: [6.5786684e-05], r: [119.19458], f: [0.00050801]\n",
      "f_r: [-0.01123616], r: [119.34154], f: [9.234261e-09]\n",
      "f_r: [0.00108275], r: [119.97464], f: [0.2391165]\n",
      "f_r: [0.02729408], r: [119.77115], f: [3.142828e-14]\n",
      "f_r: [-0.02652582], r: [119.64739], f: [1.0333166e-12]\n",
      "f_r: [-0.02763669], r: [119.96435], f: [3.3449374e-13]\n",
      "f_r: [-0.00228769], r: [119.56345], f: [93.90785]\n",
      "f_r: [0.01763115], r: [119.85365], f: [9.745254e-07]\n",
      "f_r: [-0.02547926], r: [119.58534], f: [7.1836157e-13]\n",
      "f_r: [0.0052726], r: [119.45996], f: [2.5789424e-07]\n",
      "f_r: [-0.01794576], r: [119.76385], f: [7.8400764e-10]\n",
      "f_r: [-0.00490352], r: [119.69442], f: [21.0231]\n",
      "f_r: [0.00228234], r: [119.31331], f: [1.4095351e-11]\n",
      "f_r: [-0.0006258], r: [119.421], f: [4.7053313]\n",
      "f_r: [0.00049046], r: [119.70219], f: [100.12845]\n",
      "f_r: [0.02641615], r: [119.60405], f: [1.4399868e-14]\n",
      "f_r: [9.437099e-05], r: [119.77504], f: [0.01898019]\n",
      "f_r: [-0.00128756], r: [119.81616], f: [5.529301e-05]\n",
      "f_r: [0.00027729], r: [119.760185], f: [0.04691694]\n",
      "f_r: [-0.00315621], r: [119.43172], f: [95.46532]\n",
      "f_r: [-0.00113816], r: [119.26053], f: [310.1999]\n",
      "f_r: [-0.00713323], r: [119.43969], f: [5.5592426e-11]\n",
      "f_r: [0.00116026], r: [119.07438], f: [0.00107491]\n",
      "f_r: [0.0311473], r: [119.27555], f: [1.9760447e-11]\n",
      "f_r: [0.01479844], r: [119.699905], f: [1.1191149e-06]\n",
      "f_r: [0.00053449], r: [119.63212], f: [0.01487712]\n",
      "Training loss for epoch 54: pinn: 0.3081, boundary: 17.6425, total: 17.9506\n",
      "f_r: [-0.01081274], r: [119.506454], f: [4.7710048e-12]\n",
      "f_r: [-0.00961119], r: [119.349724], f: [0.00504218]\n",
      "f_r: [-0.00661465], r: [119.959305], f: [2.0434923]\n",
      "f_r: [-0.0042024], r: [119.49551], f: [7.696822e-08]\n",
      "f_r: [0.00883059], r: [119.82005], f: [4.513394e-06]\n",
      "f_r: [0.00569008], r: [119.71886], f: [23.457432]\n",
      "f_r: [-0.00265933], r: [119.85113], f: [203.67973]\n",
      "f_r: [0.00769146], r: [119.868965], f: [10.168786]\n",
      "f_r: [-0.02935415], r: [119.663605], f: [4.3840504e-13]\n",
      "f_r: [0.0012865], r: [119.27713], f: [1.7903312e-05]\n",
      "f_r: [-0.00016745], r: [119.47182], f: [257.507]\n",
      "f_r: [-0.01205111], r: [119.835594], f: [2.4687514e-09]\n",
      "f_r: [0.0019944], r: [119.85296], f: [0.01927485]\n",
      "f_r: [0.00412388], r: [119.59378], f: [0.01903133]\n",
      "f_r: [0.00822675], r: [119.442635], f: [0.00122878]\n",
      "f_r: [0.00818779], r: [119.3281], f: [1.4456062e-05]\n",
      "f_r: [0.00307376], r: [119.58489], f: [0.29995966]\n",
      "f_r: [-0.00461203], r: [119.51329], f: [9.590545e-09]\n",
      "f_r: [-0.00715456], r: [119.02714], f: [2.5611384e-09]\n",
      "f_r: [-0.00272327], r: [119.04372], f: [11.501851]\n",
      "f_r: [0.00676927], r: [119.87011], f: [0.0045621]\n",
      "f_r: [0.00661414], r: [119.7972], f: [0.04690165]\n",
      "f_r: [0.01059355], r: [119.61728], f: [0.00921241]\n",
      "f_r: [-0.00142225], r: [119.22299], f: [0.7389045]\n",
      "f_r: [0.02176726], r: [119.54588], f: [4.704157e-15]\n",
      "f_r: [-0.00329109], r: [119.96458], f: [16.294262]\n",
      "f_r: [0.02571024], r: [119.43558], f: [5.387532e-12]\n",
      "f_r: [-0.00274728], r: [119.25803], f: [0.09464212]\n",
      "f_r: [-0.00212248], r: [119.977615], f: [4.1776524]\n",
      "f_r: [0.030516], r: [119.291466], f: [1.4593134e-11]\n",
      "f_r: [-0.00451705], r: [119.31832], f: [150.32172]\n",
      "f_r: [-0.0027596], r: [119.44948], f: [87.78714]\n",
      "f_r: [-0.00068072], r: [119.594246], f: [2.2970023]\n",
      "f_r: [-0.00772112], r: [119.523315], f: [1.1342055e-08]\n",
      "f_r: [-0.00618043], r: [119.19572], f: [5.568659e-10]\n",
      "f_r: [-0.00110361], r: [119.67981], f: [1.2039237]\n",
      "f_r: [-0.00687938], r: [119.64147], f: [2.629648e-08]\n",
      "f_r: [-0.00596086], r: [119.64718], f: [6.948382e-08]\n",
      "f_r: [0.00114269], r: [119.484116], f: [0.0001047]\n",
      "f_r: [-0.00389921], r: [119.32287], f: [5.51943e-08]\n",
      "Training loss for epoch 55: pinn: 0.3148, boundary: 20.9493, total: 21.2641\n",
      "f_r: [-0.00349413], r: [119.5703], f: [1.1943239e-07]\n",
      "f_r: [-0.00948181], r: [119.492325], f: [5.9949202e-06]\n",
      "f_r: [-0.0077504], r: [119.28987], f: [2.787071e-09]\n",
      "f_r: [0.01023789], r: [119.637596], f: [2.7629781e-05]\n",
      "f_r: [0.01188416], r: [119.429886], f: [0.0959086]\n",
      "f_r: [0.00065908], r: [119.97395], f: [1.2129689e-12]\n",
      "f_r: [-0.0274468], r: [119.484116], f: [2.3406353e-14]\n",
      "f_r: [0.00392199], r: [119.14912], f: [0.00019623]\n",
      "f_r: [0.00403261], r: [119.50737], f: [0.00127518]\n",
      "f_r: [-0.03340976], r: [119.975105], f: [1.1679027e-13]\n",
      "f_r: [-0.0063418], r: [119.93712], f: [0.23958594]\n",
      "f_r: [-0.0055084], r: [119.75814], f: [8.291191e-07]\n",
      "f_r: [-0.0114688], r: [119.589455], f: [1.3910632e-08]\n",
      "f_r: [-0.00486013], r: [119.35451], f: [0.00762825]\n",
      "f_r: [0.03205367], r: [119.031006], f: [3.702095e-15]\n",
      "f_r: [0.00130387], r: [119.47682], f: [0.03099355]\n",
      "f_r: [0.00123905], r: [119.178215], f: [11.253807]\n",
      "f_r: [0.00259003], r: [119.65425], f: [0.01630791]\n",
      "f_r: [-0.00411815], r: [119.3602], f: [297.62836]\n",
      "f_r: [-0.00158436], r: [119.92157], f: [0.6554433]\n",
      "f_r: [-0.00035879], r: [119.59036], f: [2.6733037e-14]\n",
      "f_r: [-0.00929055], r: [119.00035], f: [5.337282]\n",
      "f_r: [-0.00737579], r: [119.83834], f: [118.64512]\n",
      "f_r: [-0.00218318], r: [119.5427], f: [2.8080638e-08]\n",
      "f_r: [-0.02697076], r: [119.22664], f: [4.0535633e-13]\n",
      "f_r: [0.00202727], r: [119.81593], f: [8.915615]\n",
      "f_r: [-0.00316666], r: [119.85502], f: [7.465627e-11]\n",
      "f_r: [-0.028442], r: [119.690544], f: [4.8525508e-14]\n",
      "f_r: [0.00373066], r: [119.15025], f: [0.00016269]\n",
      "f_r: [0.00352991], r: [119.1748], f: [0.00164276]\n",
      "f_r: [0.00138025], r: [119.053474], f: [0.0085369]\n",
      "f_r: [-0.00288938], r: [119.20867], f: [1.7231999e-09]\n",
      "f_r: [0.00137428], r: [119.83148], f: [6.983993e-11]\n",
      "f_r: [0.00250318], r: [119.14775], f: [30.321733]\n",
      "f_r: [0.00153458], r: [119.76087], f: [0.00761422]\n",
      "f_r: [-0.00313607], r: [119.17343], f: [218.49998]\n",
      "f_r: [0.00159022], r: [119.19708], f: [0.00036345]\n",
      "f_r: [-0.00247349], r: [119.03713], f: [500.2595]\n",
      "f_r: [-0.00030011], r: [119.023506], f: [5.6190976e-12]\n",
      "f_r: [-0.00114985], r: [119.73232], f: [3.3869214]\n",
      "Training loss for epoch 56: pinn: 0.2807, boundary: 11.7529, total: 12.0336\n",
      "f_r: [0.00075436], r: [119.72365], f: [143.42813]\n",
      "f_r: [-0.01200834], r: [119.82576], f: [7.7212986e-13]\n",
      "f_r: [2.5393398e-05], r: [119.670456], f: [9.177984]\n",
      "f_r: [0.00336028], r: [119.71543], f: [0.03003964]\n",
      "f_r: [-0.01278369], r: [119.268036], f: [0.22058533]\n",
      "f_r: [-0.00429626], r: [119.45199], f: [0.00052704]\n",
      "f_r: [0.00031288], r: [119.9918], f: [46.88434]\n",
      "f_r: [-0.00145338], r: [119.76178], f: [3.378163e-09]\n",
      "f_r: [0.00401283], r: [119.13594], f: [0.02424816]\n",
      "f_r: [0.00958022], r: [119.4292], f: [3.5628018e-05]\n",
      "f_r: [0.02671999], r: [119.20936], f: [7.0294167e-15]\n",
      "f_r: [0.00282046], r: [119.412125], f: [9.880041e-06]\n",
      "f_r: [-0.00925172], r: [119.76293], f: [1.1496779e-09]\n",
      "f_r: [-0.004212], r: [119.5785], f: [8.884536e-05]\n",
      "f_r: [-0.00338259], r: [119.439224], f: [177.05658]\n",
      "f_r: [-0.00207446], r: [119.481155], f: [217.42004]\n",
      "f_r: [0.00768839], r: [119.122086], f: [9.72043e-06]\n",
      "f_r: [0.00715925], r: [119.66634], f: [0.05743711]\n",
      "f_r: [0.00881001], r: [119.8317], f: [9.872072e-10]\n",
      "f_r: [0.00253146], r: [119.456085], f: [138.55327]\n",
      "f_r: [0.00593666], r: [119.54452], f: [2.5526561e-10]\n",
      "f_r: [-0.00038941], r: [119.423744], f: [6.9224506e-09]\n",
      "f_r: [-0.00373105], r: [119.681404], f: [0.23198895]\n",
      "f_r: [-0.02009031], r: [119.25643], f: [1.3158719e-12]\n",
      "f_r: [8.272354e-05], r: [119.221634], f: [12.889959]\n",
      "f_r: [-0.00972644], r: [119.03736], f: [5.691605e-12]\n",
      "f_r: [0.00329662], r: [119.98151], f: [2.7424318e-10]\n",
      "f_r: [0.00321533], r: [119.228905], f: [0.00532808]\n",
      "f_r: [-3.7638743e-05], r: [119.855934], f: [1.1317862e-10]\n",
      "f_r: [-0.02306564], r: [119.52902], f: [1.4376201e-12]\n",
      "f_r: [-0.02542005], r: [119.453575], f: [1.8176773e-14]\n",
      "f_r: [-0.0044176], r: [119.42238], f: [5.860829e-12]\n",
      "f_r: [0.02837913], r: [119.34495], f: [3.8512377e-11]\n",
      "f_r: [0.00308928], r: [119.6951], f: [13.544036]\n",
      "f_r: [-0.00122545], r: [119.09845], f: [0.13201044]\n",
      "f_r: [-0.00206408], r: [119.336075], f: [9.2741e-07]\n",
      "f_r: [-0.00178527], r: [119.16094], f: [358.52777]\n",
      "f_r: [-0.02196128], r: [119.41963], f: [6.156954e-13]\n",
      "f_r: [0.00230147], r: [119.66407], f: [1.7027109]\n",
      "f_r: [0.00011653], r: [119.02601], f: [261.27942]\n",
      "Training loss for epoch 57: pinn: 0.2913, boundary: 22.3005, total: 22.5918\n",
      "f_r: [-0.00566039], r: [119.84268], f: [0.38948244]\n",
      "f_r: [-0.01097721], r: [119.61523], f: [2.20688e-12]\n",
      "f_r: [0.01236345], r: [119.856384], f: [0.00037167]\n",
      "f_r: [0.00329117], r: [119.391396], f: [6.8047964e-05]\n",
      "f_r: [-0.00783635], r: [119.71725], f: [65.911316]\n",
      "f_r: [-0.0119591], r: [119.96641], f: [1.5740552e-15]\n",
      "f_r: [-0.00374686], r: [119.26076], f: [4.7880692]\n",
      "f_r: [-0.00262231], r: [119.01784], f: [0.10711928]\n",
      "f_r: [-0.00027902], r: [119.47478], f: [1.369235e-07]\n",
      "f_r: [0.00308829], r: [119.07688], f: [6.704707e-10]\n",
      "f_r: [0.00014494], r: [119.43421], f: [0.00056059]\n",
      "f_r: [-0.00276616], r: [119.097084], f: [1.3469834e-10]\n",
      "f_r: [0.00225775], r: [119.07438], f: [1.4890106]\n",
      "f_r: [0.02380353], r: [119.10163], f: [8.184647e-16]\n",
      "f_r: [0.00109785], r: [119.04327], f: [1.0376316]\n",
      "f_r: [0.00125954], r: [119.73713], f: [71.33862]\n",
      "f_r: [0.00637869], r: [119.79584], f: [2.026157e-05]\n",
      "f_r: [0.00682973], r: [119.91151], f: [9.894095e-07]\n",
      "f_r: [0.01122699], r: [119.72959], f: [0.00089641]\n",
      "f_r: [-0.00090914], r: [119.86119], f: [43.853622]\n",
      "f_r: [0.0074769], r: [119.58374], f: [0.00047062]\n",
      "f_r: [0.00251347], r: [119.03895], f: [2.6550997e-06]\n",
      "f_r: [-0.00325044], r: [119.72387], f: [0.2736638]\n",
      "f_r: [0.00770997], r: [119.27941], f: [0.03707109]\n",
      "f_r: [-0.00126102], r: [119.50668], f: [96.20773]\n",
      "f_r: [-0.00105634], r: [119.55159], f: [91.96632]\n",
      "f_r: [0.00067452], r: [119.85845], f: [0.00035528]\n",
      "f_r: [0.00091357], r: [119.646034], f: [10.636091]\n",
      "f_r: [-0.01589948], r: [119.55707], f: [6.7630126e-15]\n",
      "f_r: [-0.00226091], r: [119.01669], f: [7.3549384e-09]\n",
      "f_r: [-0.00156652], r: [119.08209], f: [4.141156e-07]\n",
      "f_r: [-0.00287724], r: [119.620705], f: [5.1844654]\n",
      "f_r: [-0.00196025], r: [119.3791], f: [8.979646e-06]\n",
      "f_r: [-0.00081804], r: [119.1173], f: [145.53453]\n",
      "f_r: [-0.00402522], r: [119.39982], f: [3.104317e-07]\n",
      "f_r: [0.00188001], r: [119.323555], f: [1.2062068]\n",
      "f_r: [-0.00034234], r: [119.34358], f: [46.210403]\n",
      "f_r: [-0.01960117], r: [119.364296], f: [6.9117097e-13]\n",
      "f_r: [0.00215038], r: [119.18389], f: [0.00019979]\n",
      "f_r: [-0.01693368], r: [119.15207], f: [1.4430533e-13]\n",
      "Training loss for epoch 58: pinn: 0.2995, boundary: 18.9264, total: 19.2259\n",
      "f_r: [0.00586568], r: [119.472496], f: [0.00011564]\n",
      "f_r: [0.00443355], r: [119.26326], f: [247.89665]\n",
      "f_r: [0.00765269], r: [119.02283], f: [0.0040252]\n",
      "f_r: [0.03433061], r: [119.13753], f: [4.984613e-11]\n",
      "f_r: [-0.00510111], r: [119.78052], f: [1.6052772e-05]\n",
      "f_r: [-0.00526158], r: [119.61386], f: [2.2280256e-06]\n",
      "f_r: [-0.00019493], r: [119.64626], f: [3.5651468e-07]\n",
      "f_r: [0.00198174], r: [119.954735], f: [0.1062986]\n",
      "f_r: [0.0011402], r: [119.452675], f: [99.28981]\n",
      "f_r: [-0.00219179], r: [119.61887], f: [0.00152155]\n",
      "f_r: [0.0013846], r: [119.455635], f: [165.33292]\n",
      "f_r: [5.647972e-05], r: [119.27737], f: [8.680232e-05]\n",
      "f_r: [8.4909385e-05], r: [119.41304], f: [2.1651006e-11]\n",
      "f_r: [-0.00119174], r: [119.06075], f: [1.935778e-11]\n",
      "f_r: [-0.00226804], r: [119.45837], f: [46.893482]\n",
      "f_r: [-0.00012014], r: [119.1473], f: [5.5344367e-06]\n",
      "f_r: [0.00818689], r: [119.157295], f: [1.1341047e-14]\n",
      "f_r: [0.00121578], r: [119.522865], f: [4.1556337e-08]\n",
      "f_r: [-0.00079299], r: [119.18685], f: [116.405975]\n",
      "f_r: [-0.00110368], r: [119.055756], f: [2.7757238e-07]\n",
      "f_r: [-0.00163196], r: [119.682556], f: [0.3403076]\n",
      "f_r: [-0.0272934], r: [119.7458], f: [2.4793368e-12]\n",
      "f_r: [0.00230817], r: [119.11594], f: [1.3755829]\n",
      "f_r: [0.00016601], r: [119.29511], f: [486.42966]\n",
      "f_r: [0.002205], r: [119.22869], f: [20.216127]\n",
      "f_r: [-0.00081473], r: [119.34996], f: [0.10893844]\n",
      "f_r: [-0.00146495], r: [119.1748], f: [0.61280024]\n",
      "f_r: [-0.00030155], r: [119.33311], f: [0.14340597]\n",
      "f_r: [0.00264077], r: [119.89596], f: [1.6410651e-05]\n",
      "f_r: [0.00138505], r: [119.52766], f: [1.5540711e-11]\n",
      "f_r: [-0.01908945], r: [119.81457], f: [1.038063e-13]\n",
      "f_r: [0.00114989], r: [119.84908], f: [0.00566522]\n",
      "f_r: [-0.00241186], r: [119.99776], f: [1.3609248e-06]\n",
      "f_r: [-0.0020074], r: [119.338806], f: [0.00722238]\n",
      "f_r: [0.00123366], r: [119.73461], f: [5.924291e-10]\n",
      "f_r: [-0.00305057], r: [119.21254], f: [2.0143523e-05]\n",
      "f_r: [-0.00078906], r: [119.91036], f: [0.00790646]\n",
      "f_r: [-0.00676455], r: [119.697845], f: [1.8601322e-11]\n",
      "f_r: [0.00451719], r: [119.90738], f: [13.117318]\n",
      "f_r: [-0.00088901], r: [119.92957], f: [0.10396242]\n",
      "Training loss for epoch 59: pinn: 0.2702, boundary: 10.2409, total: 10.5111\n",
      "f_r: [-0.00080192], r: [119.47682], f: [6.46022e-06]\n",
      "f_r: [0.00461104], r: [119.74718], f: [0.6596795]\n",
      "f_r: [0.00837317], r: [119.08959], f: [0.00031214]\n",
      "f_r: [0.00268565], r: [119.452675], f: [1.4395472e-07]\n",
      "f_r: [-0.00567424], r: [119.81868], f: [4.4707813e-06]\n",
      "f_r: [-0.0070223], r: [119.99639], f: [1.0794089e-05]\n",
      "f_r: [-0.02169427], r: [119.70812], f: [4.4919265e-14]\n",
      "f_r: [-0.00039796], r: [119.65219], f: [0.01116714]\n",
      "f_r: [-0.00821131], r: [119.38137], f: [7.484663e-14]\n",
      "f_r: [0.00088368], r: [119.61751], f: [0.00044196]\n",
      "f_r: [-0.00551871], r: [119.939865], f: [0.40255618]\n",
      "f_r: [0.00142919], r: [119.526276], f: [44.634407]\n",
      "f_r: [-0.01702729], r: [119.265526], f: [2.457796e-12]\n",
      "f_r: [0.00459074], r: [119.960686], f: [3.698389e-08]\n",
      "f_r: [0.00241934], r: [119.93482], f: [5.129375e-06]\n",
      "f_r: [-0.00499246], r: [119.72091], f: [4.645658e-14]\n",
      "f_r: [-0.0011729], r: [119.50121], f: [3.8848052]\n",
      "f_r: [0.00037477], r: [119.16412], f: [54.223076]\n",
      "f_r: [0.00492066], r: [119.98036], f: [9.2029085]\n",
      "f_r: [0.00048523], r: [119.69328], f: [2.2446244e-08]\n",
      "f_r: [0.00457115], r: [119.091866], f: [2.4059807e-09]\n",
      "f_r: [0.00127889], r: [119.1657], f: [1.6440012e-08]\n",
      "f_r: [-0.00843376], r: [119.31263], f: [1.1506946e-11]\n",
      "f_r: [-0.00508517], r: [119.5345], f: [1.102088e-14]\n",
      "f_r: [0.00204515], r: [119.70926], f: [0.00031384]\n",
      "f_r: [0.00322585], r: [119.700356], f: [2.841639e-06]\n",
      "f_r: [0.0075199], r: [119.99684], f: [0.02600046]\n",
      "f_r: [0.02666503], r: [119.77366], f: [1.4582309e-15]\n",
      "f_r: [0.01407832], r: [119.39027], f: [2.8269706e-11]\n",
      "f_r: [-0.00066971], r: [119.01829], f: [5.052435]\n",
      "f_r: [0.03616819], r: [119.45221], f: [1.9774746e-10]\n",
      "f_r: [8.200796e-05], r: [119.38046], f: [6.3809395]\n",
      "f_r: [-0.0007993], r: [119.238464], f: [6.347584e-07]\n",
      "f_r: [0.0037862], r: [119.19162], f: [0.03660366]\n",
      "f_r: [-0.00150309], r: [119.26349], f: [5.992248e-07]\n",
      "f_r: [-0.00517769], r: [119.38114], f: [6.9451365e-15]\n",
      "f_r: [-0.00396775], r: [119.68187], f: [8.7376094e-08]\n",
      "f_r: [-0.00056662], r: [119.65562], f: [83.80523]\n",
      "f_r: [-0.00188354], r: [119.352455], f: [0.07807722]\n",
      "f_r: [-0.00140044], r: [119.54839], f: [1.3343157e-06]\n",
      "Training loss for epoch 60: pinn: 0.2463, boundary: 12.9056, total: 13.1518\n",
      "f_r: [0.00081146], r: [119.77709], f: [107.27749]\n",
      "f_r: [-0.01344422], r: [119.09618], f: [1.0815738e-05]\n",
      "f_r: [-0.00313479], r: [119.991585], f: [0.22857773]\n",
      "f_r: [0.00033993], r: [119.73232], f: [0.60936284]\n",
      "f_r: [0.00969185], r: [119.74969], f: [0.04029049]\n",
      "f_r: [0.008273], r: [119.338356], f: [28.764784]\n",
      "f_r: [0.0066909], r: [119.76772], f: [0.05389434]\n",
      "f_r: [0.00377334], r: [119.67387], f: [3.0924048e-06]\n",
      "f_r: [-0.0012073], r: [119.76704], f: [0.01536376]\n",
      "f_r: [-0.00148403], r: [119.04213], f: [3.8595078]\n",
      "f_r: [-0.00183611], r: [119.5101], f: [83.48141]\n",
      "f_r: [-0.00248437], r: [119.47614], f: [0.0130905]\n",
      "f_r: [-0.00014915], r: [119.98242], f: [88.810425]\n",
      "f_r: [0.00032218], r: [119.60839], f: [38.6496]\n",
      "f_r: [-0.01568793], r: [119.81868], f: [1.5786037e-12]\n",
      "f_r: [0.00417068], r: [119.71999], f: [9.364646e-09]\n",
      "f_r: [0.01984762], r: [119.430565], f: [1.0694817e-09]\n",
      "f_r: [-0.00028638], r: [119.09004], f: [40.56571]\n",
      "f_r: [-0.00135576], r: [119.04826], f: [25.504044]\n",
      "f_r: [-0.00250708], r: [119.24984], f: [3.526365e-05]\n",
      "f_r: [0.00257503], r: [119.70104], f: [9.858797e-08]\n",
      "f_r: [0.00022074], r: [119.23142], f: [580.77405]\n",
      "f_r: [-0.00261289], r: [119.02714], f: [0.2360249]\n",
      "f_r: [0.00224115], r: [119.46269], f: [0.73712736]\n",
      "f_r: [-0.00113599], r: [119.68826], f: [115.68171]\n",
      "f_r: [-0.012272], r: [119.18299], f: [3.1048758e-13]\n",
      "f_r: [0.00353585], r: [119.71474], f: [0.00025281]\n",
      "f_r: [-0.00039955], r: [119.76361], f: [0.09235362]\n",
      "f_r: [0.03313166], r: [119.281906], f: [2.3652031e-09]\n",
      "f_r: [-0.00391892], r: [119.8804], f: [3.704586]\n",
      "f_r: [-0.00427488], r: [119.820274], f: [20.666325]\n",
      "f_r: [0.0023953], r: [119.88383], f: [15.14946]\n",
      "f_r: [-0.01591951], r: [119.31218], f: [3.4518742e-13]\n",
      "f_r: [0.00253751], r: [119.87423], f: [0.02699923]\n",
      "f_r: [-8.14086e-05], r: [119.01602], f: [472.6924]\n",
      "f_r: [-0.00215729], r: [119.0385], f: [0.0919478]\n",
      "f_r: [0.00010814], r: [119.78441], f: [499.83127]\n",
      "f_r: [-0.01283382], r: [119.179794], f: [9.9595415e-14]\n",
      "f_r: [-0.00329762], r: [119.77687], f: [0.19655941]\n",
      "f_r: [-0.00036705], r: [119.757675], f: [0.05382618]\n",
      "Training loss for epoch 61: pinn: 0.2331, boundary: 16.8899, total: 17.1231\n",
      "f_r: [-0.00448951], r: [119.82531], f: [3.9244333e-11]\n",
      "f_r: [-0.01656298], r: [119.45084], f: [1.4292734e-15]\n",
      "f_r: [-0.0106288], r: [119.96847], f: [7.2495637]\n",
      "f_r: [-0.00187754], r: [119.73278], f: [2.4521852]\n",
      "f_r: [0.00059052], r: [119.6004], f: [124.23063]\n",
      "f_r: [0.00897117], r: [119.168434], f: [0.00059841]\n",
      "f_r: [0.00698259], r: [119.82576], f: [0.00599783]\n",
      "f_r: [0.01019411], r: [119.073235], f: [1.3625152e-14]\n",
      "f_r: [0.00086147], r: [119.75401], f: [0.2548975]\n",
      "f_r: [0.00220747], r: [119.21936], f: [5.7892877e-09]\n",
      "f_r: [0.00332084], r: [119.42783], f: [5.180492e-10]\n",
      "f_r: [0.00314926], r: [119.48776], f: [6.4431767]\n",
      "f_r: [-0.00133444], r: [119.65676], f: [174.26768]\n",
      "f_r: [-0.00346333], r: [119.72616], f: [2.5769727e-11]\n",
      "f_r: [0.00805176], r: [119.49985], f: [2.0059924e-14]\n",
      "f_r: [-0.0078557], r: [119.27213], f: [6.611195e-13]\n",
      "f_r: [-0.00538364], r: [119.08233], f: [6.2901334e-10]\n",
      "f_r: [-0.00583805], r: [119.00648], f: [5.0572434e-14]\n",
      "f_r: [-0.00023718], r: [119.2703], f: [4.3658204e-08]\n",
      "f_r: [-0.00024476], r: [119.056206], f: [4.375421]\n",
      "f_r: [-6.521452e-05], r: [119.52651], f: [5.537177]\n",
      "f_r: [0.010075], r: [119.37568], f: [1.9339828e-09]\n",
      "f_r: [0.01022291], r: [119.50349], f: [9.630528e-12]\n",
      "f_r: [0.00018968], r: [119.67616], f: [40.44127]\n",
      "f_r: [0.00053398], r: [119.86074], f: [345.85437]\n",
      "f_r: [0.00343276], r: [119.82645], f: [1.2653333e-09]\n",
      "f_r: [-0.01273061], r: [119.30307], f: [3.3398693e-13]\n",
      "f_r: [-0.00215352], r: [119.20799], f: [22.694212]\n",
      "f_r: [-0.00148889], r: [119.317406], f: [31.483095]\n",
      "f_r: [-0.00035187], r: [119.44379], f: [64.13567]\n",
      "f_r: [0.00020717], r: [119.59698], f: [295.0909]\n",
      "f_r: [-0.00025267], r: [119.52743], f: [94.47692]\n",
      "f_r: [-0.00619318], r: [119.00127], f: [7.8718126e-10]\n",
      "f_r: [0.00142055], r: [119.82257], f: [9.627902e-08]\n",
      "f_r: [-0.00826396], r: [119.536316], f: [4.440162e-10]\n",
      "f_r: [-0.01062971], r: [119.248474], f: [6.6396823e-12]\n",
      "f_r: [0.00231598], r: [119.76133], f: [0.6532191]\n",
      "f_r: [-0.00362026], r: [119.90945], f: [18.302153]\n",
      "f_r: [-5.0750365e-05], r: [119.680725], f: [447.92026]\n",
      "f_r: [0.00115062], r: [119.58398], f: [3.7408784e-06]\n",
      "Training loss for epoch 62: pinn: 0.2100, boundary: 19.0748, total: 19.2848\n",
      "f_r: [0.00116548], r: [119.628006], f: [7.2817464]\n",
      "f_r: [-0.00365447], r: [119.38683], f: [34.57387]\n",
      "f_r: [-0.00747917], r: [119.84222], f: [9.02297]\n",
      "f_r: [0.00218677], r: [119.69579], f: [1.0568267]\n",
      "f_r: [-0.00502973], r: [119.326965], f: [2.8008422e-12]\n",
      "f_r: [0.00975082], r: [119.91196], f: [1.5619314e-07]\n",
      "f_r: [0.0062675], r: [119.582146], f: [8.287649e-09]\n",
      "f_r: [0.00300088], r: [119.14299], f: [22.298126]\n",
      "f_r: [-0.00038751], r: [119.35269], f: [45.026756]\n",
      "f_r: [-0.00087266], r: [119.70332], f: [71.1262]\n",
      "f_r: [0.00292233], r: [119.04713], f: [1.26874]\n",
      "f_r: [0.01035447], r: [119.646034], f: [4.746505e-09]\n",
      "f_r: [-0.00398982], r: [119.55683], f: [3.438256]\n",
      "f_r: [0.00543244], r: [119.4611], f: [0.00824943]\n",
      "f_r: [0.00281087], r: [119.59994], f: [10.448692]\n",
      "f_r: [-0.00552653], r: [119.82142], f: [1.07567115e-11]\n",
      "f_r: [0.00190573], r: [119.87926], f: [4.59366e-06]\n",
      "f_r: [0.00331323], r: [119.55479], f: [6.753106]\n",
      "f_r: [0.01691677], r: [119.42897], f: [7.122399e-09]\n",
      "f_r: [-0.01055088], r: [119.30762], f: [7.228188e-13]\n",
      "f_r: [0.00123537], r: [119.17412], f: [1.8512326e-05]\n",
      "f_r: [-0.00136496], r: [119.99569], f: [64.523766]\n",
      "f_r: [-0.0006649], r: [119.16276], f: [0.21245812]\n",
      "f_r: [-0.00023565], r: [119.26644], f: [640.10925]\n",
      "f_r: [0.00607726], r: [119.022606], f: [6.483389e-08]\n",
      "f_r: [-0.0073845], r: [119.33334], f: [2.0671259e-13]\n",
      "f_r: [-0.00254117], r: [119.91608], f: [63.31902]\n",
      "f_r: [-0.00210207], r: [119.019424], f: [140.30057]\n",
      "f_r: [0.00365934], r: [119.27782], f: [1.2189602e-11]\n",
      "f_r: [-0.00326445], r: [119.64443], f: [0.12742998]\n",
      "f_r: [0.00055901], r: [119.95565], f: [189.22226]\n",
      "f_r: [-0.00262648], r: [119.065285], f: [1.2946879e-05]\n",
      "f_r: [0.00030804], r: [119.43308], f: [1.490411e-07]\n",
      "f_r: [-0.00154531], r: [119.21891], f: [4.526787e-06]\n",
      "f_r: [-0.01165112], r: [119.5712], f: [2.1352337e-10]\n",
      "f_r: [0.00026259], r: [119.85754], f: [6.4848943]\n",
      "f_r: [-0.00078959], r: [119.112076], f: [47.07365]\n",
      "f_r: [0.00361843], r: [119.21891], f: [1.3056247]\n",
      "f_r: [-0.00261676], r: [119.896866], f: [5.8732445e-14]\n",
      "f_r: [0.00350297], r: [119.08551], f: [0.02805385]\n",
      "Training loss for epoch 63: pinn: 0.1875, boundary: 16.7790, total: 16.9665\n",
      "f_r: [0.01583524], r: [119.217766], f: [1.9829608e-08]\n",
      "f_r: [-0.00598727], r: [119.03282], f: [1.5821488e-08]\n",
      "f_r: [-0.0080479], r: [119.13616], f: [4.0366433e-13]\n",
      "f_r: [-0.00575109], r: [119.036], f: [4.948458e-10]\n",
      "f_r: [0.00673647], r: [119.168434], f: [1.0931527e-05]\n",
      "f_r: [0.01394183], r: [119.79629], f: [3.3132753e-11]\n",
      "f_r: [-0.00083915], r: [119.10163], f: [3.567772e-13]\n",
      "f_r: [-0.00494618], r: [119.03419], f: [18.0932]\n",
      "f_r: [0.00068752], r: [119.46975], f: [4.2396807e-16]\n",
      "f_r: [-0.01179059], r: [119.99937], f: [1.0096394e-09]\n",
      "f_r: [0.00067637], r: [119.23324], f: [92.41193]\n",
      "f_r: [0.00126905], r: [119.61455], f: [445.36475]\n",
      "f_r: [-0.00875239], r: [119.86211], f: [3.5251757e-10]\n",
      "f_r: [0.00020448], r: [119.35314], f: [18.358213]\n",
      "f_r: [0.00238286], r: [119.965256], f: [0.5601751]\n",
      "f_r: [-0.00494721], r: [119.66018], f: [1.2742846e-13]\n",
      "f_r: [0.00167142], r: [119.25415], f: [10.174308]\n",
      "f_r: [0.00174098], r: [119.83926], f: [3.766736e-06]\n",
      "f_r: [-0.00019414], r: [119.855705], f: [43.90525]\n",
      "f_r: [-0.00826973], r: [119.49893], f: [1.2146115e-10]\n",
      "f_r: [-0.00848867], r: [119.03577], f: [27.204176]\n",
      "f_r: [0.00406742], r: [119.680725], f: [0.9597636]\n",
      "f_r: [-0.01290577], r: [119.57805], f: [4.2080164e-10]\n",
      "f_r: [-0.00158745], r: [119.69944], f: [5.698815e-13]\n",
      "f_r: [-0.0050845], r: [119.6385], f: [0.3360945]\n",
      "f_r: [-0.00258628], r: [119.29079], f: [2.950259e-13]\n",
      "f_r: [-0.00182158], r: [119.90693], f: [1.5671966e-13]\n",
      "f_r: [0.00256229], r: [119.8436], f: [1.2935628e-08]\n",
      "f_r: [-0.00191708], r: [119.023056], f: [0.06541699]\n",
      "f_r: [-0.00287243], r: [119.81525], f: [0.1987006]\n",
      "f_r: [-0.00030189], r: [119.42259], f: [6.3203904e-14]\n",
      "f_r: [0.02010052], r: [119.528336], f: [3.4133464e-12]\n",
      "f_r: [-0.00106812], r: [119.14685], f: [1.3537595e-14]\n",
      "f_r: [-0.01125081], r: [119.21936], f: [1.383896e-09]\n",
      "f_r: [-0.01229269], r: [119.55136], f: [3.7172607e-10]\n",
      "f_r: [0.00344566], r: [119.98059], f: [6.423828e-07]\n",
      "f_r: [-0.00606666], r: [119.66018], f: [5.8638844e-11]\n",
      "f_r: [0.00083318], r: [119.66041], f: [1.1761625e-06]\n",
      "f_r: [0.00342942], r: [119.172066], f: [7.1957974]\n",
      "f_r: [-0.00029996], r: [119.46907], f: [387.9139]\n",
      "Training loss for epoch 64: pinn: 0.1672, boundary: 11.2705, total: 11.4377\n",
      "f_r: [-0.00272178], r: [119.961136], f: [0.00307637]\n",
      "f_r: [-0.00262297], r: [119.62914], f: [377.19296]\n",
      "f_r: [-0.00026975], r: [119.682556], f: [0.13339113]\n",
      "f_r: [-0.00726054], r: [119.97808], f: [19.361801]\n",
      "f_r: [-0.00240835], r: [119.29055], f: [4.1263995e-13]\n",
      "f_r: [-0.00343647], r: [119.411674], f: [2.6393313e-06]\n",
      "f_r: [-0.0034508], r: [119.006714], f: [0.00023269]\n",
      "f_r: [0.00133966], r: [119.2553], f: [1.126266e-06]\n",
      "f_r: [0.0015947], r: [119.3709], f: [1.2489602e-05]\n",
      "f_r: [0.0015967], r: [119.771614], f: [180.18259]\n",
      "f_r: [0.00217925], r: [119.55182], f: [171.93683]\n",
      "f_r: [-0.00384938], r: [119.24393], f: [0.30604306]\n",
      "f_r: [-0.00613915], r: [119.363846], f: [1.8810706e-05]\n",
      "f_r: [-0.00304207], r: [119.97144], f: [1.5897724e-07]\n",
      "f_r: [-0.00403538], r: [119.74763], f: [0.00010988]\n",
      "f_r: [0.00138766], r: [119.866], f: [7.1537046]\n",
      "f_r: [0.00252301], r: [119.30011], f: [1.4699e-12]\n",
      "f_r: [0.01014066], r: [119.24483], f: [1.8589085e-11]\n",
      "f_r: [-0.00892051], r: [119.39344], f: [2.666746e-09]\n",
      "f_r: [-0.0020941], r: [119.217316], f: [2.779144]\n",
      "f_r: [0.00600134], r: [119.32447], f: [1.7230401e-15]\n",
      "f_r: [7.1109884e-05], r: [119.30307], f: [10.720142]\n",
      "f_r: [-0.00209355], r: [119.24278], f: [45.202137]\n",
      "f_r: [-0.00262423], r: [119.63553], f: [0.23916037]\n",
      "f_r: [0.00128812], r: [119.654015], f: [1.6103131e-12]\n",
      "f_r: [-0.01084623], r: [119.389114], f: [2.2088587e-09]\n",
      "f_r: [0.00467994], r: [119.2496], f: [0.02990719]\n",
      "f_r: [-0.0006127], r: [119.03305], f: [140.92561]\n",
      "f_r: [-0.00283032], r: [119.360664], f: [8.3495815e-15]\n",
      "f_r: [0.00078943], r: [119.787155], f: [3.713585e-07]\n",
      "f_r: [-0.00054404], r: [119.55479], f: [422.2341]\n",
      "f_r: [0.00048549], r: [119.20321], f: [5.898782e-15]\n",
      "f_r: [-0.01365458], r: [119.683235], f: [2.6481023e-10]\n",
      "f_r: [-0.0020308], r: [119.67387], f: [9.47322e-14]\n",
      "f_r: [-0.00337648], r: [119.32674], f: [7.896624e-14]\n",
      "f_r: [-0.00068396], r: [119.200264], f: [48.704308]\n",
      "f_r: [-0.00421548], r: [119.670906], f: [0.16120161]\n",
      "f_r: [0.00324917], r: [119.44628], f: [2.1478047]\n",
      "f_r: [-0.000371], r: [119.09459], f: [0.10073619]\n",
      "f_r: [0.00195665], r: [119.57417], f: [2.4508216e-15]\n",
      "Training loss for epoch 65: pinn: 0.1903, boundary: 16.1303, total: 16.3206\n",
      "f_r: [0.00312669], r: [119.64009], f: [0.9962626]\n",
      "f_r: [8.550341e-06], r: [119.172066], f: [2.1913023e-08]\n",
      "f_r: [0.02655559], r: [119.96435], f: [1.1568189e-11]\n",
      "f_r: [-0.01346689], r: [119.10504], f: [3.4499578e-10]\n",
      "f_r: [-0.00701841], r: [119.86417], f: [4.5679968e-05]\n",
      "f_r: [-0.00930496], r: [119.13616], f: [4.6938168e-14]\n",
      "f_r: [-0.00056313], r: [119.96824], f: [114.109314]\n",
      "f_r: [-0.00535974], r: [119.508736], f: [0.03829841]\n",
      "f_r: [-0.01808037], r: [119.73255], f: [2.601266e-10]\n",
      "f_r: [0.01278011], r: [119.60132], f: [0.01806027]\n",
      "f_r: [0.01559896], r: [119.08551], f: [1.7245729e-07]\n",
      "f_r: [0.01098422], r: [119.60884], f: [7.321266e-12]\n",
      "f_r: [0.00223452], r: [119.5427], f: [10.467153]\n",
      "f_r: [-0.00109281], r: [119.93369], f: [4.927688e-07]\n",
      "f_r: [-0.00222416], r: [119.38092], f: [9.1099144e-05]\n",
      "f_r: [-0.0001624], r: [119.82759], f: [148.5588]\n",
      "f_r: [0.00278445], r: [119.37386], f: [0.00120605]\n",
      "f_r: [-0.01266973], r: [119.45221], f: [9.125508e-10]\n",
      "f_r: [0.00186535], r: [119.1273], f: [1.0155105e-13]\n",
      "f_r: [-0.00573773], r: [119.50485], f: [23.054434]\n",
      "f_r: [0.00860774], r: [119.235054], f: [3.0961607e-12]\n",
      "f_r: [-0.00121299], r: [119.51419], f: [0.4880804]\n",
      "f_r: [-0.01395424], r: [119.120255], f: [6.280195e-10]\n",
      "f_r: [-0.00220467], r: [119.217545], f: [0.22035615]\n",
      "f_r: [-0.00087649], r: [119.15025], f: [415.9975]\n",
      "f_r: [-0.00116355], r: [119.57577], f: [448.08368]\n",
      "f_r: [0.00065102], r: [119.63713], f: [1.7754505]\n",
      "f_r: [-0.00898152], r: [119.85754], f: [7.1774258e-09]\n",
      "f_r: [-0.01580737], r: [119.95771], f: [6.622662e-11]\n",
      "f_r: [0.02016425], r: [119.83536], f: [9.820286e-08]\n",
      "f_r: [-0.00071049], r: [119.21823], f: [0.00090195]\n",
      "f_r: [-0.00236078], r: [119.97602], f: [0.27141318]\n",
      "f_r: [-0.0161778], r: [119.608604], f: [3.577856e-10]\n",
      "f_r: [-0.00310543], r: [119.5085], f: [1.00473015e-11]\n",
      "f_r: [-0.01660507], r: [119.206856], f: [1.4475242e-10]\n",
      "f_r: [-0.00042795], r: [119.615], f: [5.9758524e-05]\n",
      "f_r: [0.00100362], r: [119.973495], f: [372.2333]\n",
      "f_r: [-0.0046121], r: [119.58238], f: [1.13699095e-08]\n",
      "f_r: [0.00172833], r: [119.33084], f: [2.2396395e-14]\n",
      "f_r: [-2.2275484e-05], r: [119.25439], f: [1.589321e-14]\n",
      "Training loss for epoch 66: pinn: 0.1942, boundary: 15.1452, total: 15.3395\n",
      "f_r: [0.00021193], r: [119.41189], f: [6.9979484e-07]\n",
      "f_r: [0.00999478], r: [119.15593], f: [1.0304981e-12]\n",
      "f_r: [0.00305769], r: [119.87789], f: [82.97038]\n",
      "f_r: [0.00462668], r: [119.32833], f: [9.050186e-06]\n",
      "f_r: [-0.01546876], r: [119.95565], f: [6.706571e-11]\n",
      "f_r: [-0.00250137], r: [119.4456], f: [2.5435563e-15]\n",
      "f_r: [-0.00257255], r: [119.08073], f: [0.00359343]\n",
      "f_r: [0.01241123], r: [119.512825], f: [2.236726e-12]\n",
      "f_r: [0.01687063], r: [119.03622], f: [1.8956574e-07]\n",
      "f_r: [-0.00946973], r: [119.4456], f: [6.577061e-09]\n",
      "f_r: [0.00320823], r: [119.075966], f: [2.7640831]\n",
      "f_r: [0.03006968], r: [119.7031], f: [1.5057454e-12]\n",
      "f_r: [0.00050772], r: [119.46201], f: [8.585621e-12]\n",
      "f_r: [-0.0266256], r: [119.145256], f: [0.24714345]\n",
      "f_r: [0.01548009], r: [119.51192], f: [8.6423555e-08]\n",
      "f_r: [-0.00025613], r: [119.24619], f: [151.57925]\n",
      "f_r: [0.00350282], r: [119.98242], f: [15.833775]\n",
      "f_r: [0.00882965], r: [119.68643], f: [0.0213103]\n",
      "f_r: [0.00075931], r: [119.66976], f: [673.49414]\n",
      "f_r: [0.00276099], r: [119.95084], f: [1.3449582e-13]\n",
      "f_r: [0.00106872], r: [119.3215], f: [1.049732e-14]\n",
      "f_r: [0.00035601], r: [119.18799], f: [8.253912e-15]\n",
      "f_r: [-0.00369829], r: [119.87445], f: [0.26699564]\n",
      "f_r: [0.00494906], r: [119.56026], f: [0.0249892]\n",
      "f_r: [-0.00080035], r: [119.76042], f: [183.34138]\n",
      "f_r: [0.02799362], r: [119.046], f: [1.614275e-07]\n",
      "f_r: [0.0004926], r: [119.628456], f: [352.7982]\n",
      "f_r: [0.00296556], r: [119.2926], f: [12.777781]\n",
      "f_r: [0.00326996], r: [119.29716], f: [10.841032]\n",
      "f_r: [-0.00447057], r: [119.403915], f: [7.7074255e-05]\n",
      "f_r: [-0.0042867], r: [119.72707], f: [1.6895456e-08]\n",
      "f_r: [-0.01676663], r: [119.99295], f: [7.843816e-10]\n",
      "f_r: [-0.00269021], r: [119.33494], f: [0.00384916]\n",
      "f_r: [0.00194359], r: [119.51055], f: [0.75849694]\n",
      "f_r: [-0.00396738], r: [119.90693], f: [0.51862776]\n",
      "f_r: [0.00026877], r: [119.994095], f: [1.3390228e-05]\n",
      "f_r: [0.00032747], r: [119.67616], f: [232.92355]\n",
      "f_r: [-0.00011962], r: [119.873085], f: [420.6074]\n",
      "f_r: [-0.0024948], r: [119.18321], f: [0.05690015]\n",
      "f_r: [-0.00315645], r: [119.95726], f: [0.16089478]\n",
      "Training loss for epoch 67: pinn: 0.1932, boundary: 14.2205, total: 14.4137\n",
      "f_r: [0.00475284], r: [119.50098], f: [9.387078]\n",
      "f_r: [-0.00441177], r: [119.47864], f: [2.3498988e-07]\n",
      "f_r: [-0.0041191], r: [119.2578], f: [0.01120821]\n",
      "f_r: [-0.00194661], r: [119.05053], f: [4.490707]\n",
      "f_r: [-0.00293109], r: [119.12798], f: [0.4161905]\n",
      "f_r: [0.00678552], r: [119.743965], f: [0.00070785]\n",
      "f_r: [0.00748976], r: [119.48868], f: [3.5095098e-05]\n",
      "f_r: [0.00532366], r: [119.74466], f: [0.00011381]\n",
      "f_r: [0.00290209], r: [119.041], f: [1.7439777e-13]\n",
      "f_r: [0.00187887], r: [119.015564], f: [4.8170803e-12]\n",
      "f_r: [-0.01375752], r: [119.59904], f: [2.256135e-09]\n",
      "f_r: [-0.00305762], r: [119.64147], f: [2.0439948e-05]\n",
      "f_r: [-0.00037372], r: [119.29738], f: [7.754576e-14]\n",
      "f_r: [0.00184248], r: [119.76202], f: [484.47226]\n",
      "f_r: [0.00058678], r: [119.02419], f: [3.5915548e-08]\n",
      "f_r: [0.00521358], r: [119.08141], f: [10.276882]\n",
      "f_r: [-0.00039744], r: [119.98151], f: [358.65518]\n",
      "f_r: [-0.00165585], r: [119.317406], f: [0.00386393]\n",
      "f_r: [-0.00090388], r: [119.55228], f: [292.28354]\n",
      "f_r: [0.0037624], r: [119.13048], f: [3.7304968e-08]\n",
      "f_r: [-0.000752], r: [119.98861], f: [49.217266]\n",
      "f_r: [0.00029744], r: [119.40824], f: [123.23794]\n",
      "f_r: [0.00232106], r: [119.51101], f: [5.998367e-14]\n",
      "f_r: [0.00897533], r: [119.214584], f: [5.2009117e-08]\n",
      "f_r: [0.00909685], r: [119.02124], f: [1.6686804e-12]\n",
      "f_r: [-0.00308328], r: [119.67478], f: [2.8077872]\n",
      "f_r: [-0.00404145], r: [119.681175], f: [8.769346e-12]\n",
      "f_r: [0.00144312], r: [119.77732], f: [1.3408496e-13]\n",
      "f_r: [0.00101713], r: [119.75471], f: [5.475204]\n",
      "f_r: [0.00053044], r: [119.771614], f: [3.865051e-05]\n",
      "f_r: [-0.01598901], r: [119.11367], f: [1.4979154e-10]\n",
      "f_r: [0.00044926], r: [119.61523], f: [1.4529794e-13]\n",
      "f_r: [0.00220388], r: [119.94467], f: [0.02458939]\n",
      "f_r: [0.00071489], r: [119.71405], f: [2.482457e-14]\n",
      "f_r: [-0.00048788], r: [119.7506], f: [3.255016e-14]\n",
      "f_r: [0.00049604], r: [119.517624], f: [148.35258]\n",
      "f_r: [-0.00057548], r: [119.26371], f: [1.7102942e-14]\n",
      "f_r: [-0.00046391], r: [119.97464], f: [0.00025715]\n",
      "f_r: [2.5464926e-05], r: [119.018745], f: [513.4412]\n",
      "f_r: [-0.00032641], r: [119.623665], f: [237.11786]\n",
      "Training loss for epoch 68: pinn: 0.1834, boundary: 12.9578, total: 13.1412\n",
      "f_r: [-0.00056216], r: [119.07438], f: [1.06581614e-13]\n",
      "f_r: [0.00830798], r: [119.873535], f: [2.4495424e-14]\n",
      "f_r: [-0.00033639], r: [119.88315], f: [4.9532314e-08]\n",
      "f_r: [0.00512769], r: [119.02464], f: [17.810122]\n",
      "f_r: [-0.00208944], r: [119.34586], f: [0.03329879]\n",
      "f_r: [-0.0027313], r: [119.94033], f: [4.6642676e-14]\n",
      "f_r: [0.00045929], r: [119.73072], f: [0.5822981]\n",
      "f_r: [0.00023585], r: [119.41235], f: [5.4012077e-15]\n",
      "f_r: [-0.00217499], r: [119.18731], f: [1.510037e-11]\n",
      "f_r: [-0.01046024], r: [119.56162], f: [2.7589898]\n",
      "f_r: [-0.01372209], r: [119.13753], f: [1.5905344e-10]\n",
      "f_r: [0.00033721], r: [119.68529], f: [3.7804876e-15]\n",
      "f_r: [-0.01827428], r: [119.81319], f: [1.3615912e-09]\n",
      "f_r: [-0.00142466], r: [119.51033], f: [0.00146502]\n",
      "f_r: [0.00198991], r: [119.1814], f: [0.02178831]\n",
      "f_r: [0.00257331], r: [119.37158], f: [3.42558e-13]\n",
      "f_r: [0.02460347], r: [119.46201], f: [6.843092e-13]\n",
      "f_r: [0.00084158], r: [119.3709], f: [0.7965939]\n",
      "f_r: [-0.01264426], r: [119.13684], f: [2.368853e-11]\n",
      "f_r: [-0.01770145], r: [119.578735], f: [1.8125063e-09]\n",
      "f_r: [0.00049372], r: [119.54156], f: [5.656844e-06]\n",
      "f_r: [0.00221181], r: [119.981735], f: [7.3350546e-14]\n",
      "f_r: [-0.00017499], r: [119.21823], f: [314.29434]\n",
      "f_r: [-0.00023054], r: [119.1273], f: [101.04724]\n",
      "f_r: [0.00337684], r: [119.48092], f: [12.146545]\n",
      "f_r: [0.0017767], r: [119.31331], f: [4.864684e-13]\n",
      "f_r: [0.00049964], r: [119.400505], f: [50.745003]\n",
      "f_r: [-0.00442002], r: [119.70515], f: [22.0682]\n",
      "f_r: [0.00213239], r: [119.44606], f: [0.71274126]\n",
      "f_r: [-0.00137998], r: [119.10095], f: [18.891842]\n",
      "f_r: [-0.01404456], r: [119.04327], f: [1.4055894e-10]\n",
      "f_r: [0.00166146], r: [119.73302], f: [1.1724207]\n",
      "f_r: [0.00035951], r: [119.18799], f: [5.5757365]\n",
      "f_r: [0.00013455], r: [119.741005], f: [0.00123525]\n",
      "f_r: [-0.00144083], r: [119.7803], f: [2.7906208e-06]\n",
      "f_r: [-0.00377162], r: [119.01829], f: [0.00068585]\n",
      "f_r: [-0.01444736], r: [119.040085], f: [2.836409e-09]\n",
      "f_r: [-0.00127912], r: [119.039635], f: [0.00018953]\n",
      "f_r: [-0.0007149], r: [119.51922], f: [0.03117213]\n",
      "f_r: [0.01569538], r: [119.51329], f: [8.3657596e-08]\n",
      "Training loss for epoch 69: pinn: 0.1836, boundary: 9.8616, total: 10.0452\n",
      "f_r: [0.00383208], r: [119.59904], f: [4.2106842e-07]\n",
      "f_r: [-0.01506516], r: [119.22914], f: [2.1738586e-09]\n",
      "f_r: [-0.00571324], r: [119.44856], f: [0.26980802]\n",
      "f_r: [0.00049765], r: [119.69465], f: [0.06279565]\n",
      "f_r: [0.00425451], r: [119.62961], f: [156.8579]\n",
      "f_r: [0.00671104], r: [119.0621], f: [1.1116909e-12]\n",
      "f_r: [0.00200708], r: [119.96983], f: [453.984]\n",
      "f_r: [0.00179325], r: [119.850914], f: [98.35336]\n",
      "f_r: [0.00210672], r: [119.49551], f: [1.79942e-13]\n",
      "f_r: [-0.00313598], r: [119.37067], f: [0.02848693]\n",
      "f_r: [0.00217447], r: [119.4456], f: [8.734954]\n",
      "f_r: [-0.01250609], r: [119.52788], f: [2.9426053e-09]\n",
      "f_r: [-0.00161746], r: [119.539276], f: [0.85887355]\n",
      "f_r: [-0.01064336], r: [119.48], f: [3.2141323e-10]\n",
      "f_r: [0.0032982], r: [119.73483], f: [0.00126827]\n",
      "f_r: [0.00252866], r: [119.16162], f: [6.3418527]\n",
      "f_r: [-0.00125858], r: [119.678894], f: [9.471752e-15]\n",
      "f_r: [-0.00183621], r: [119.444016], f: [3.480666e-06]\n",
      "f_r: [-0.00334144], r: [119.2487], f: [6.2272577]\n",
      "f_r: [-0.01375801], r: [119.62733], f: [5.306997e-10]\n",
      "f_r: [0.01188168], r: [119.65493], f: [9.17932e-08]\n",
      "f_r: [0.00335913], r: [119.84976], f: [3.8518847e-05]\n",
      "f_r: [0.00418448], r: [119.37728], f: [1.4385354e-13]\n",
      "f_r: [-0.00254936], r: [119.32674], f: [7.529394]\n",
      "f_r: [-0.00190153], r: [119.26781], f: [32.35467]\n",
      "f_r: [-0.00140558], r: [119.37227], f: [138.8264]\n",
      "f_r: [0.02460077], r: [119.71976], f: [7.688688e-13]\n",
      "f_r: [-0.01267298], r: [119.48069], f: [2.2050254]\n",
      "f_r: [0.00079704], r: [119.973724], f: [1.8259847e-15]\n",
      "f_r: [0.01607381], r: [119.32537], f: [1.611743e-07]\n",
      "f_r: [-0.00189515], r: [119.12935], f: [21.34053]\n",
      "f_r: [-0.00207464], r: [119.40528], f: [0.03479632]\n",
      "f_r: [0.00039701], r: [119.84587], f: [7.407711e-15]\n",
      "f_r: [0.02161796], r: [119.51579], f: [2.7003742e-07]\n",
      "f_r: [0.00021338], r: [119.45996], f: [36.95461]\n",
      "f_r: [0.00075388], r: [119.13981], f: [127.19183]\n",
      "f_r: [-0.00025974], r: [119.43148], f: [1.3101207]\n",
      "f_r: [-0.00053896], r: [119.21164], f: [1.9457595e-13]\n",
      "f_r: [-0.00061506], r: [119.81868], f: [17.194155]\n",
      "f_r: [0.00225102], r: [119.83421], f: [1.0673972]\n",
      "Training loss for epoch 70: pinn: 0.1828, boundary: 13.5891, total: 13.7720\n",
      "f_r: [0.0180227], r: [119.95794], f: [2.649589e-07]\n",
      "f_r: [0.00393669], r: [119.41963], f: [1033.5195]\n",
      "f_r: [0.00357716], r: [119.08437], f: [140.90694]\n",
      "f_r: [0.00532685], r: [119.65949], f: [0.4638978]\n",
      "f_r: [0.00092362], r: [119.92866], f: [0.00166808]\n",
      "f_r: [0.00161803], r: [119.565735], f: [0.09334987]\n",
      "f_r: [0.00593823], r: [119.30604], f: [0.00065278]\n",
      "f_r: [0.00748672], r: [119.16457], f: [9.518697e-07]\n",
      "f_r: [-0.01308137], r: [119.10186], f: [1.4417018]\n",
      "f_r: [-0.01171074], r: [119.726845], f: [1.707296e-10]\n",
      "f_r: [-0.00281047], r: [119.851364], f: [0.03085442]\n",
      "f_r: [-0.00584198], r: [119.0796], f: [2.0793344e-08]\n",
      "f_r: [-0.00441253], r: [119.91379], f: [3.0747696e-15]\n",
      "f_r: [-0.00235846], r: [119.24619], f: [0.00272689]\n",
      "f_r: [0.00317262], r: [119.91493], f: [95.429634]\n",
      "f_r: [-0.00046629], r: [119.04621], f: [4.280246e-14]\n",
      "f_r: [-0.00170523], r: [119.924545], f: [1.5639393e-05]\n",
      "f_r: [-0.00136843], r: [119.68963], f: [1.730807e-15]\n",
      "f_r: [-0.00353236], r: [119.42579], f: [0.13322929]\n",
      "f_r: [0.00267534], r: [119.892746], f: [5.2887437e-15]\n",
      "f_r: [-0.00859181], r: [119.66771], f: [0.38716036]\n",
      "f_r: [0.00671801], r: [119.367035], f: [4.2982247e-08]\n",
      "f_r: [-0.00211901], r: [119.96847], f: [0.1998503]\n",
      "f_r: [0.00544179], r: [119.62686], f: [0.00164396]\n",
      "f_r: [0.00060187], r: [119.54292], f: [0.00017043]\n",
      "f_r: [0.00264641], r: [119.882], f: [0.00099087]\n",
      "f_r: [0.00156023], r: [119.67227], f: [7.5755117e-16]\n",
      "f_r: [-0.00046072], r: [119.9362], f: [70.293365]\n",
      "f_r: [-0.01142085], r: [119.85022], f: [2.3237778e-09]\n",
      "f_r: [-0.00224112], r: [119.06165], f: [28.625765]\n",
      "f_r: [0.00059611], r: [119.16094], f: [6.078085e-07]\n",
      "f_r: [-0.00648357], r: [119.82804], f: [0.1744607]\n",
      "f_r: [-0.00132077], r: [119.37523], f: [9.3742e-05]\n",
      "f_r: [-0.01630421], r: [119.50006], f: [7.5159506e-10]\n",
      "f_r: [-0.01751676], r: [119.62709], f: [1.7127853e-10]\n",
      "f_r: [-0.00120817], r: [119.638275], f: [22.312187]\n",
      "f_r: [-0.00236437], r: [119.17753], f: [0.00096442]\n",
      "f_r: [-0.01585085], r: [119.13594], f: [1.5203154e-09]\n",
      "f_r: [0.01158883], r: [119.617744], f: [0.00854172]\n",
      "f_r: [0.00019982], r: [119.59606], f: [86.8813]\n",
      "Training loss for epoch 71: pinn: 0.1880, boundary: 12.2751, total: 12.4631\n",
      "f_r: [0.00225106], r: [119.145485], f: [2.4968227e-13]\n",
      "f_r: [-0.00808214], r: [119.24687], f: [9.938397e-15]\n",
      "f_r: [0.00455991], r: [119.8916], f: [0.9074831]\n",
      "f_r: [0.00726745], r: [119.276], f: [909.26697]\n",
      "f_r: [0.00331113], r: [119.88932], f: [9.8992]\n",
      "f_r: [0.02055994], r: [119.822784], f: [3.4281245e-12]\n",
      "f_r: [0.00984995], r: [119.31673], f: [7.397598e-12]\n",
      "f_r: [0.0011041], r: [119.47568], f: [0.74825513]\n",
      "f_r: [0.02687473], r: [119.68507], f: [2.5725206e-13]\n",
      "f_r: [0.00147232], r: [119.87262], f: [6.7010865e-07]\n",
      "f_r: [-0.013288], r: [119.07801], f: [9.580132e-11]\n",
      "f_r: [0.0025153], r: [119.40187], f: [5.0033487e-15]\n",
      "f_r: [-0.00908538], r: [119.95611], f: [2.0138873e-09]\n",
      "f_r: [-0.00828199], r: [119.757675], f: [2.1100084e-09]\n",
      "f_r: [0.005534], r: [119.83102], f: [0.01380577]\n",
      "f_r: [0.00220103], r: [119.20754], f: [14.207703]\n",
      "f_r: [0.00045932], r: [119.30307], f: [181.6868]\n",
      "f_r: [-0.00127478], r: [119.398], f: [20.052288]\n",
      "f_r: [-0.00319784], r: [119.33243], f: [2.6995954e-06]\n",
      "f_r: [-0.00447127], r: [119.56231], f: [2.4864281e-14]\n",
      "f_r: [0.00171184], r: [119.77436], f: [0.9001732]\n",
      "f_r: [-0.00829474], r: [119.352005], f: [2.17555]\n",
      "f_r: [0.0005375], r: [119.30557], f: [3.47133e-14]\n",
      "f_r: [-0.01429941], r: [119.50737], f: [3.7425016e-10]\n",
      "f_r: [0.01365454], r: [119.21527], f: [1.2444982e-12]\n",
      "f_r: [-0.00970895], r: [119.89252], f: [6.3807035e-09]\n",
      "f_r: [-0.0001029], r: [119.27623], f: [327.87552]\n",
      "f_r: [-0.00106998], r: [119.42807], f: [21.512127]\n",
      "f_r: [0.00164731], r: [119.69465], f: [9.193102]\n",
      "f_r: [0.00094123], r: [119.57599], f: [3.6155357]\n",
      "f_r: [-0.00045172], r: [119.733696], f: [0.07548892]\n",
      "f_r: [0.00292287], r: [119.2114], f: [7.727814e-12]\n",
      "f_r: [0.00115176], r: [119.63736], f: [45.249786]\n",
      "f_r: [0.00014442], r: [119.64488], f: [27.78325]\n",
      "f_r: [0.00114923], r: [119.93872], f: [9.5754356e-15]\n",
      "f_r: [-0.00444111], r: [119.68164], f: [1.1668013e-08]\n",
      "f_r: [-0.01538499], r: [119.61317], f: [2.4165758e-10]\n",
      "f_r: [0.00101033], r: [119.248474], f: [1.8919635e-15]\n",
      "f_r: [-0.00904055], r: [119.00353], f: [3.3903984e-11]\n",
      "f_r: [0.00107311], r: [119.252335], f: [3.793274e-14]\n",
      "Training loss for epoch 72: pinn: 0.1930, boundary: 17.8447, total: 18.0377\n",
      "f_r: [0.00278826], r: [119.36794], f: [1.3606575]\n",
      "f_r: [0.00495656], r: [119.7915], f: [0.00087103]\n",
      "f_r: [-0.00203697], r: [119.14775], f: [12.358053]\n",
      "f_r: [-0.00180732], r: [119.70104], f: [7.82968]\n",
      "f_r: [0.00104863], r: [119.66771], f: [0.04302744]\n",
      "f_r: [0.00119989], r: [119.61956], f: [560.9762]\n",
      "f_r: [0.00340142], r: [119.12662], f: [47.882786]\n",
      "f_r: [0.00103139], r: [119.520134], f: [0.02201491]\n",
      "f_r: [-0.00336798], r: [119.373184], f: [0.00029266]\n",
      "f_r: [0.00138803], r: [119.67387], f: [109.96655]\n",
      "f_r: [0.00153626], r: [119.28942], f: [5.2096515]\n",
      "f_r: [-0.00018679], r: [119.04168], f: [5.436422]\n",
      "f_r: [-0.01058483], r: [119.94924], f: [1.2816088e-10]\n",
      "f_r: [-0.01511798], r: [119.52171], f: [0.277532]\n",
      "f_r: [-0.00363307], r: [119.16662], f: [4.1669116e-12]\n",
      "f_r: [0.00037925], r: [119.64032], f: [4.210173e-15]\n",
      "f_r: [-0.00021716], r: [119.05826], f: [6.8138056]\n",
      "f_r: [-0.00204501], r: [119.62937], f: [0.07301252]\n",
      "f_r: [-0.01581284], r: [119.13616], f: [1.2607729e-09]\n",
      "f_r: [-0.00340254], r: [119.89572], f: [0.00036056]\n",
      "f_r: [0.00127091], r: [119.44606], f: [488.86304]\n",
      "f_r: [0.00272505], r: [119.93689], f: [5.132443e-06]\n",
      "f_r: [0.00161835], r: [119.53904], f: [0.9089991]\n",
      "f_r: [-0.00473593], r: [119.87766], f: [0.14979094]\n",
      "f_r: [-0.00122667], r: [119.86257], f: [264.01462]\n",
      "f_r: [-0.00035027], r: [119.3363], f: [362.83615]\n",
      "f_r: [0.00126784], r: [119.33084], f: [0.00013646]\n",
      "f_r: [0.00041121], r: [119.16139], f: [6.8202984e-14]\n",
      "f_r: [0.00036195], r: [119.70903], f: [295.0359]\n",
      "f_r: [-0.00292902], r: [119.56482], f: [0.06442817]\n",
      "f_r: [-0.00946049], r: [119.57098], f: [7.1456125e-09]\n",
      "f_r: [-0.00050121], r: [119.403694], f: [3.4255219]\n",
      "f_r: [0.02093151], r: [119.75631], f: [2.709025e-13]\n",
      "f_r: [0.01776523], r: [119.48889], f: [4.4614377e-13]\n",
      "f_r: [0.00087845], r: [119.808395], f: [4.0588803]\n",
      "f_r: [-0.00029145], r: [119.015564], f: [0.00453847]\n",
      "f_r: [0.00051854], r: [119.015564], f: [2.460881e-13]\n",
      "f_r: [-0.0115661], r: [119.517624], f: [3.8981183e-09]\n",
      "f_r: [0.0002199], r: [119.9703], f: [7.5740404e-06]\n",
      "f_r: [-0.00061257], r: [119.484116], f: [0.00029199]\n",
      "Training loss for epoch 73: pinn: 0.1840, boundary: 10.4476, total: 10.6316\n",
      "f_r: [0.00108201], r: [119.26485], f: [6.833658e-05]\n",
      "f_r: [-0.01559248], r: [119.581924], f: [2.1504554e-09]\n",
      "f_r: [-0.00060673], r: [119.80908], f: [0.4286774]\n",
      "f_r: [0.0010649], r: [119.38638], f: [45.106644]\n",
      "f_r: [0.00295875], r: [119.16094], f: [391.55243]\n",
      "f_r: [0.00490612], r: [119.48525], f: [6.9196176e-15]\n",
      "f_r: [0.00516068], r: [119.68347], f: [1.0945659e-13]\n",
      "f_r: [0.00245635], r: [119.47864], f: [0.00205411]\n",
      "f_r: [-0.00100278], r: [119.925674], f: [50.43544]\n",
      "f_r: [-0.00039153], r: [119.65996], f: [287.21762]\n",
      "f_r: [-0.0010094], r: [119.134346], f: [0.00011676]\n",
      "f_r: [0.00219623], r: [119.4021], f: [3.908259e-12]\n",
      "f_r: [0.01689166], r: [119.80063], f: [0.01010755]\n",
      "f_r: [0.00290899], r: [119.65858], f: [7.623155e-05]\n",
      "f_r: [0.00260624], r: [119.95496], f: [6.142344]\n",
      "f_r: [-0.00014872], r: [119.35815], f: [0.00177861]\n",
      "f_r: [0.00033025], r: [119.94604], f: [5.6048436]\n",
      "f_r: [-0.01115363], r: [119.325836], f: [4.2556e-09]\n",
      "f_r: [-0.01262715], r: [119.03577], f: [2.484927e-09]\n",
      "f_r: [0.0006949], r: [119.54064], f: [0.10015196]\n",
      "f_r: [0.00426832], r: [119.99731], f: [1.2403219e-06]\n",
      "f_r: [-0.00223751], r: [119.83034], f: [2.8860223]\n",
      "f_r: [-0.00124907], r: [119.69625], f: [41.131046]\n",
      "f_r: [-0.00261171], r: [119.34768], f: [7.737032e-12]\n",
      "f_r: [0.00209123], r: [119.379555], f: [4.000628e-12]\n",
      "f_r: [0.00045992], r: [119.57531], f: [0.00020828]\n",
      "f_r: [-7.096126e-05], r: [119.810905], f: [493.99628]\n",
      "f_r: [-0.00019246], r: [119.189354], f: [61.52182]\n",
      "f_r: [-0.00129464], r: [119.59812], f: [3.7652477e-05]\n",
      "f_r: [-0.00116316], r: [119.958626], f: [0.00202999]\n",
      "f_r: [-0.01558277], r: [119.804054], f: [5.558196e-10]\n",
      "f_r: [-0.00107069], r: [119.84153], f: [0.00013908]\n",
      "f_r: [-0.01302781], r: [119.45131], f: [2.5197477e-10]\n",
      "f_r: [-0.00067917], r: [119.35406], f: [0.08803462]\n",
      "f_r: [-0.00720494], r: [119.23369], f: [1.4227839e-11]\n",
      "f_r: [-0.00161716], r: [119.10867], f: [1.3618935e-15]\n",
      "f_r: [0.00794888], r: [119.04553], f: [1.1993768e-07]\n",
      "f_r: [0.00024366], r: [119.35975], f: [48.593513]\n",
      "f_r: [-1.4815716e-05], r: [119.145485], f: [3.876552e-15]\n",
      "f_r: [7.44931e-05], r: [119.227776], f: [1.1467385e-13]\n",
      "Training loss for epoch 74: pinn: 0.1739, boundary: 11.4875, total: 11.6614\n",
      "f_r: [-0.00093113], r: [119.56459], f: [3.0533276]\n",
      "f_r: [0.01521694], r: [119.69921], f: [1.1151149e-11]\n",
      "f_r: [0.00649906], r: [119.5044], f: [0.24434215]\n",
      "f_r: [-0.00694557], r: [119.96183], f: [0.3315834]\n",
      "f_r: [0.013572], r: [119.099815], f: [7.6076976e-13]\n",
      "f_r: [-0.00863476], r: [119.993416], f: [0.00108735]\n",
      "f_r: [-0.00424317], r: [119.16594], f: [1.328471]\n",
      "f_r: [-0.00455721], r: [119.11775], f: [0.03194592]\n",
      "f_r: [-0.00346445], r: [119.16752], f: [3.170594e-08]\n",
      "f_r: [0.00099807], r: [119.388435], f: [157.32292]\n",
      "f_r: [0.00645246], r: [119.81891], f: [3.995839e-12]\n",
      "f_r: [0.00375666], r: [119.39549], f: [376.77914]\n",
      "f_r: [0.00408495], r: [119.6426], f: [274.90067]\n",
      "f_r: [0.00087324], r: [119.20912], f: [1.578075e-14]\n",
      "f_r: [-0.01031882], r: [119.89183], f: [5.814408e-09]\n",
      "f_r: [-0.00321511], r: [119.72136], f: [1.8533225e-05]\n",
      "f_r: [0.00173521], r: [119.22186], f: [0.91694397]\n",
      "f_r: [-0.00191567], r: [119.70332], f: [1.34978745e-05]\n",
      "f_r: [-0.00015988], r: [119.69944], f: [3.1524442e-15]\n",
      "f_r: [0.0009179], r: [119.06597], f: [0.00093788]\n",
      "f_r: [0.00408706], r: [119.60153], f: [6.7239874e-08]\n",
      "f_r: [0.00123516], r: [119.834], f: [201.50232]\n",
      "f_r: [0.00272398], r: [119.96983], f: [1.5360395e-14]\n",
      "f_r: [0.00260932], r: [119.83834], f: [5.9982455e-07]\n",
      "f_r: [0.00089361], r: [119.6036], f: [6.6159706]\n",
      "f_r: [0.01479521], r: [119.67912], f: [2.0079192e-07]\n",
      "f_r: [-0.00059229], r: [119.92363], f: [0.073084]\n",
      "f_r: [-0.01162203], r: [119.857086], f: [2.0158324]\n",
      "f_r: [0.00118972], r: [119.375465], f: [0.00069802]\n",
      "f_r: [-0.00274164], r: [119.3782], f: [2.175582e-11]\n",
      "f_r: [-0.00206716], r: [119.421], f: [0.2388022]\n",
      "f_r: [0.00155457], r: [119.69716], f: [1.0066317e-06]\n",
      "f_r: [0.00098329], r: [119.70104], f: [2.438286e-06]\n",
      "f_r: [-0.001668], r: [119.62778], f: [0.02523795]\n",
      "f_r: [0.00149029], r: [119.64694], f: [7.558871e-12]\n",
      "f_r: [0.0024462], r: [119.52811], f: [6.677242e-14]\n",
      "f_r: [0.00025621], r: [119.32037], f: [0.6084943]\n",
      "f_r: [-0.00358272], r: [119.02487], f: [1.9435353e-08]\n",
      "f_r: [-0.00216616], r: [119.70104], f: [0.34278515]\n",
      "f_r: [-0.00274101], r: [119.50258], f: [5.7710104]\n",
      "Training loss for epoch 75: pinn: 0.1871, boundary: 16.9838, total: 17.1709\n",
      "f_r: [-0.00323075], r: [119.79629], f: [0.00189419]\n",
      "f_r: [0.00444108], r: [119.80177], f: [10.182773]\n",
      "f_r: [0.00547824], r: [119.23255], f: [6.1841496e-14]\n",
      "f_r: [0.02026854], r: [119.30011], f: [4.992345e-07]\n",
      "f_r: [-0.00308945], r: [119.49072], f: [3.9307402e-15]\n",
      "f_r: [-0.00440102], r: [119.698524], f: [2.5174797e-14]\n",
      "f_r: [-0.01284207], r: [119.192535], f: [4.085372e-09]\n",
      "f_r: [-0.00207619], r: [119.10481], f: [0.02022521]\n",
      "f_r: [0.00142283], r: [119.552956], f: [7.430036e-05]\n",
      "f_r: [0.00340145], r: [119.48503], f: [2.6659064]\n",
      "f_r: [0.00395953], r: [119.22391], f: [0.92019874]\n",
      "f_r: [0.00096661], r: [119.39732], f: [123.2655]\n",
      "f_r: [-0.01272562], r: [119.29443], f: [1.5413055e-09]\n",
      "f_r: [-0.00990788], r: [119.04939], f: [6.624993e-09]\n",
      "f_r: [-0.00206858], r: [119.58671], f: [0.01957839]\n",
      "f_r: [0.00349651], r: [119.24415], f: [1.7787013e-12]\n",
      "f_r: [0.00149652], r: [119.82987], f: [1.75909]\n",
      "f_r: [0.00377116], r: [119.81365], f: [7.404311e-14]\n",
      "f_r: [-0.00226132], r: [119.94673], f: [0.52019256]\n",
      "f_r: [-0.00107371], r: [119.16684], f: [0.06791127]\n",
      "f_r: [-1.759934e-05], r: [119.31491], f: [194.09352]\n",
      "f_r: [-0.01037447], r: [119.213005], f: [1.2078415e-08]\n",
      "f_r: [-0.01625506], r: [119.25325], f: [1.1036707e-09]\n",
      "f_r: [-0.01108716], r: [119.90715], f: [2.6318418e-11]\n",
      "f_r: [0.00238405], r: [119.16525], f: [9.279762e-07]\n",
      "f_r: [0.0034666], r: [119.62458], f: [1.0093569e-06]\n",
      "f_r: [-0.00118888], r: [119.98678], f: [3.4690921]\n",
      "f_r: [0.00220537], r: [119.20186], f: [5.250172e-14]\n",
      "f_r: [0.00167243], r: [119.51101], f: [1.7907961e-12]\n",
      "f_r: [0.000744], r: [119.548164], f: [7.7538216e-14]\n",
      "f_r: [-0.00195859], r: [119.518074], f: [0.04548495]\n",
      "f_r: [0.0176105], r: [119.653336], f: [4.812138e-07]\n",
      "f_r: [0.02117855], r: [119.179794], f: [3.0566576e-13]\n",
      "f_r: [-0.00056733], r: [119.70583], f: [0.04706411]\n",
      "f_r: [0.00050368], r: [119.2155], f: [1.4340904e-15]\n",
      "f_r: [-0.01248351], r: [119.49254], f: [4.5011235e-09]\n",
      "f_r: [0.00128151], r: [119.31649], f: [0.00408075]\n",
      "f_r: [-0.01322817], r: [119.95747], f: [1.397255e-10]\n",
      "f_r: [0.00236051], r: [119.8772], f: [2.2331758e-06]\n",
      "f_r: [0.00585298], r: [119.01284], f: [1.6445462e-07]\n",
      "Training loss for epoch 76: pinn: 0.1790, boundary: 12.9155, total: 13.0946\n",
      "f_r: [-0.00880025], r: [119.10958], f: [2.401508e-11]\n",
      "f_r: [0.01211512], r: [119.118904], f: [1.15352286e-07]\n",
      "f_r: [-0.00055382], r: [119.3363], f: [4.7949834]\n",
      "f_r: [0.00116271], r: [119.00308], f: [5.599175]\n",
      "f_r: [-4.563985e-05], r: [119.37568], f: [3.757369e-15]\n",
      "f_r: [-0.00051037], r: [119.536995], f: [439.3476]\n",
      "f_r: [0.00155207], r: [119.200714], f: [10.1022625]\n",
      "f_r: [-0.00051439], r: [119.726616], f: [0.29818684]\n",
      "f_r: [0.00737509], r: [119.05166], f: [1.5247692e-14]\n",
      "f_r: [0.00528013], r: [119.010574], f: [1.1290543e-14]\n",
      "f_r: [-0.00225826], r: [119.42738], f: [0.06941933]\n",
      "f_r: [-0.00088794], r: [119.25939], f: [3.9804854e-06]\n",
      "f_r: [-0.00552241], r: [119.14822], f: [5.6832747e-08]\n",
      "f_r: [0.00027227], r: [119.12708], f: [75.69879]\n",
      "f_r: [-0.00473989], r: [119.82828], f: [0.00099105]\n",
      "f_r: [-0.01232736], r: [119.23687], f: [1.5784414e-08]\n",
      "f_r: [-1.2351919e-05], r: [119.803604], f: [1.03246696e-13]\n",
      "f_r: [0.00750955], r: [119.95405], f: [0.00885727]\n",
      "f_r: [0.00528015], r: [119.028275], f: [0.01062507]\n",
      "f_r: [0.00232646], r: [119.22619], f: [1.8582313e-15]\n",
      "f_r: [-0.0100871], r: [119.93255], f: [0.474733]\n",
      "f_r: [0.00894566], r: [119.022156], f: [3.711712e-07]\n",
      "f_r: [-0.00170901], r: [119.74922], f: [0.5946264]\n",
      "f_r: [0.00208902], r: [119.31149], f: [7.380689e-15]\n",
      "f_r: [-0.00043514], r: [119.73643], f: [0.5351042]\n",
      "f_r: [-0.00020992], r: [119.58374], f: [0.0021268]\n",
      "f_r: [-0.0011757], r: [119.681175], f: [24.143444]\n",
      "f_r: [-0.00195967], r: [119.36613], f: [0.0460581]\n",
      "f_r: [-0.00726911], r: [119.24097], f: [1.1590845e-08]\n",
      "f_r: [0.00038035], r: [119.20799], f: [0.00193663]\n",
      "f_r: [0.00139756], r: [119.65517], f: [4.617729e-12]\n",
      "f_r: [0.0010792], r: [119.72273], f: [3.169762e-14]\n",
      "f_r: [-0.00017058], r: [119.00127], f: [79.422035]\n",
      "f_r: [0.00163766], r: [119.20594], f: [8.830924e-06]\n",
      "f_r: [0.00738668], r: [119.48799], f: [3.2514725e-07]\n",
      "f_r: [-0.00237365], r: [119.87834], f: [8.60044e-08]\n",
      "f_r: [2.810564e-05], r: [119.78075], f: [8.170208e-15]\n",
      "f_r: [0.00045677], r: [119.61476], f: [58.739758]\n",
      "f_r: [-5.4545617e-05], r: [119.367485], f: [6.0247955]\n",
      "f_r: [-0.00193826], r: [119.42897], f: [0.02136347]\n",
      "Training loss for epoch 77: pinn: 0.1768, boundary: 8.1660, total: 8.3428\n",
      "f_r: [-0.01123286], r: [119.89709], f: [1.4536332e-10]\n",
      "f_r: [-0.05133571], r: [119.23392], f: [0.19284339]\n",
      "f_r: [-0.00593017], r: [119.07801], f: [0.09140555]\n",
      "f_r: [-0.00399442], r: [119.26826], f: [0.00106439]\n",
      "f_r: [0.02279754], r: [119.16366], f: [4.891069e-13]\n",
      "f_r: [0.00413351], r: [119.48365], f: [0.12830427]\n",
      "f_r: [0.00601531], r: [119.46178], f: [5.4213426e-12]\n",
      "f_r: [0.00124992], r: [119.602], f: [0.5081139]\n",
      "f_r: [0.00337738], r: [119.23482], f: [2.413147e-06]\n",
      "f_r: [0.00285547], r: [119.9385], f: [2.8489294e-12]\n",
      "f_r: [0.00407783], r: [119.79103], f: [1.3952532e-05]\n",
      "f_r: [-0.00076129], r: [119.83102], f: [59.735455]\n",
      "f_r: [0.00067324], r: [119.227776], f: [3.0514355e-11]\n",
      "f_r: [0.00032239], r: [119.21027], f: [34.571316]\n",
      "f_r: [0.02001171], r: [119.523315], f: [0.0079537]\n",
      "f_r: [0.00230153], r: [119.45745], f: [0.73206836]\n",
      "f_r: [-0.01202051], r: [119.907845], f: [2.6024332e-09]\n",
      "f_r: [-3.0017605e-05], r: [119.42031], f: [3.974663e-06]\n",
      "f_r: [-0.00025194], r: [119.85204], f: [48.324284]\n",
      "f_r: [-0.00117724], r: [119.792625], f: [9.577406e-12]\n",
      "f_r: [-0.00254857], r: [119.40506], f: [6.317265e-08]\n",
      "f_r: [0.00241157], r: [119.39231], f: [0.01435161]\n",
      "f_r: [0.00013924], r: [119.65287], f: [1.8738208e-05]\n",
      "f_r: [-0.01324868], r: [119.9465], f: [1.2905876e-09]\n",
      "f_r: [0.00245459], r: [119.41758], f: [6.9738073]\n",
      "f_r: [2.6950094e-05], r: [119.61227], f: [185.50247]\n",
      "f_r: [0.00083588], r: [119.41052], f: [0.00579887]\n",
      "f_r: [-0.00918965], r: [119.69214], f: [1.0876458e-10]\n",
      "f_r: [0.00374715], r: [119.56345], f: [8.630924]\n",
      "f_r: [-0.00076449], r: [119.476364], f: [0.50645447]\n",
      "f_r: [0.00020334], r: [119.64694], f: [206.55376]\n",
      "f_r: [0.00322705], r: [119.96411], f: [8.765302]\n",
      "f_r: [-0.00206003], r: [119.790794], f: [0.028088]\n",
      "f_r: [-0.00668425], r: [119.42602], f: [3.7213167e-11]\n",
      "f_r: [-2.9402436e-05], r: [119.03872], f: [3.2964058]\n",
      "f_r: [-0.0033202], r: [119.68688], f: [20.037462]\n",
      "f_r: [0.00074218], r: [119.26667], f: [1.319882]\n",
      "f_r: [-0.00084381], r: [119.60976], f: [5.2510123]\n",
      "f_r: [-0.00162437], r: [119.33153], f: [6.1396813]\n",
      "f_r: [0.00797369], r: [119.323555], f: [3.4675872e-07]\n",
      "Training loss for epoch 78: pinn: 0.1602, boundary: 10.3629, total: 10.5231\n",
      "f_r: [0.00208991], r: [119.3684], f: [0.08925395]\n",
      "f_r: [-0.00778972], r: [119.41668], f: [6.3251354e-16]\n",
      "f_r: [-0.00469814], r: [119.71429], f: [2.4314626e-05]\n",
      "f_r: [0.00076861], r: [119.698524], f: [7.245256]\n",
      "f_r: [0.00381295], r: [119.70013], f: [5.480162e-13]\n",
      "f_r: [0.00384038], r: [119.46566], f: [18.372988]\n",
      "f_r: [0.00241892], r: [119.19708], f: [0.59361976]\n",
      "f_r: [-0.00466945], r: [119.01716], f: [8.353729e-10]\n",
      "f_r: [0.0018007], r: [119.698074], f: [0.00022638]\n",
      "f_r: [-0.0040045], r: [119.13163], f: [2.1013311e-11]\n",
      "f_r: [-9.038602e-05], r: [119.61842], f: [1.0790275e-06]\n",
      "f_r: [-0.00364823], r: [119.57303], f: [4.2444223e-16]\n",
      "f_r: [0.00169645], r: [119.726616], f: [4.453643e-12]\n",
      "f_r: [0.00167922], r: [119.83536], f: [5.0999042e-06]\n",
      "f_r: [0.00088296], r: [119.95565], f: [0.00048482]\n",
      "f_r: [-0.00215288], r: [119.29716], f: [1.2252918e-10]\n",
      "f_r: [-0.00027368], r: [119.02419], f: [0.23414838]\n",
      "f_r: [0.00158477], r: [119.71132], f: [0.00083195]\n",
      "f_r: [0.00130539], r: [119.49392], f: [0.54515773]\n",
      "f_r: [0.00021845], r: [119.78441], f: [1.0127301e-11]\n",
      "f_r: [-0.0021611], r: [119.89434], f: [21.618753]\n",
      "f_r: [-0.002235], r: [119.37865], f: [1.8790324]\n",
      "f_r: [-0.00714964], r: [119.28055], f: [1.13276135e-08]\n",
      "f_r: [-0.00762327], r: [119.14799], f: [2.1942348]\n",
      "f_r: [0.00037815], r: [119.11754], f: [719.64996]\n",
      "f_r: [0.00098413], r: [119.47182], f: [604.57587]\n",
      "f_r: [0.00112047], r: [119.5541], f: [337.10437]\n",
      "f_r: [0.00039597], r: [119.29738], f: [66.779396]\n",
      "f_r: [0.00465495], r: [119.667946], f: [0.00779219]\n",
      "f_r: [0.00043626], r: [119.27258], f: [7.8520625e-14]\n",
      "f_r: [0.00648063], r: [119.9131], f: [0.00845811]\n",
      "f_r: [0.00113373], r: [119.636894], f: [1.6033942]\n",
      "f_r: [0.00144046], r: [119.02464], f: [2.4684055e-05]\n",
      "f_r: [0.00063431], r: [119.339485], f: [7.400841e-13]\n",
      "f_r: [0.00108995], r: [119.988144], f: [1.2474802]\n",
      "f_r: [-0.00340828], r: [119.216866], f: [0.10041367]\n",
      "f_r: [0.00249688], r: [119.79903], f: [2.2314543e-07]\n",
      "f_r: [0.00039076], r: [119.743965], f: [244.38875]\n",
      "f_r: [0.00075947], r: [119.142075], f: [0.51985145]\n",
      "f_r: [-0.00871578], r: [119.21709], f: [3.138876e-09]\n",
      "Training loss for epoch 79: pinn: 0.1466, boundary: 14.1300, total: 14.2766\n",
      "f_r: [3.5690584e-05], r: [119.670906], f: [2.0073866e-13]\n",
      "f_r: [0.01532678], r: [119.977615], f: [1.5678825e-06]\n",
      "f_r: [0.00239155], r: [119.48297], f: [6.81477e-11]\n",
      "f_r: [-0.00356526], r: [119.10481], f: [0.6256206]\n",
      "f_r: [-0.00089027], r: [119.961365], f: [215.57237]\n",
      "f_r: [-0.0055702], r: [119.07346], f: [6.7684578e-06]\n",
      "f_r: [-0.00139379], r: [119.01784], f: [67.79974]\n",
      "f_r: [-0.00802728], r: [119.09027], f: [2.2765444e-11]\n",
      "f_r: [0.00342142], r: [119.6579], f: [0.00987332]\n",
      "f_r: [0.01453232], r: [119.962746], f: [2.4942064e-12]\n",
      "f_r: [0.0030954], r: [119.20549], f: [0.00324892]\n",
      "f_r: [0.00075213], r: [119.14754], f: [101.73527]\n",
      "f_r: [0.00497658], r: [119.539955], f: [1.6725063e-13]\n",
      "f_r: [0.0023098], r: [119.05439], f: [0.00080011]\n",
      "f_r: [-0.00848365], r: [119.88681], f: [0.3408597]\n",
      "f_r: [0.00179384], r: [119.64284], f: [5.893271e-06]\n",
      "f_r: [0.00173084], r: [119.89778], f: [7.5797415]\n",
      "f_r: [-0.00526151], r: [119.868965], f: [8.71614e-11]\n",
      "f_r: [0.01624892], r: [119.79857], f: [0.00645006]\n",
      "f_r: [0.00320924], r: [119.09027], f: [2.0780264e-15]\n",
      "f_r: [-0.00202952], r: [119.26212], f: [0.02980181]\n",
      "f_r: [-0.00441573], r: [119.85204], f: [7.048147e-11]\n",
      "f_r: [0.00757644], r: [119.06144], f: [2.2302422e-12]\n",
      "f_r: [-0.00472281], r: [119.65287], f: [18.890898]\n",
      "f_r: [-0.00142684], r: [119.82783], f: [4.70949e-15]\n",
      "f_r: [0.00246316], r: [119.65311], f: [0.07723726]\n",
      "f_r: [0.0007158], r: [119.658356], f: [336.6692]\n",
      "f_r: [-0.0025833], r: [119.58671], f: [0.5144037]\n",
      "f_r: [-0.00053317], r: [119.32174], f: [0.00095868]\n",
      "f_r: [0.00116973], r: [119.241875], f: [0.7748063]\n",
      "f_r: [-0.00564565], r: [119.29443], f: [5.05425e-08]\n",
      "f_r: [-0.00037735], r: [119.79126], f: [14.956027]\n",
      "f_r: [0.00112308], r: [119.69145], f: [0.6123625]\n",
      "f_r: [-0.00788085], r: [119.74809], f: [8.7062585e-10]\n",
      "f_r: [0.00252731], r: [119.63165], f: [3.0165012e-07]\n",
      "f_r: [0.00156433], r: [119.54087], f: [2.6359416e-07]\n",
      "f_r: [-0.00016068], r: [119.87675], f: [53.940117]\n",
      "f_r: [-0.00179456], r: [119.50258], f: [0.00015693]\n",
      "f_r: [-0.01043608], r: [119.06189], f: [4.11163e-09]\n",
      "f_r: [0.00018549], r: [119.74237], f: [6.659898e-05]\n",
      "Training loss for epoch 80: pinn: 0.1483, boundary: 12.6286, total: 12.7769\n",
      "f_r: [0.00179992], r: [119.40893], f: [0.0141197]\n",
      "f_r: [-0.00613765], r: [119.39596], f: [0.00156981]\n",
      "f_r: [-0.00615572], r: [119.1064], f: [0.14264324]\n",
      "f_r: [6.3171545e-05], r: [119.54247], f: [3.480995]\n",
      "f_r: [0.00364895], r: [119.920876], f: [1.10637255e-13]\n",
      "f_r: [0.00080442], r: [119.27941], f: [0.08339447]\n",
      "f_r: [0.0046182], r: [119.467255], f: [1.0364431]\n",
      "f_r: [0.00411908], r: [119.19958], f: [2.7985594e-14]\n",
      "f_r: [0.00185113], r: [119.75265], f: [7.9579346e-05]\n",
      "f_r: [-0.00155068], r: [119.43831], f: [0.00164578]\n",
      "f_r: [-0.00305292], r: [119.34699], f: [0.08337694]\n",
      "f_r: [0.00036611], r: [119.193665], f: [258.8575]\n",
      "f_r: [0.00108695], r: [119.15093], f: [158.21129]\n",
      "f_r: [0.00164853], r: [119.42487], f: [7.544459e-05]\n",
      "f_r: [-0.00077826], r: [119.27737], f: [0.02612023]\n",
      "f_r: [0.00086739], r: [119.088455], f: [129.94995]\n",
      "f_r: [-0.00308841], r: [119.311264], f: [0.03302667]\n",
      "f_r: [0.00039269], r: [119.892746], f: [4.250095e-15]\n",
      "f_r: [-0.01096779], r: [119.375465], f: [4.94425e-10]\n",
      "f_r: [0.00060968], r: [119.79812], f: [0.57130593]\n",
      "f_r: [-0.00114693], r: [119.45084], f: [37.378944]\n",
      "f_r: [-0.00054908], r: [119.361115], f: [0.00107503]\n",
      "f_r: [0.00141996], r: [119.18662], f: [2.0488524e-05]\n",
      "f_r: [-0.0019882], r: [119.54064], f: [0.02155302]\n",
      "f_r: [0.00057437], r: [119.13184], f: [187.09846]\n",
      "f_r: [-0.00069516], r: [119.25961], f: [0.5129771]\n",
      "f_r: [-0.00079402], r: [119.91744], f: [2.5080473e-05]\n",
      "f_r: [0.00131922], r: [119.60063], f: [0.7189777]\n",
      "f_r: [0.00124373], r: [119.3256], f: [5.1125464]\n",
      "f_r: [0.0016321], r: [119.51671], f: [0.0146424]\n",
      "f_r: [-0.00805035], r: [119.388885], f: [7.8664997e-10]\n",
      "f_r: [-6.183888e-05], r: [119.6757], f: [511.80496]\n",
      "f_r: [0.00182373], r: [119.95337], f: [0.68116003]\n",
      "f_r: [0.00125404], r: [119.39572], f: [4.144112e-14]\n",
      "f_r: [0.0042361], r: [119.05326], f: [5.9565426e-12]\n",
      "f_r: [-0.0018642], r: [119.342896], f: [2.3668975e-11]\n",
      "f_r: [0.01295869], r: [119.38365], f: [1.8943952e-06]\n",
      "f_r: [0.00877589], r: [119.81023], f: [2.810432e-12]\n",
      "f_r: [0.0049257], r: [119.146385], f: [4.7439184e-12]\n",
      "f_r: [-0.00914693], r: [119.34586], f: [4.2903983e-10]\n",
      "Training loss for epoch 81: pinn: 0.1383, boundary: 9.5606, total: 9.6989\n",
      "f_r: [-0.00754583], r: [119.76521], f: [6.120789e-08]\n",
      "f_r: [0.0061444], r: [119.25961], f: [5.1078e-13]\n",
      "f_r: [0.00063477], r: [119.29942], f: [3.0762723e-07]\n",
      "f_r: [0.00198918], r: [119.78988], f: [3.4985856e-05]\n",
      "f_r: [-0.00265047], r: [119.39732], f: [0.00058278]\n",
      "f_r: [-0.0125368], r: [119.30352], f: [1.5084267e-09]\n",
      "f_r: [-0.00118861], r: [119.76385], f: [5.892255e-13]\n",
      "f_r: [-0.00808153], r: [119.40734], f: [2.6838004e-08]\n",
      "f_r: [-0.00400041], r: [119.91585], f: [3.4814801]\n",
      "f_r: [8.803829e-05], r: [119.40803], f: [0.63416857]\n",
      "f_r: [0.00065746], r: [119.769554], f: [51.779957]\n",
      "f_r: [-0.01117174], r: [119.99524], f: [3.9106268e-10]\n",
      "f_r: [-0.00101091], r: [119.4652], f: [3.629003e-05]\n",
      "f_r: [-0.00020517], r: [119.855705], f: [172.837]\n",
      "f_r: [0.00241947], r: [119.74969], f: [9.962419e-05]\n",
      "f_r: [0.0050631], r: [119.115036], f: [4.6417845e-06]\n",
      "f_r: [0.00013167], r: [119.963196], f: [101.15605]\n",
      "f_r: [-0.00043525], r: [119.060074], f: [50.3483]\n",
      "f_r: [-0.00848682], r: [119.82394], f: [2.1544129e-09]\n",
      "f_r: [0.01596914], r: [119.15571], f: [7.1975086e-13]\n",
      "f_r: [0.00044371], r: [119.05961], f: [1.5505623e-15]\n",
      "f_r: [0.00123602], r: [119.757225], f: [4.3000684e-05]\n",
      "f_r: [0.00111725], r: [119.60291], f: [1.3110248e-15]\n",
      "f_r: [0.00143327], r: [119.66976], f: [1.4703296]\n",
      "f_r: [-0.00044213], r: [119.868744], f: [2.8696284e-14]\n",
      "f_r: [0.01271567], r: [119.99707], f: [9.849712e-13]\n",
      "f_r: [0.00053272], r: [119.093], f: [1.35057935e-05]\n",
      "f_r: [0.00011554], r: [119.875595], f: [0.00242253]\n",
      "f_r: [0.00154249], r: [119.57758], f: [9.817484e-14]\n",
      "f_r: [-0.00027001], r: [119.991585], f: [96.204704]\n",
      "f_r: [-0.00820182], r: [119.363396], f: [2.1924269e-08]\n",
      "f_r: [0.01209304], r: [119.27941], f: [1.313823e-12]\n",
      "f_r: [0.00028592], r: [119.03419], f: [149.3348]\n",
      "f_r: [0.00139165], r: [119.74443], f: [1.5191147]\n",
      "f_r: [0.00133114], r: [119.43421], f: [4.6581877e-06]\n",
      "f_r: [0.0016851], r: [119.99639], f: [0.9549137]\n",
      "f_r: [-0.00022737], r: [119.858], f: [4.245608e-05]\n",
      "f_r: [0.00203821], r: [119.35292], f: [4.4978495e-07]\n",
      "f_r: [0.00077185], r: [119.67457], f: [431.08536]\n",
      "f_r: [0.00161149], r: [119.78624], f: [0.9224022]\n",
      "Training loss for epoch 82: pinn: 0.1321, boundary: 8.3758, total: 8.5079\n",
      "f_r: [0.0002219], r: [119.50485], f: [1.948753e-13]\n",
      "f_r: [0.00268335], r: [119.496414], f: [0.41823944]\n",
      "f_r: [0.00695908], r: [119.56824], f: [1.3403661e-06]\n",
      "f_r: [0.00197829], r: [119.93482], f: [0.57840717]\n",
      "f_r: [-0.00218599], r: [119.662], f: [5.4207572e-05]\n",
      "f_r: [0.00361704], r: [119.22641], f: [0.00444357]\n",
      "f_r: [-0.00283737], r: [119.64671], f: [1.1346452e-11]\n",
      "f_r: [0.00143026], r: [119.49985], f: [0.00817701]\n",
      "f_r: [-0.0069685], r: [119.79697], f: [2.7077016e-10]\n",
      "f_r: [-0.00024477], r: [119.694885], f: [5.1295395]\n",
      "f_r: [-0.00662847], r: [119.42897], f: [2.743944e-10]\n",
      "f_r: [-0.00950824], r: [119.697845], f: [1.2877924e-08]\n",
      "f_r: [-0.00480507], r: [119.62413], f: [2.3365308e-11]\n",
      "f_r: [0.00052957], r: [119.93895], f: [598.74506]\n",
      "f_r: [6.0617116e-05], r: [119.76065], f: [2.942508]\n",
      "f_r: [-0.01005912], r: [119.537224], f: [0.38434887]\n",
      "f_r: [0.00147561], r: [119.18662], f: [4.5515034e-14]\n",
      "f_r: [0.0007696], r: [119.01511], f: [107.59937]\n",
      "f_r: [0.0069306], r: [119.44948], f: [1.20355306e-11]\n",
      "f_r: [-0.00408054], r: [119.181625], f: [7.4733664e-10]\n",
      "f_r: [-0.00185048], r: [119.44948], f: [0.03073731]\n",
      "f_r: [0.00374706], r: [119.28055], f: [3.318508e-13]\n",
      "f_r: [-0.00157694], r: [119.5443], f: [1.972633e-07]\n",
      "f_r: [-0.00784988], r: [119.00127], f: [1.878497e-08]\n",
      "f_r: [0.00114169], r: [119.32925], f: [6.9157286e-14]\n",
      "f_r: [0.00187975], r: [119.509415], f: [4.2530595e-13]\n",
      "f_r: [-0.007985], r: [119.3413], f: [1.0409301e-09]\n",
      "f_r: [0.000744], r: [119.46702], f: [44.110123]\n",
      "f_r: [0.00156121], r: [119.91334], f: [13.685362]\n",
      "f_r: [-0.00840906], r: [119.868515], f: [2.238976e-08]\n",
      "f_r: [0.00065931], r: [119.35655], f: [8.042194e-14]\n",
      "f_r: [-0.00224681], r: [119.25688], f: [2.0614053e-07]\n",
      "f_r: [0.00191726], r: [119.43741], f: [0.6703126]\n",
      "f_r: [0.0016389], r: [119.46406], f: [2.4804017e-15]\n",
      "f_r: [0.00071281], r: [119.64056], f: [9.547228e-14]\n",
      "f_r: [-0.00260837], r: [119.69145], f: [6.902548]\n",
      "f_r: [0.01083148], r: [119.74237], f: [1.2451132e-12]\n",
      "f_r: [-0.00359511], r: [119.85], f: [2.457303e-07]\n",
      "f_r: [-0.00201002], r: [119.040764], f: [0.10443424]\n",
      "f_r: [0.00105575], r: [119.82783], f: [1.0222336e-11]\n",
      "Training loss for epoch 83: pinn: 0.1372, boundary: 10.5238, total: 10.6610\n",
      "f_r: [-2.8978888e-05], r: [119.88268], f: [1.2843977e-15]\n",
      "f_r: [0.00177575], r: [119.89138], f: [49.1531]\n",
      "f_r: [0.00193078], r: [119.39208], f: [582.62164]\n",
      "f_r: [0.0005236], r: [119.21232], f: [79.86195]\n",
      "f_r: [-0.00333937], r: [119.9003], f: [8.2079797e-14]\n",
      "f_r: [-0.00159758], r: [119.92774], f: [44.87756]\n",
      "f_r: [0.00046267], r: [119.83696], f: [2.7105065e-05]\n",
      "f_r: [-0.00082088], r: [119.27668], f: [72.8787]\n",
      "f_r: [0.00219593], r: [119.59013], f: [5.043217e-07]\n",
      "f_r: [0.00368644], r: [119.85068], f: [2.610158e-13]\n",
      "f_r: [0.00105853], r: [120.000046], f: [244.93439]\n",
      "f_r: [0.00253459], r: [119.39253], f: [2.5231033e-11]\n",
      "f_r: [-0.00132666], r: [119.35406], f: [3.138343e-13]\n",
      "f_r: [-0.00978049], r: [119.01306], f: [8.099512e-09]\n",
      "f_r: [4.9234273e-05], r: [119.78806], f: [242.12653]\n",
      "f_r: [-0.00017639], r: [119.536995], f: [8.3879495e-05]\n",
      "f_r: [-0.00220537], r: [119.77002], f: [8.05359]\n",
      "f_r: [0.00046178], r: [119.122986], f: [469.52518]\n",
      "f_r: [-0.00556549], r: [119.81388], f: [8.917624e-09]\n",
      "f_r: [-0.00511572], r: [119.78669], f: [1.1905426e-09]\n",
      "f_r: [0.00162698], r: [119.057106], f: [8.10801e-06]\n",
      "f_r: [0.0005641], r: [119.53107], f: [3.227763]\n",
      "f_r: [-0.00936395], r: [119.73027], f: [1.4954895e-09]\n",
      "f_r: [-0.00298174], r: [119.391624], f: [15.354855]\n",
      "f_r: [-0.001016], r: [119.093], f: [0.00264595]\n",
      "f_r: [0.00110152], r: [119.94284], f: [1.2224484e-14]\n",
      "f_r: [0.00579702], r: [119.01579], f: [1.11702435e-11]\n",
      "f_r: [-0.00811617], r: [119.32174], f: [1.686101e-08]\n",
      "f_r: [-0.00102552], r: [119.773445], f: [16.430342]\n",
      "f_r: [-0.00146957], r: [119.41144], f: [0.00250468]\n",
      "f_r: [0.00211087], r: [119.28464], f: [0.0082754]\n",
      "f_r: [0.0007278], r: [119.34199], f: [0.00016781]\n",
      "f_r: [-0.00494165], r: [119.87149], f: [2.8035524e-08]\n",
      "f_r: [-0.00025884], r: [119.18071], f: [55.77752]\n",
      "f_r: [0.00272421], r: [119.63987], f: [0.00053705]\n",
      "f_r: [0.00244824], r: [119.11004], f: [6.0619356e-14]\n",
      "f_r: [0.00093669], r: [119.93072], f: [2.4111506e-15]\n",
      "f_r: [0.00097257], r: [119.64147], f: [0.36019668]\n",
      "f_r: [0.00070971], r: [119.70812], f: [1.3107444e-12]\n",
      "f_r: [0.00197606], r: [119.45062], f: [1.1800681]\n",
      "Training loss for epoch 84: pinn: 0.1227, boundary: 11.2546, total: 11.3773\n",
      "f_r: [0.00062207], r: [119.909676], f: [188.2652]\n",
      "f_r: [-0.00184415], r: [119.728676], f: [50.602016]\n",
      "f_r: [0.0083311], r: [119.5573], f: [1.1193656e-12]\n",
      "f_r: [-0.0049262], r: [119.388664], f: [1.5352252]\n",
      "f_r: [-0.00182614], r: [119.2744], f: [0.2733986]\n",
      "f_r: [0.00426168], r: [119.961136], f: [0.00025751]\n",
      "f_r: [0.00438997], r: [119.189354], f: [1.8506717e-12]\n",
      "f_r: [0.00169775], r: [119.724785], f: [15.600876]\n",
      "f_r: [-0.0040282], r: [119.96594], f: [1.2896575e-07]\n",
      "f_r: [-0.00017607], r: [119.25712], f: [128.46593]\n",
      "f_r: [0.00133583], r: [119.872856], f: [6.472497]\n",
      "f_r: [0.00224056], r: [119.06665], f: [0.7522054]\n",
      "f_r: [-0.00684197], r: [119.61431], f: [1.415359e-08]\n",
      "f_r: [0.00023086], r: [119.93895], f: [46.438587]\n",
      "f_r: [0.00197346], r: [119.51579], f: [7.7411134e-14]\n",
      "f_r: [-0.00413204], r: [119.15025], f: [1.9097446e-10]\n",
      "f_r: [0.00029204], r: [119.84405], f: [6.201135e-14]\n",
      "f_r: [0.00024744], r: [119.56961], f: [7.415939e-15]\n",
      "f_r: [0.00507338], r: [119.417816], f: [1.7208524e-06]\n",
      "f_r: [6.382117e-05], r: [119.91768], f: [15.34774]\n",
      "f_r: [-0.00060353], r: [119.0344], f: [0.19765127]\n",
      "f_r: [0.0001984], r: [119.475], f: [3.385477e-13]\n",
      "f_r: [0.0020772], r: [119.20709], f: [7.626597e-06]\n",
      "f_r: [-0.00075854], r: [119.7241], f: [21.610628]\n",
      "f_r: [0.00092506], r: [119.167755], f: [3.5080636e-11]\n",
      "f_r: [-0.00690604], r: [119.74969], f: [6.7474915e-10]\n",
      "f_r: [-0.0009166], r: [119.3791], f: [0.00058197]\n",
      "f_r: [-0.00073415], r: [119.52811], f: [2.3158924e-13]\n",
      "f_r: [-0.001628], r: [119.64739], f: [2.429312]\n",
      "f_r: [-0.00096403], r: [119.55752], f: [0.00061973]\n",
      "f_r: [-0.00068886], r: [119.38479], f: [0.00020323]\n",
      "f_r: [-0.00144924], r: [119.47386], f: [6.651563e-11]\n",
      "f_r: [-9.139816e-05], r: [119.13708], f: [53.71102]\n",
      "f_r: [0.00063473], r: [119.5345], f: [2.4363558e-14]\n",
      "f_r: [0.00050012], r: [119.493004], f: [0.00103506]\n",
      "f_r: [0.00043198], r: [119.453804], f: [8.160338e-14]\n",
      "f_r: [0.0043577], r: [119.0285], f: [0.20811924]\n",
      "f_r: [-0.00420484], r: [119.91402], f: [1.2969369e-07]\n",
      "f_r: [0.00031435], r: [119.34381], f: [194.37962]\n",
      "f_r: [0.00107213], r: [119.512375], f: [6.879929e-05]\n",
      "Training loss for epoch 85: pinn: 0.1145, boundary: 6.7004, total: 6.8149\n",
      "f_r: [-0.00525604], r: [119.68232], f: [8.01108e-08]\n",
      "f_r: [-0.00115399], r: [119.79584], f: [128.78836]\n",
      "f_r: [-0.00450778], r: [119.2553], f: [2.3842722e-07]\n",
      "f_r: [9.599404e-05], r: [119.66497], f: [3.7127154]\n",
      "f_r: [-0.00452244], r: [119.66155], f: [9.491801e-09]\n",
      "f_r: [0.00257043], r: [119.55752], f: [0.02383836]\n",
      "f_r: [-0.00393704], r: [119.633484], f: [5.065462e-09]\n",
      "f_r: [0.00145762], r: [119.69876], f: [0.00028225]\n",
      "f_r: [-0.00021038], r: [119.11867], f: [356.3535]\n",
      "f_r: [1.2041499e-05], r: [119.277596], f: [0.00928804]\n",
      "f_r: [0.01384883], r: [119.01693], f: [2.691859e-12]\n",
      "f_r: [-0.00045915], r: [119.25712], f: [0.4573181]\n",
      "f_r: [0.0017644], r: [119.868744], f: [1.2652482e-10]\n",
      "f_r: [-0.00064575], r: [119.168434], f: [4.3174907e-07]\n",
      "f_r: [0.0005931], r: [119.20049], f: [0.00016616]\n",
      "f_r: [-0.00169335], r: [119.78258], f: [0.00089981]\n",
      "f_r: [-1.04725e-05], r: [119.520355], f: [310.09476]\n",
      "f_r: [7.000226e-05], r: [119.57211], f: [571.4047]\n",
      "f_r: [-0.00348908], r: [119.56755], f: [0.00021079]\n",
      "f_r: [-0.00239799], r: [119.69899], f: [5.209631e-11]\n",
      "f_r: [-0.00062714], r: [119.10095], f: [8.52786e-07]\n",
      "f_r: [-0.00182129], r: [119.74694], f: [0.0148964]\n",
      "f_r: [-0.00290268], r: [119.12185], f: [2.8190356e-10]\n",
      "f_r: [-0.00095861], r: [119.55866], f: [320.94806]\n",
      "f_r: [-0.00010759], r: [119.787834], f: [0.0002054]\n",
      "f_r: [-0.00093317], r: [119.49916], f: [0.00265682]\n",
      "f_r: [0.00060383], r: [119.57531], f: [8.707598e-15]\n",
      "f_r: [0.00024213], r: [119.47203], f: [0.01411786]\n",
      "f_r: [0.00047533], r: [119.11844], f: [1.005552e-12]\n",
      "f_r: [-0.00018416], r: [119.597206], f: [0.00096041]\n",
      "f_r: [7.012894e-05], r: [119.607475], f: [475.27005]\n",
      "f_r: [0.00256725], r: [119.853874], f: [0.05882277]\n",
      "f_r: [0.00291049], r: [119.680725], f: [1.4341108e-06]\n",
      "f_r: [-0.00386149], r: [119.05529], f: [2.1787235e-07]\n",
      "f_r: [0.0021024], r: [119.241196], f: [1.0498062]\n",
      "f_r: [-0.00011004], r: [119.26826], f: [14.018535]\n",
      "f_r: [-0.00256909], r: [119.38479], f: [0.02997571]\n",
      "f_r: [0.00790744], r: [119.5436], f: [3.3824072e-06]\n",
      "f_r: [0.0015944], r: [119.79401], f: [1.2862025e-05]\n",
      "f_r: [-0.00540148], r: [119.69008], f: [1.0466419e-09]\n",
      "Training loss for epoch 86: pinn: 0.1182, boundary: 8.5505, total: 8.6687\n",
      "f_r: [0.00075623], r: [119.278046], f: [4.859053]\n",
      "f_r: [-0.00597261], r: [119.72114], f: [9.248802e-13]\n",
      "f_r: [-0.00185231], r: [119.54588], f: [0.43009275]\n",
      "f_r: [-0.00682082], r: [119.5883], f: [2.2556499e-08]\n",
      "f_r: [0.00249457], r: [119.06983], f: [13.417762]\n",
      "f_r: [0.00045782], r: [119.50303], f: [0.28318986]\n",
      "f_r: [0.00200817], r: [119.68643], f: [6.4943356e-10]\n",
      "f_r: [-0.00339574], r: [119.09777], f: [23.488754]\n",
      "f_r: [-0.00010516], r: [119.7522], f: [29.892727]\n",
      "f_r: [0.00082184], r: [119.70127], f: [0.65581197]\n",
      "f_r: [-0.00112124], r: [119.38092], f: [0.10480607]\n",
      "f_r: [-0.00431043], r: [119.95839], f: [0.00786853]\n",
      "f_r: [-0.00090841], r: [119.00082], f: [2.3856447]\n",
      "f_r: [-0.00938482], r: [119.0419], f: [2.6528608e-09]\n",
      "f_r: [-0.00701921], r: [119.255066], f: [5.7604762e-08]\n",
      "f_r: [0.00195416], r: [119.11367], f: [5.872637e-11]\n",
      "f_r: [0.00133425], r: [119.17571], f: [9.398394e-07]\n",
      "f_r: [-0.00423145], r: [119.36634], f: [1.1740947e-08]\n",
      "f_r: [0.00314407], r: [119.25598], f: [1.0506825e-12]\n",
      "f_r: [0.00124983], r: [119.88062], f: [219.84566]\n",
      "f_r: [0.00491081], r: [119.28304], f: [2.0506927e-06]\n",
      "f_r: [7.314409e-05], r: [119.40506], f: [1.5288916e-12]\n",
      "f_r: [3.3794848e-05], r: [119.99684], f: [8.8127373e-13]\n",
      "f_r: [-0.00052835], r: [119.44424], f: [4.478641]\n",
      "f_r: [0.00132745], r: [119.274185], f: [0.0001351]\n",
      "f_r: [-0.0034171], r: [119.076645], f: [3.3687173e-09]\n",
      "f_r: [0.00263255], r: [119.46702], f: [0.00223555]\n",
      "f_r: [0.00044227], r: [119.08982], f: [100.31655]\n",
      "f_r: [-0.00033862], r: [119.795135], f: [24.07364]\n",
      "f_r: [-0.001468], r: [119.92614], f: [0.01470888]\n",
      "f_r: [-0.00504623], r: [119.182076], f: [1.4395748e-07]\n",
      "f_r: [-0.00080128], r: [119.35361], f: [5.321308e-14]\n",
      "f_r: [-0.00023478], r: [119.87903], f: [1.6582916e-13]\n",
      "f_r: [-0.00411314], r: [119.38069], f: [9.0232877e-10]\n",
      "f_r: [-0.00164972], r: [119.02238], f: [3.0178376e-10]\n",
      "f_r: [-0.00147777], r: [119.82851], f: [5.754659e-07]\n",
      "f_r: [0.00194601], r: [119.874916], f: [0.5194847]\n",
      "f_r: [-0.0013451], r: [119.274635], f: [7.4556806e-07]\n",
      "f_r: [-0.00118879], r: [119.98014], f: [21.372803]\n",
      "f_r: [0.00082174], r: [119.8987], f: [2.8941273e-14]\n",
      "Training loss for epoch 87: pinn: 0.1214, boundary: 13.2857, total: 13.4071\n",
      "f_r: [0.0013218], r: [119.3058], f: [3.8575856e-13]\n",
      "f_r: [-0.004429], r: [119.18707], f: [2.68141e-16]\n",
      "f_r: [-0.00170932], r: [119.12503], f: [17.03802]\n",
      "f_r: [9.9362675e-05], r: [119.07438], f: [101.358696]\n",
      "f_r: [-0.00264955], r: [119.18821], f: [1.6506459e-07]\n",
      "f_r: [0.00283782], r: [119.95611], f: [0.00358414]\n",
      "f_r: [-0.0008847], r: [119.16752], f: [1.3673714e-09]\n",
      "f_r: [0.00261901], r: [119.403694], f: [8.388411]\n",
      "f_r: [-0.00112838], r: [119.32264], f: [0.04291231]\n",
      "f_r: [0.00129144], r: [119.26826], f: [1.1173378e-05]\n",
      "f_r: [-0.00365547], r: [119.15117], f: [2.2893028e-07]\n",
      "f_r: [-0.00024216], r: [119.02101], f: [7.957524e-07]\n",
      "f_r: [0.0008583], r: [119.86417], f: [0.0006108]\n",
      "f_r: [-0.00442706], r: [119.84291], f: [9.99893e-09]\n",
      "f_r: [0.00068728], r: [119.3873], f: [1.8823183e-10]\n",
      "f_r: [0.00291124], r: [119.43717], f: [0.06534655]\n",
      "f_r: [-8.774606e-05], r: [119.34882], f: [1.4812116e-15]\n",
      "f_r: [-0.00090665], r: [119.925674], f: [5.8983493e-13]\n",
      "f_r: [0.00196689], r: [119.50006], f: [7.2429366]\n",
      "f_r: [-0.00297491], r: [119.57667], f: [0.03408042]\n",
      "f_r: [0.00084469], r: [119.30694], f: [75.71287]\n",
      "f_r: [-0.00311008], r: [119.23528], f: [0.03255244]\n",
      "f_r: [0.00096243], r: [119.808395], f: [4.0194542e-14]\n",
      "f_r: [-0.00014018], r: [119.555466], f: [0.00011536]\n",
      "f_r: [-0.00023091], r: [119.61067], f: [40.915325]\n",
      "f_r: [0.00278345], r: [119.54794], f: [2.4889366e-06]\n",
      "f_r: [-9.309976e-05], r: [119.78007], f: [36.83541]\n",
      "f_r: [-0.00084992], r: [119.54247], f: [2.0814829e-10]\n",
      "f_r: [0.00063125], r: [119.429436], f: [359.53442]\n",
      "f_r: [-0.00350327], r: [119.81868], f: [7.196275]\n",
      "f_r: [0.00132229], r: [119.0955], f: [6.275869e-11]\n",
      "f_r: [-0.00626261], r: [119.95016], f: [3.05775e-08]\n",
      "f_r: [-0.00040538], r: [119.68232], f: [27.405325]\n",
      "f_r: [0.00010289], r: [119.0796], f: [67.82914]\n",
      "f_r: [-0.00538345], r: [119.64375], f: [21.827948]\n",
      "f_r: [0.00085073], r: [119.26667], f: [3.2495741e-15]\n",
      "f_r: [0.00584962], r: [119.97075], f: [1.7048578e-11]\n",
      "f_r: [-0.0003485], r: [119.35109], f: [4.233035e-14]\n",
      "f_r: [-0.00576948], r: [119.22346], f: [1.1550772e-07]\n",
      "f_r: [-0.00087363], r: [119.34927], f: [0.0012203]\n",
      "Training loss for epoch 88: pinn: 0.1070, boundary: 7.8727, total: 7.9798\n",
      "f_r: [-0.00185784], r: [119.12435], f: [7.326796e-07]\n",
      "f_r: [-0.00094502], r: [119.728676], f: [1.724321e-09]\n",
      "f_r: [-0.00128968], r: [119.063255], f: [52.983143]\n",
      "f_r: [-0.00580657], r: [119.18071], f: [0.24772476]\n",
      "f_r: [0.01343752], r: [119.39572], f: [4.6443955e-12]\n",
      "f_r: [0.00156379], r: [119.95222], f: [199.0058]\n",
      "f_r: [0.00042628], r: [119.00513], f: [0.25036836]\n",
      "f_r: [-0.0077739], r: [119.15003], f: [5.021558e-09]\n",
      "f_r: [-0.00099487], r: [119.67433], f: [2.9886022e-13]\n",
      "f_r: [9.889564e-05], r: [119.52263], f: [191.15683]\n",
      "f_r: [0.00362252], r: [119.96847], f: [2.0502898e-06]\n",
      "f_r: [0.00042299], r: [119.66634], f: [7.890101e-15]\n",
      "f_r: [-0.00068488], r: [119.32127], f: [96.76632]\n",
      "f_r: [0.00072938], r: [119.8836], f: [6.736229e-13]\n",
      "f_r: [0.00042813], r: [119.603134], f: [3.2702215]\n",
      "f_r: [-0.00145948], r: [119.3297], f: [0.00118693]\n",
      "f_r: [-0.00168565], r: [119.09686], f: [0.036704]\n",
      "f_r: [-0.00025396], r: [119.42442], f: [27.58769]\n",
      "f_r: [-6.287018e-05], r: [119.51511], f: [177.13815]\n",
      "f_r: [0.00097286], r: [119.179115], f: [1.2101382]\n",
      "f_r: [0.0002649], r: [119.22619], f: [0.01218298]\n",
      "f_r: [0.00195299], r: [119.925674], f: [0.52907664]\n",
      "f_r: [0.00160636], r: [119.77664], f: [1.2129896]\n",
      "f_r: [-0.00022088], r: [119.71405], f: [6.7504604e-15]\n",
      "f_r: [-0.00182691], r: [119.75927], f: [4.9670655e-07]\n",
      "f_r: [-0.00244236], r: [119.9687], f: [4.545911e-07]\n",
      "f_r: [9.059738e-05], r: [119.015564], f: [271.9664]\n",
      "f_r: [0.00725274], r: [119.21232], f: [0.07932826]\n",
      "f_r: [-2.0017145e-05], r: [119.71429], f: [507.70197]\n",
      "f_r: [0.01574654], r: [119.37773], f: [0.00410229]\n",
      "f_r: [0.00418223], r: [119.90921], f: [2.0393623e-11]\n",
      "f_r: [-0.00032671], r: [119.79857], f: [8.059874e-13]\n",
      "f_r: [-7.499492e-05], r: [119.07915], f: [1.056614e-14]\n",
      "f_r: [0.00029718], r: [119.09119], f: [7.592878e-14]\n",
      "f_r: [0.00040247], r: [119.886345], f: [8.7477206e-14]\n",
      "f_r: [-0.00290476], r: [119.107544], f: [0.03272186]\n",
      "f_r: [-0.00042747], r: [119.759735], f: [0.00151906]\n",
      "f_r: [-0.00689513], r: [119.15889], f: [1.7612076]\n",
      "f_r: [0.00177557], r: [119.729805], f: [0.8347362]\n",
      "f_r: [0.00587129], r: [119.43604], f: [4.7359317e-06]\n",
      "Training loss for epoch 89: pinn: 0.0982, boundary: 4.2493, total: 4.3475\n",
      "f_r: [-0.00015353], r: [119.78806], f: [328.11652]\n",
      "f_r: [-0.00322884], r: [119.406425], f: [2.9059522e-11]\n",
      "f_r: [0.00698149], r: [119.61956], f: [2.382946e-06]\n",
      "f_r: [0.00440615], r: [119.05463], f: [92.48414]\n",
      "f_r: [0.00346216], r: [119.083694], f: [5.367809e-15]\n",
      "f_r: [0.00282813], r: [119.47182], f: [183.09642]\n",
      "f_r: [0.0043719], r: [119.77229], f: [0.01070885]\n",
      "f_r: [0.00075147], r: [119.039635], f: [249.67395]\n",
      "f_r: [0.00113353], r: [119.42283], f: [8.3617934e-14]\n",
      "f_r: [0.00085078], r: [119.539505], f: [0.00202723]\n",
      "f_r: [0.00223082], r: [119.05031], f: [1.0205091e-06]\n",
      "f_r: [0.00047746], r: [119.15025], f: [33.22709]\n",
      "f_r: [0.00209666], r: [119.27782], f: [0.6620564]\n",
      "f_r: [-0.00120634], r: [119.97419], f: [3.8825325e-05]\n",
      "f_r: [-0.00126737], r: [119.792175], f: [8.548852e-07]\n",
      "f_r: [-0.00079032], r: [119.61751], f: [1.5039698e-14]\n",
      "f_r: [0.01234406], r: [119.031456], f: [0.00432195]\n",
      "f_r: [-5.6769182e-05], r: [119.14094], f: [10.700539]\n",
      "f_r: [0.00011119], r: [119.70789], f: [0.05833348]\n",
      "f_r: [-0.00102701], r: [119.79926], f: [12.260616]\n",
      "f_r: [-0.00321019], r: [119.75562], f: [6.887257e-10]\n",
      "f_r: [-9.3236355e-05], r: [119.24711], f: [495.59805]\n",
      "f_r: [-0.00036638], r: [119.09322], f: [5.544812]\n",
      "f_r: [0.0015652], r: [119.08641], f: [1.447893e-06]\n",
      "f_r: [-0.00593568], r: [119.81229], f: [9.88983e-09]\n",
      "f_r: [-2.070816e-05], r: [119.3709], f: [7.371263e-15]\n",
      "f_r: [-0.00042384], r: [119.594246], f: [0.00043998]\n",
      "f_r: [0.00109372], r: [119.53222], f: [0.71175045]\n",
      "f_r: [-5.063305e-05], r: [119.481834], f: [0.0009542]\n",
      "f_r: [-0.00037613], r: [119.406425], f: [27.595472]\n",
      "f_r: [0.00017751], r: [119.82919], f: [122.82306]\n",
      "f_r: [0.00077683], r: [119.46383], f: [3.8499467]\n",
      "f_r: [0.00058612], r: [119.62914], f: [9.2350605e-15]\n",
      "f_r: [-0.00530506], r: [119.96046], f: [1.0227676e-08]\n",
      "f_r: [-0.00355116], r: [119.237785], f: [7.5889844e-10]\n",
      "f_r: [-0.00271931], r: [119.01306], f: [0.0159084]\n",
      "f_r: [0.00052243], r: [119.5566], f: [401.1321]\n",
      "f_r: [0.00036299], r: [119.66109], f: [4.128016]\n",
      "f_r: [0.00967754], r: [119.94467], f: [5.0169357e-12]\n",
      "f_r: [0.00021257], r: [119.83193], f: [515.0867]\n",
      "Training loss for epoch 90: pinn: 0.1009, boundary: 5.2923, total: 5.3932\n",
      "f_r: [-0.00320127], r: [119.943985], f: [2.6221542e-07]\n",
      "f_r: [-0.00194282], r: [119.1473], f: [0.39598012]\n",
      "f_r: [0.00023241], r: [119.55455], f: [6.1410236]\n",
      "f_r: [-0.0015627], r: [119.339035], f: [0.00110555]\n",
      "f_r: [-0.00103297], r: [119.6312], f: [7.3923125]\n",
      "f_r: [0.00290548], r: [119.02805], f: [0.00176166]\n",
      "f_r: [0.00347114], r: [119.97945], f: [1.756617e-13]\n",
      "f_r: [0.00129604], r: [119.15093], f: [98.410225]\n",
      "f_r: [0.00102564], r: [119.255066], f: [7.3742103e-13]\n",
      "f_r: [-0.00049374], r: [119.28987], f: [21.042332]\n",
      "f_r: [-0.00881599], r: [119.8301], f: [1.2785734]\n",
      "f_r: [-0.00070821], r: [119.83079], f: [1.9217165e-12]\n",
      "f_r: [0.00057818], r: [119.66976], f: [0.19799341]\n",
      "f_r: [-0.0017244], r: [119.52423], f: [7.492992e-10]\n",
      "f_r: [-0.00296894], r: [119.72799], f: [3.9017948e-08]\n",
      "f_r: [0.00098754], r: [119.37272], f: [396.9841]\n",
      "f_r: [0.0020872], r: [119.94971], f: [1.9675485e-15]\n",
      "f_r: [0.00046575], r: [119.66041], f: [0.00236725]\n",
      "f_r: [3.6737776e-05], r: [119.25961], f: [5.7257424e-15]\n",
      "f_r: [-0.00481905], r: [119.888855], f: [18.202915]\n",
      "f_r: [0.0015999], r: [119.82349], f: [1.01847]\n",
      "f_r: [-0.00187976], r: [119.961136], f: [3.2905308e-07]\n",
      "f_r: [-0.00010225], r: [119.64558], f: [0.01236078]\n",
      "f_r: [-0.00486803], r: [119.122986], f: [2.8001748e-08]\n",
      "f_r: [-0.00526693], r: [119.81844], f: [2.9210594e-09]\n",
      "f_r: [-0.00043233], r: [119.63508], f: [29.44824]\n",
      "f_r: [0.0012897], r: [119.97258], f: [0.00844104]\n",
      "f_r: [-0.00066797], r: [119.202545], f: [0.00200717]\n",
      "f_r: [0.00027367], r: [119.10163], f: [90.21785]\n",
      "f_r: [-0.00010583], r: [119.655846], f: [5.1321337e-14]\n",
      "f_r: [-0.00212024], r: [119.430115], f: [2.6260116e-10]\n",
      "f_r: [5.456178e-05], r: [119.44583], f: [322.2629]\n",
      "f_r: [5.5216704e-05], r: [119.90738], f: [450.716]\n",
      "f_r: [-0.00378167], r: [119.288055], f: [0.02080191]\n",
      "f_r: [0.00045369], r: [119.34177], f: [1.5801085e-10]\n",
      "f_r: [-0.00453682], r: [119.74809], f: [2.9361242e-09]\n",
      "f_r: [-0.0006403], r: [119.55935], f: [0.00078754]\n",
      "f_r: [0.01706981], r: [119.698296], f: [0.00303535]\n",
      "f_r: [-0.00916844], r: [119.91402], f: [1.6173637]\n",
      "f_r: [-0.00608974], r: [119.16502], f: [4.925073e-08]\n",
      "Training loss for epoch 91: pinn: 0.0986, boundary: 7.7434, total: 7.8420\n",
      "f_r: [-0.00059778], r: [119.868965], f: [2.699405]\n",
      "f_r: [-0.0024117], r: [119.6725], f: [9.893897e-07]\n",
      "f_r: [0.00738388], r: [119.34723], f: [4.5043766e-06]\n",
      "f_r: [0.00114071], r: [119.08959], f: [0.00160675]\n",
      "f_r: [-0.0009436], r: [119.43763], f: [43.734257]\n",
      "f_r: [0.00147454], r: [119.98448], f: [2.9116192e-13]\n",
      "f_r: [0.00090495], r: [119.667946], f: [0.00078826]\n",
      "f_r: [0.01818544], r: [119.56414], f: [0.00341434]\n",
      "f_r: [-0.00234215], r: [119.00535], f: [5.1884715e-14]\n",
      "f_r: [-0.00337954], r: [119.33379], f: [2.0911965e-10]\n",
      "f_r: [-0.00549876], r: [119.06552], f: [1.740283e-09]\n",
      "f_r: [-0.00184547], r: [119.37841], f: [4.1173942e-07]\n",
      "f_r: [-0.00137724], r: [119.61386], f: [4.894792e-10]\n",
      "f_r: [0.00062654], r: [119.24369], f: [1.9346195e-14]\n",
      "f_r: [-0.00428024], r: [119.24324], f: [1.5216384e-09]\n",
      "f_r: [-0.00605337], r: [119.00172], f: [4.6551452e-08]\n",
      "f_r: [-0.00016358], r: [119.9552], f: [58.94829]\n",
      "f_r: [0.00012933], r: [119.98837], f: [576.7987]\n",
      "f_r: [-0.00481238], r: [119.717476], f: [5.770998e-09]\n",
      "f_r: [0.00409247], r: [119.92889], f: [0.00656073]\n",
      "f_r: [-0.00107364], r: [119.99043], f: [1.8166801e-13]\n",
      "f_r: [6.4909975e-05], r: [119.26485], f: [70.42038]\n",
      "f_r: [-0.00282415], r: [119.363396], f: [0.01683988]\n",
      "f_r: [0.00101097], r: [119.1014], f: [2.0110809e-13]\n",
      "f_r: [0.00104518], r: [119.824394], f: [0.54318106]\n",
      "f_r: [0.00094477], r: [119.68711], f: [0.21760215]\n",
      "f_r: [0.0087969], r: [119.971664], f: [7.871214e-06]\n",
      "f_r: [-0.00056823], r: [119.9854], f: [0.04317928]\n",
      "f_r: [-0.00072512], r: [119.07256], f: [6.225237]\n",
      "f_r: [0.00093212], r: [119.27167], f: [7.8022013]\n",
      "f_r: [-0.00025085], r: [119.71109], f: [50.866955]\n",
      "f_r: [-0.00037293], r: [119.21936], f: [7.6482116e-05]\n",
      "f_r: [0.0005519], r: [119.79674], f: [9.077957e-14]\n",
      "f_r: [0.00080369], r: [119.98289], f: [4.5318613]\n",
      "f_r: [0.00048589], r: [119.14889], f: [9.054738e-13]\n",
      "f_r: [-0.0006708], r: [119.469986], f: [4.396198e-14]\n",
      "f_r: [0.00028176], r: [119.13163], f: [114.32624]\n",
      "f_r: [-0.00073223], r: [119.456085], f: [6.0881486e-13]\n",
      "f_r: [-0.0004186], r: [119.84702], f: [5.9395394]\n",
      "f_r: [-0.00379759], r: [119.57507], f: [1.3090524e-09]\n",
      "Training loss for epoch 92: pinn: 0.0918, boundary: 5.1834, total: 5.2752\n",
      "f_r: [9.0536574e-05], r: [119.470436], f: [67.31981]\n",
      "f_r: [0.00200051], r: [119.17798], f: [283.31482]\n",
      "f_r: [0.0013495], r: [119.464745], f: [100.78177]\n",
      "f_r: [0.00217507], r: [119.40483], f: [4.3010205e-12]\n",
      "f_r: [-0.00185188], r: [119.743965], f: [0.0019598]\n",
      "f_r: [-0.00143323], r: [119.28214], f: [261.50537]\n",
      "f_r: [-0.00275824], r: [119.22937], f: [1.182933e-12]\n",
      "f_r: [-0.00040287], r: [119.33516], f: [3.516654]\n",
      "f_r: [-0.00010162], r: [119.757904], f: [516.7704]\n",
      "f_r: [0.00747368], r: [119.28624], f: [9.650333e-06]\n",
      "f_r: [0.00029861], r: [119.16344], f: [28.691816]\n",
      "f_r: [0.00235035], r: [119.81365], f: [2.42482e-06]\n",
      "f_r: [-0.002083], r: [119.91517], f: [0.01603438]\n",
      "f_r: [0.00042249], r: [119.71954], f: [9.782274e-13]\n",
      "f_r: [-0.00056115], r: [119.523315], f: [0.0001523]\n",
      "f_r: [0.00012865], r: [119.69762], f: [1.4607207e-06]\n",
      "f_r: [-0.00032868], r: [119.34017], f: [95.725235]\n",
      "f_r: [-0.00407323], r: [119.43649], f: [4.021553e-08]\n",
      "f_r: [-0.00304948], r: [119.42123], f: [1.3096957e-07]\n",
      "f_r: [-0.00168203], r: [119.90487], f: [1.0568647e-09]\n",
      "f_r: [-0.00185168], r: [119.34358], f: [6.8962613e-10]\n",
      "f_r: [-0.00017573], r: [119.68918], f: [92.08479]\n",
      "f_r: [-0.00127046], r: [119.35815], f: [0.07500993]\n",
      "f_r: [0.00990115], r: [119.31559], f: [1.4868421e-05]\n",
      "f_r: [-0.00495214], r: [119.55046], f: [1.3524121e-07]\n",
      "f_r: [0.00363203], r: [119.444016], f: [3.7273476e-11]\n",
      "f_r: [0.00145867], r: [119.86349], f: [4.410067]\n",
      "f_r: [0.00015587], r: [119.304436], f: [0.11683302]\n",
      "f_r: [-0.00037056], r: [119.72205], f: [22.572123]\n",
      "f_r: [-0.00498026], r: [119.15548], f: [7.2288775e-09]\n",
      "f_r: [0.00073809], r: [119.804054], f: [4.6846442e-05]\n",
      "f_r: [0.00217983], r: [119.68803], f: [2.3938792e-06]\n",
      "f_r: [-0.00407954], r: [119.597206], f: [5.1705933e-09]\n",
      "f_r: [0.00912729], r: [119.59606], f: [7.702283e-12]\n",
      "f_r: [-0.00351126], r: [119.244606], f: [3.7652939e-07]\n",
      "f_r: [-0.00028148], r: [119.89572], f: [57.502632]\n",
      "f_r: [-0.00506767], r: [119.85411], f: [2.0711872e-09]\n",
      "f_r: [-0.00019687], r: [119.65174], f: [0.00028157]\n",
      "f_r: [0.00676501], r: [119.203445], f: [0.07394387]\n",
      "f_r: [0.0001278], r: [119.37135], f: [8.8466244e-05]\n",
      "Training loss for epoch 93: pinn: 0.0980, boundary: 7.4351, total: 7.5330\n",
      "f_r: [-0.00038152], r: [119.52378], f: [43.893833]\n",
      "f_r: [0.00152117], r: [119.47568], f: [398.21683]\n",
      "f_r: [0.0017934], r: [119.24619], f: [0.00031448]\n",
      "f_r: [-1.0526398e-05], r: [119.525375], f: [0.0092392]\n",
      "f_r: [-0.00779247], r: [119.192764], f: [1.6840055]\n",
      "f_r: [-0.0005803], r: [119.23369], f: [0.00012707]\n",
      "f_r: [-0.00116063], r: [119.73461], f: [24.78623]\n",
      "f_r: [-0.00035238], r: [119.29716], f: [59.299427]\n",
      "f_r: [-6.842394e-05], r: [119.40551], f: [498.02792]\n",
      "f_r: [-0.00027701], r: [119.46293], f: [79.26136]\n",
      "f_r: [-0.000317], r: [119.838104], f: [378.97668]\n",
      "f_r: [0.00147297], r: [119.36862], f: [7.638678]\n",
      "f_r: [0.00029598], r: [119.50758], f: [2.3522075e-15]\n",
      "f_r: [0.00058714], r: [119.20594], f: [60.534924]\n",
      "f_r: [0.00035369], r: [119.907845], f: [572.19763]\n",
      "f_r: [0.00237245], r: [119.157295], f: [0.7576602]\n",
      "f_r: [-0.00537206], r: [119.67227], f: [4.1113477e-09]\n",
      "f_r: [0.00565595], r: [119.91951], f: [9.089696e-12]\n",
      "f_r: [0.00012008], r: [119.86051], f: [128.08554]\n",
      "f_r: [-0.00367861], r: [119.05916], f: [0.13792205]\n",
      "f_r: [-0.00396714], r: [119.41827], f: [2.800243e-09]\n",
      "f_r: [-0.00369635], r: [119.42351], f: [1.8946182e-07]\n",
      "f_r: [0.00096079], r: [119.90144], f: [3.7223592]\n",
      "f_r: [-0.00033473], r: [119.9099], f: [33.1359]\n",
      "f_r: [-0.00356083], r: [119.525375], f: [0.01751116]\n",
      "f_r: [-0.00525872], r: [119.633934], f: [22.515419]\n",
      "f_r: [9.3641785e-05], r: [119.58739], f: [1.2402153e-10]\n",
      "f_r: [-0.00559002], r: [119.50053], f: [2.4747257e-08]\n",
      "f_r: [-8.242026e-05], r: [119.65766], f: [40.43457]\n",
      "f_r: [-0.00024172], r: [119.73553], f: [5.930392e-15]\n",
      "f_r: [0.00089634], r: [119.88062], f: [1.2705623]\n",
      "f_r: [0.00103322], r: [119.01353], f: [1.0484551]\n",
      "f_r: [-0.00173037], r: [119.233], f: [0.03189438]\n",
      "f_r: [0.0028578], r: [119.77779], f: [2.862892e-11]\n",
      "f_r: [-0.0041451], r: [119.07391], f: [1.5258483e-07]\n",
      "f_r: [-0.00016774], r: [119.958626], f: [31.742104]\n",
      "f_r: [-0.00156487], r: [119.83331], f: [16.180628]\n",
      "f_r: [-0.00318275], r: [119.07256], f: [5.8935345e-10]\n",
      "f_r: [-1.2475936e-05], r: [119.19935], f: [1.3117024]\n",
      "f_r: [9.456469e-05], r: [119.03464], f: [3.9149697e-14]\n",
      "Training loss for epoch 94: pinn: 0.0904, boundary: 4.3607, total: 4.4510\n",
      "f_r: [0.00170921], r: [119.61203], f: [5.385747e-11]\n",
      "f_r: [0.00413061], r: [119.94765], f: [9.984273e-13]\n",
      "f_r: [-0.00348994], r: [119.73506], f: [0.5161921]\n",
      "f_r: [-0.00011091], r: [119.67457], f: [0.0003316]\n",
      "f_r: [-0.00503416], r: [119.700806], f: [15.035999]\n",
      "f_r: [-0.00158379], r: [119.59081], f: [0.00657649]\n",
      "f_r: [0.00039797], r: [119.02692], f: [0.08192476]\n",
      "f_r: [0.00165904], r: [119.40324], f: [49.644787]\n",
      "f_r: [0.00073503], r: [119.6344], f: [1.0722752e-14]\n",
      "f_r: [-0.00066731], r: [119.57577], f: [0.01771744]\n",
      "f_r: [-0.00019699], r: [119.67661], f: [3.5488675]\n",
      "f_r: [0.00624182], r: [119.3898], f: [1.502636e-11]\n",
      "f_r: [-0.00075854], r: [119.975105], f: [3.1385972e-15]\n",
      "f_r: [0.00519919], r: [119.17049], f: [0.00420179]\n",
      "f_r: [-0.00573428], r: [119.27896], f: [1.1683107e-07]\n",
      "f_r: [-0.00644396], r: [119.018974], f: [6.4664576e-08]\n",
      "f_r: [-0.0003012], r: [119.774574], f: [0.10379015]\n",
      "f_r: [0.00012428], r: [119.324005], f: [53.993797]\n",
      "f_r: [0.00129184], r: [119.278275], f: [9.1540045e-15]\n",
      "f_r: [0.00127866], r: [119.747856], f: [0.9440099]\n",
      "f_r: [5.186761e-05], r: [119.20276], f: [4.288383e-15]\n",
      "f_r: [-0.00019018], r: [119.189575], f: [223.77812]\n",
      "f_r: [-0.00985412], r: [119.14389], f: [0.3671193]\n",
      "f_r: [-0.00195467], r: [119.50234], f: [5.0738265e-07]\n",
      "f_r: [0.00027846], r: [119.15844], f: [475.69745]\n",
      "f_r: [-0.00158021], r: [119.93231], f: [16.380163]\n",
      "f_r: [-0.00376613], r: [119.338356], f: [2.8201567e-08]\n",
      "f_r: [0.00065942], r: [119.579865], f: [8.560688]\n",
      "f_r: [-0.00073602], r: [119.95062], f: [0.09028377]\n",
      "f_r: [-0.00461613], r: [119.99432], f: [1.1423101e-08]\n",
      "f_r: [-0.0018768], r: [119.61568], f: [0.01172233]\n",
      "f_r: [0.00029886], r: [119.02169], f: [235.38829]\n",
      "f_r: [-0.00028137], r: [119.235504], f: [0.00039305]\n",
      "f_r: [-0.00329669], r: [119.55114], f: [0.01227064]\n",
      "f_r: [0.00190926], r: [119.59766], f: [4.0447475e-11]\n",
      "f_r: [-0.0002746], r: [119.261894], f: [1.2781888e-10]\n",
      "f_r: [0.00034583], r: [119.512146], f: [409.0913]\n",
      "f_r: [0.00893483], r: [119.63257], f: [1.8028508e-05]\n",
      "f_r: [-0.0025458], r: [119.55911], f: [2.021521]\n",
      "f_r: [0.00069315], r: [119.50303], f: [2.566382e-06]\n",
      "Training loss for epoch 95: pinn: 0.0911, boundary: 6.7275, total: 6.8186\n",
      "f_r: [0.00190392], r: [119.909676], f: [5.021217e-11]\n",
      "f_r: [0.00937822], r: [119.14617], f: [2.7055216e-11]\n",
      "f_r: [0.00121576], r: [119.37568], f: [55.052822]\n",
      "f_r: [0.00351137], r: [119.26599], f: [7.1127944e-11]\n",
      "f_r: [-0.00126202], r: [119.24597], f: [0.0004146]\n",
      "f_r: [-0.0007478], r: [119.94033], f: [259.1665]\n",
      "f_r: [-0.0007198], r: [119.55911], f: [131.45755]\n",
      "f_r: [0.00097086], r: [119.86211], f: [7.93865e-11]\n",
      "f_r: [-0.00327663], r: [119.99318], f: [1.804755e-07]\n",
      "f_r: [-0.00182428], r: [119.453354], f: [0.15862422]\n",
      "f_r: [-0.00238092], r: [119.8237], f: [0.01678806]\n",
      "f_r: [-0.00194666], r: [119.99088], f: [6.894625]\n",
      "f_r: [0.00021482], r: [119.24097], f: [174.69542]\n",
      "f_r: [-0.00419455], r: [119.28645], f: [0.01565223]\n",
      "f_r: [0.00013398], r: [119.89755], f: [1.300543]\n",
      "f_r: [-0.00582404], r: [119.35998], f: [1.8383762e-08]\n",
      "f_r: [-0.00112325], r: [119.86234], f: [0.00901153]\n",
      "f_r: [0.00085013], r: [119.26736], f: [347.28418]\n",
      "f_r: [-0.00480552], r: [119.27372], f: [0.1831151]\n",
      "f_r: [0.00052273], r: [119.313995], f: [0.00100703]\n",
      "f_r: [-0.00345431], r: [119.23096], f: [2.8224423e-09]\n",
      "f_r: [0.00060154], r: [119.3841], f: [1.9407075e-13]\n",
      "f_r: [0.00061469], r: [119.238235], f: [3.0741905e-14]\n",
      "f_r: [-0.00012027], r: [119.15526], f: [516.31104]\n",
      "f_r: [-9.458928e-05], r: [119.9003], f: [540.0199]\n",
      "f_r: [0.00104522], r: [119.986084], f: [2.3313168e-12]\n",
      "f_r: [0.00590413], r: [119.157524], f: [1.2216034e-05]\n",
      "f_r: [0.00420295], r: [119.866], f: [0.00548781]\n",
      "f_r: [-0.00013398], r: [119.141174], f: [2.454211e-13]\n",
      "f_r: [-0.00391761], r: [119.04645], f: [2.91655e-09]\n",
      "f_r: [0.00016194], r: [119.714516], f: [9.92412e-14]\n",
      "f_r: [-9.2002294e-05], r: [119.58374], f: [406.90228]\n",
      "f_r: [-0.00026194], r: [119.733696], f: [1.6037598e-12]\n",
      "f_r: [-0.00018786], r: [119.5566], f: [1.05360795e-13]\n",
      "f_r: [0.00010512], r: [119.25325], f: [0.44756314]\n",
      "f_r: [0.00036341], r: [119.379776], f: [1.3397398e-10]\n",
      "f_r: [-0.00406116], r: [119.32014], f: [1.9076941e-07]\n",
      "f_r: [2.7717471e-05], r: [119.498245], f: [6.0273907e-15]\n",
      "f_r: [0.00139297], r: [119.12821], f: [1.0618004]\n",
      "f_r: [0.00993352], r: [119.12845], f: [2.5308878e-05]\n",
      "Training loss for epoch 96: pinn: 0.0867, boundary: 5.3709, total: 5.4576\n",
      "f_r: [0.0076664], r: [119.076416], f: [0.06248196]\n",
      "f_r: [-0.00057035], r: [119.78417], f: [28.754053]\n",
      "f_r: [0.00060868], r: [119.02192], f: [44.50513]\n",
      "f_r: [0.00102416], r: [119.67912], f: [168.17133]\n",
      "f_r: [0.00747116], r: [119.04213], f: [5.326417e-06]\n",
      "f_r: [0.00102305], r: [119.336075], f: [1.0317982]\n",
      "f_r: [0.00223976], r: [119.10095], f: [7.6902214e-11]\n",
      "f_r: [-0.00162395], r: [119.5256], f: [0.03048532]\n",
      "f_r: [0.00082653], r: [119.92614], f: [0.00022845]\n",
      "f_r: [0.00032672], r: [119.57507], f: [1.9531775e-13]\n",
      "f_r: [-0.00720739], r: [119.603134], f: [0.25922424]\n",
      "f_r: [-0.00101571], r: [119.46542], f: [6.7901885e-13]\n",
      "f_r: [-0.00395986], r: [119.27645], f: [7.337896e-10]\n",
      "f_r: [-0.00143624], r: [119.09096], f: [1.956566e-10]\n",
      "f_r: [-0.00016047], r: [119.86828], f: [28.290476]\n",
      "f_r: [-0.00029052], r: [119.7458], f: [2.2656626e-15]\n",
      "f_r: [-0.00448136], r: [119.975105], f: [1.435232e-07]\n",
      "f_r: [-0.00276992], r: [119.51261], f: [4.4108575e-07]\n",
      "f_r: [0.00060013], r: [119.335625], f: [99.975784]\n",
      "f_r: [0.00096434], r: [119.08254], f: [3.719563e-15]\n",
      "f_r: [0.00029922], r: [119.03327], f: [10.583865]\n",
      "f_r: [-0.00446439], r: [119.34085], f: [5.39436e-08]\n",
      "f_r: [0.00126936], r: [119.77824], f: [0.2130153]\n",
      "f_r: [0.00097745], r: [119.99112], f: [1.7141582e-06]\n",
      "f_r: [0.000162], r: [119.94512], f: [74.127045]\n",
      "f_r: [0.00080291], r: [119.19231], f: [1.5696578e-14]\n",
      "f_r: [0.00011548], r: [119.11004], f: [293.07596]\n",
      "f_r: [0.00320631], r: [119.36043], f: [4.695139e-06]\n",
      "f_r: [-0.00080134], r: [119.75882], f: [12.834696]\n",
      "f_r: [0.00041052], r: [119.83834], f: [0.00034138]\n",
      "f_r: [0.00074333], r: [119.25347], f: [8.344597]\n",
      "f_r: [0.00013273], r: [119.520134], f: [2.994147]\n",
      "f_r: [0.00023712], r: [119.83217], f: [114.21497]\n",
      "f_r: [-0.00010817], r: [119.79354], f: [24.396133]\n",
      "f_r: [0.00021345], r: [119.52902], f: [5.788334e-05]\n",
      "f_r: [0.00014391], r: [119.807945], f: [40.860043]\n",
      "f_r: [-0.00064656], r: [119.787834], f: [0.0008193]\n",
      "f_r: [-0.00025481], r: [119.71109], f: [5.0371686e-15]\n",
      "f_r: [-0.00446957], r: [119.522415], f: [5.8728338e-09]\n",
      "f_r: [0.00910656], r: [119.2496], f: [1.8240726e-05]\n",
      "Training loss for epoch 97: pinn: 0.0844, boundary: 3.8163, total: 3.9007\n",
      "f_r: [2.2306114e-05], r: [119.996605], f: [0.03179413]\n",
      "f_r: [-0.00868516], r: [119.192085], f: [5.1947055e-08]\n",
      "f_r: [-0.00119056], r: [119.50417], f: [41.999863]\n",
      "f_r: [-0.00051591], r: [119.00103], f: [54.646828]\n",
      "f_r: [0.00038203], r: [119.16366], f: [92.05046]\n",
      "f_r: [0.002922], r: [119.99867], f: [6.955592e-05]\n",
      "f_r: [0.00032728], r: [119.04963], f: [3.0863576]\n",
      "f_r: [-0.00014248], r: [119.28033], f: [75.87909]\n",
      "f_r: [0.00623527], r: [119.58534], f: [7.9763e-12]\n",
      "f_r: [-0.00118071], r: [119.59516], f: [1.9871119e-14]\n",
      "f_r: [0.00015005], r: [119.20663], f: [96.15059]\n",
      "f_r: [0.00070728], r: [119.55638], f: [3.4452105]\n",
      "f_r: [9.2823066e-05], r: [119.4333], f: [0.26823735]\n",
      "f_r: [0.00111555], r: [119.09141], f: [307.81116]\n",
      "f_r: [0.00149811], r: [119.14002], f: [9.913385]\n",
      "f_r: [-0.00248185], r: [119.36634], f: [6.8301015]\n",
      "f_r: [0.00841312], r: [119.85868], f: [0.00339556]\n",
      "f_r: [0.00017385], r: [119.27282], f: [390.62857]\n",
      "f_r: [0.00019228], r: [119.25939], f: [9.926388e-11]\n",
      "f_r: [0.00059399], r: [119.12593], f: [0.00028676]\n",
      "f_r: [0.00343324], r: [119.019196], f: [5.52355e-11]\n",
      "f_r: [0.00151394], r: [119.99731], f: [4.1709287e-15]\n",
      "f_r: [0.00729553], r: [119.60177], f: [1.1935607e-11]\n",
      "f_r: [0.00181101], r: [119.66337], f: [0.7187202]\n",
      "f_r: [0.00021865], r: [119.710175], f: [95.51372]\n",
      "f_r: [0.00013798], r: [119.98059], f: [409.6045]\n",
      "f_r: [-0.01395561], r: [119.59333], f: [0.34213716]\n",
      "f_r: [0.00599087], r: [119.95358], f: [0.00529768]\n",
      "f_r: [-0.00120991], r: [119.15389], f: [6.49211e-07]\n",
      "f_r: [-0.00570164], r: [119.996155], f: [8.519684]\n",
      "f_r: [-0.00036777], r: [119.70561], f: [1.9501875e-10]\n",
      "f_r: [0.00991335], r: [119.71976], f: [2.583785e-05]\n",
      "f_r: [0.01606972], r: [119.376366], f: [0.00264902]\n",
      "f_r: [7.234158e-05], r: [119.92408], f: [1.4642845e-15]\n",
      "f_r: [-0.00433216], r: [119.53039], f: [6.1734764e-09]\n",
      "f_r: [-0.00068995], r: [119.00513], f: [29.4477]\n",
      "f_r: [-0.00533339], r: [119.681404], f: [1.5572486e-08]\n",
      "f_r: [-0.00474749], r: [119.57577], f: [6.7372325e-09]\n",
      "f_r: [-0.00457873], r: [119.2694], f: [3.398769e-08]\n",
      "f_r: [0.00531636], r: [119.26098], f: [1.9589363e-11]\n",
      "Training loss for epoch 98: pinn: 0.0865, boundary: 5.7199, total: 5.8064\n",
      "f_r: [-0.0003446], r: [119.680725], f: [24.515867]\n",
      "f_r: [-0.0082591], r: [119.83193], f: [1.2587408e-08]\n",
      "f_r: [0.00236167], r: [119.573944], f: [73.2692]\n",
      "f_r: [0.00258817], r: [119.989975], f: [198.7545]\n",
      "f_r: [-0.0017341], r: [119.24734], f: [3.7357286e-09]\n",
      "f_r: [0.00191355], r: [119.552734], f: [9.822084]\n",
      "f_r: [-0.00138466], r: [119.068245], f: [13.657699]\n",
      "f_r: [-0.00027172], r: [119.10231], f: [140.16049]\n",
      "f_r: [-0.0025693], r: [119.230736], f: [9.751389e-09]\n",
      "f_r: [0.00260786], r: [119.26326], f: [3.0475703e-13]\n",
      "f_r: [0.00560285], r: [119.76727], f: [0.00664253]\n",
      "f_r: [-5.236281e-06], r: [119.15458], f: [26.507809]\n",
      "f_r: [0.00118049], r: [119.42897], f: [1.9977188e-06]\n",
      "f_r: [-0.00326181], r: [119.27668], f: [2.4506983e-09]\n",
      "f_r: [-0.00137121], r: [119.55228], f: [0.23716223]\n",
      "f_r: [-0.00509762], r: [119.29556], f: [1.0689826e-08]\n",
      "f_r: [0.00111719], r: [119.84291], f: [0.7626421]\n",
      "f_r: [0.00044517], r: [119.993416], f: [141.11214]\n",
      "f_r: [0.01186277], r: [119.44515], f: [0.00344873]\n",
      "f_r: [0.00173444], r: [119.83285], f: [4.405769e-06]\n",
      "f_r: [-0.00272107], r: [119.69373], f: [0.02523361]\n",
      "f_r: [0.00024568], r: [119.84336], f: [7.9435005]\n",
      "f_r: [-0.00449985], r: [119.59058], f: [8.367739e-08]\n",
      "f_r: [-0.00022589], r: [119.57234], f: [504.57608]\n",
      "f_r: [0.00279868], r: [119.61614], f: [7.6508806e-11]\n",
      "f_r: [0.00077559], r: [119.70515], f: [4.271626]\n",
      "f_r: [0.00805773], r: [119.8987], f: [6.579096e-12]\n",
      "f_r: [-0.00060701], r: [119.08005], f: [3.6925063e-14]\n",
      "f_r: [-3.1985921e-06], r: [119.742836], f: [11.494307]\n",
      "f_r: [0.00057612], r: [119.141174], f: [0.11011533]\n",
      "f_r: [0.00010542], r: [119.48936], f: [0.00025754]\n",
      "f_r: [0.00027452], r: [119.996605], f: [1.3348015e-14]\n",
      "f_r: [7.533518e-05], r: [119.91676], f: [40.708004]\n",
      "f_r: [0.0026246], r: [119.32287], f: [6.0053476e-11]\n",
      "f_r: [-0.00096193], r: [119.82736], f: [15.662362]\n",
      "f_r: [0.0003896], r: [119.78464], f: [5.862011e-13]\n",
      "f_r: [0.00051931], r: [119.92225], f: [1.0398756]\n",
      "f_r: [-0.00076915], r: [119.43103], f: [2.5353772e-10]\n",
      "f_r: [-0.00389711], r: [119.50827], f: [7.0477304]\n",
      "f_r: [0.00025646], r: [119.641685], f: [1.45091e-14]\n",
      "Training loss for epoch 99: pinn: 0.0834, boundary: 4.7244, total: 4.8078\n"
     ]
    }
   ],
   "source": [
    "# Neural network. Note: 2 inputs- (p, r), 1 output- f(r, p)\n",
    "inputs = tf.keras.Input((2))\n",
    "x_ = tf.keras.layers.Dense(79, activation='selu')(inputs)\n",
    "x_ = tf.keras.layers.Dense(79, activation='selu')(x_)\n",
    "x_ = tf.keras.layers.Dense(79, activation='selu')(x_)\n",
    "x_ = tf.keras.layers.Dense(79, activation='selu')(x_)\n",
    "outputs = tf.keras.layers.Dense(1, activation='linear')(x_) \n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.2902434203767448\n",
    "lr = 3e-2\n",
    "lr_decay = 0.9162384181161904\n",
    "batchsize = 512\n",
    "boundary_batchsize = 128\n",
    "epochs = 100\n",
    "save = False\n",
    "load_epoch = -1\n",
    "weight_change = 1.4426168198220866\n",
    "patience = 3\n",
    "filename = 'sherpa_id_11'\n",
    "\n",
    "# Initialize and fit the PINN\n",
    "pinn = PINN(inputs=inputs, outputs=outputs, lower_bound=lb, upper_bound=ub, p=p[:, 0], r=r[:, 0], \n",
    "            f_boundary=f_boundary[:, 0], size=size)\n",
    "pinn_loss, boundary_loss, predictions = pinn.fit(P_predict=P_star, alpha=alpha, batchsize=batchsize, boundary_batchsize=boundary_batchsize,\n",
    "                                                         epochs=epochs, lr=lr, size=size, save=save, load_epoch=load_epoch, lr_decay=lr_decay,\n",
    "                                                         weight_change=weight_change, patience=patience, filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the outputs to a pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PINN outputs\n",
    "with open('./figures/pickles/pinn_loss_' + filename + '.pkl', 'wb') as file:\n",
    "    pkl.dump(pinn_loss, file)\n",
    "    \n",
    "with open('./figures/pickles/boundary_loss_' + filename + '.pkl', 'wb') as file:\n",
    "    pkl.dump(boundary_loss, file)\n",
    "    \n",
    "with open('./figures/pickles/predictions_' + filename + '.pkl', 'wb') as file:\n",
    "    pkl.dump(predictions, file)\n",
    "    \n",
    "# with open('./figures/pickles/f_boundary.pkl', 'wb') as file:\n",
    "#     pkl.dump(f_boundary, file)\n",
    "    \n",
    "# with open('./figures/pickles/p.pkl', 'wb') as file:\n",
    "#     pkl.dump(p, file)\n",
    "    \n",
    "# with open('./figures/pickles/T.pkl', 'wb') as file:\n",
    "#     pkl.dump(T, file)\n",
    "    \n",
    "# with open('./figures/pickles/r.pkl', 'wb') as file:\n",
    "#     pkl.dump(r, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinns",
   "language": "python",
   "name": "pinns"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
